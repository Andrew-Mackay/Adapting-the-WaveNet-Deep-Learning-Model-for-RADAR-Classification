{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znku3TNhZY2m"
   },
   "source": [
    "# Hyperparameter search over range data model\n",
    "\n",
    "Due to the time the model takes to train (over 1 hour per epoch), using a 5 fold cross validation strategy (applied in notebook 8 for the CNN model) would take close to 50 hours per parameter configuration (assuming 10 epochs). Therefore to perform any meaningful search, it would take several weeks.\n",
    "\n",
    "Instead, the model will be trained on subject A, D, E and F then evaluated on B.\n",
    "For one parameter configuration (training for 10 epochs) it would now only take 10 hours.\n",
    "\n",
    "The following parameters will remain fixed:\n",
    "* Optimizer: 'adam'\n",
    "* Batch size: 32\n",
    "* Number of desnse layers: 1\n",
    "* Learning rate: 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZxhO7V0ZHUE"
   },
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGNeUj-JDXhs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Needed to allow editing using PyCharm etc\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwLbqieVYIJt"
   },
   "source": [
    "The following cell is needed for compatibility when using both CoLab and Local Jupyter notebook. It sets the appropriate file path for the data and also installs local packages such as models and data_loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XeU0HtoDXh6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "if path == '/content':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    BASE_PATH = '/content/gdrive/My Drive/Level-4-Project/'\n",
    "#     !cd gdrive/My\\ Drive/Level-4-Project/ && pip install --editable .\n",
    "    os.chdir('gdrive/My Drive/Level-4-Project/')\n",
    "    \n",
    "elif path == 'D:\\\\Google Drive\\\\Level-4-Project\\\\notebooks':\n",
    "    BASE_PATH = \"D:/Google Drive/Level-4-Project/\"\n",
    "    \n",
    "elif path == \"/export/home/2192793m\":\n",
    "    BASE_PATH = \"/export/home/2192793m/Level-4-Project/\"\n",
    "    \n",
    "    \n",
    "DATA_PATH_MTI = BASE_PATH + 'data/processed/range_FFT/3/MTI_applied/' # not used\n",
    "DATA_PATH_NO_MTI = BASE_PATH + 'data/processed/range_FFT/3/MTI_not_applied/'\n",
    "\n",
    "RESULTS_PATH = BASE_PATH + 'results/range_data_model_hyperparameter_search/'\n",
    "if not os.path.exists(RESULTS_PATH):\n",
    "    os.makedirs(RESULTS_PATH)\n",
    "    \n",
    "MODEL_PATH = BASE_PATH + 'models/range_data_model_hyperparameter_search/'\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QW7Fa5jTCDXo"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras.callbacks import History, ModelCheckpoint, CSVLogger\n",
    "from keras.models import load_model\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.layers import Input, Conv1D, Multiply, Add, Reshape, Activation, AveragePooling1D, Lambda, Flatten, Dense,GlobalAveragePooling1D\n",
    "from keras.models import load_model, Model\n",
    "from keras.callbacks import History, ModelCheckpoint, EarlyStopping\n",
    "import sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tk_HAyYKYrI8"
   },
   "outputs": [],
   "source": [
    "# needed for CheckpointSaver\n",
    "# https://github.com/scikit-optimize/scikit-optimize/issues/678\n",
    "# ! pip install git+https://github.com/scikit-optimize/scikit-optimize/ \n",
    "    \n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.callbacks import CheckpointSaver\n",
    "from skopt import dump, load\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vxIKU3-fTUy7"
   },
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sj59Pvxv5CX9"
   },
   "outputs": [],
   "source": [
    "# Load in data dictionary.\n",
    "# This does not load in any actual data,\n",
    "# just the dictionary with the names of the files and their associated labels\n",
    "with open(DATA_PATH_NO_MTI + \"index.pkl\", \"rb\") as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYNFp-60ZFe2"
   },
   "outputs": [],
   "source": [
    "#Remove user C as this user is reserved for the test set\n",
    "try:\n",
    "    del data[\"C\"]\n",
    "except KeyError:\n",
    "    print (\"Key 'C' not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQIwQ8EACdIQ"
   },
   "outputs": [],
   "source": [
    "def convert_label_to_int(label):\n",
    "    if label == \"walking\":\n",
    "        return 0\n",
    "    if label == \"pushing\":\n",
    "        return 1\n",
    "    if label == \"sitting\":\n",
    "        return 2\n",
    "    if label == \"pulling\":\n",
    "        return 3\n",
    "    if label == \"circling\":\n",
    "        return 4\n",
    "    if label == \"clapping\":\n",
    "        return 5\n",
    "    if label == \"bending\":\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zN4lXwZg7vv_"
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "partition = {'train':[], 'validation':[]} # contains list of training and validation ID's\n",
    "validation_user = \"B\" # use user B for validation\n",
    "\n",
    "for user_letter, actions in data.items():\n",
    "    for action, results in actions.items():\n",
    "        for result in results:\n",
    "            for row in result:\n",
    "                if user_letter == validation_user:\n",
    "                    partition[\"validation\"].append(row)\n",
    "                    labels[row] = convert_label_to_int(action)\n",
    "\n",
    "                else:\n",
    "                    partition[\"train\"].append(row)\n",
    "                    labels[row] = convert_label_to_int(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4fd5mwu11f9"
   },
   "outputs": [],
   "source": [
    "target_names = [\"walking\", \"pushing\", \"sitting\", \"pulling\", \"circling\", \"clapping\", \"bending\"]\n",
    "nb_classes = len(target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ah1RGSSTYfQ"
   },
   "source": [
    "## DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gOcp1JeSop2"
   },
   "outputs": [],
   "source": [
    "'''Based on code from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly'''\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Generates data for Keras\"\"\"\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(3000),\n",
    "                 n_classes=7, shuffle=False, data_directory='data/',\n",
    "                 bin_range=(0,60), take_average=False, every_second_cell=False):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.data_directory = data_directory\n",
    "        self.bin_range=bin_range\n",
    "        self.take_average = take_average\n",
    "        self.every_second_cell = every_second_cell\n",
    "        self.indexes = None\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\"\"\"\n",
    "\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size samples\"\"\"\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            if self.take_average:\n",
    "                X[i,] = abs(np.average(np.load(self.data_directory + ID), axis=1)[:,np.newaxis])\n",
    "                \n",
    "            elif self.every_second_cell:\n",
    "                X[i,] = abs(np.load(self.data_directory + ID))[:,::2]\n",
    "                \n",
    "            else:\n",
    "                X[i,] = abs(np.load(self.data_directory + ID))[:,self.bin_range[0]:self.bin_range[1]]\n",
    "                \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3MQ0FACt9aa"
   },
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__yOu1WH_iBb"
   },
   "outputs": [],
   "source": [
    "def visualize_results(csvlog_path, metric, save=False, save_file_name=\"\"):\n",
    "    df = pd.read_csv(RESULTS_PATH + csvlog_path)\n",
    "    epoch = df['epoch'] +1\n",
    "    train = df[metric]\n",
    "    val = df['val_' + metric]\n",
    "    plt.figure()\n",
    "    plt.plot(epoch, train, label='train')\n",
    "    plt.plot(epoch, val, label='val')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    if save:\n",
    "        plt.savefig(RESULTS_PATH + save_file_name, format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88LpWZJeTfj2"
   },
   "source": [
    "## Model: Wavenet model adapted based on interpretation from Wavenet Paper\n",
    "\n",
    "Keras implementation of wavenet model taken from https://github.com/basveeling/wavenet and https://github.com/mjpyeon/wavenet-classifier\n",
    "\n",
    "This model has then been adapted to the classification task based on the intrustions from the paper \"WAVENET: A GENERATIVE MODEL FOR RAW AUDIO\" (https://arxiv.org/pdf/1609.03499.pdf)\n",
    "\n",
    "Specifically:\n",
    "\"For this task we added a mean-pooling layer after the dilated convolutions that aggregated the activations to coarser frames spanning 10 milliseconds (160× downsampling).  The pooling layer was followed by a few non-causal convolutions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMveaN0ITfAP"
   },
   "outputs": [],
   "source": [
    "class WaveNetClassifier:\n",
    "    def __init__(self, input_shape, output_shape, kernel_size=2, dilation_depth=9, nb_stacks=1, nb_filters=40,\n",
    "                 pool_size=80, kernel_size_2=4, num_dense_nodes=512, use_skip_connections=True, causal=True):\n",
    "\n",
    "        self.activation = 'softmax'\n",
    "        self.pool_size = pool_size\n",
    "        self.nb_stacks = nb_stacks\n",
    "        self.kernel_size = kernel_size # for dilated layers\n",
    "        self.kernel_size_2 = kernel_size_2 # for normal conv layers at end\n",
    "        self.dilation_depth = dilation_depth\n",
    "        self.nb_filters = nb_filters\n",
    "        self.num_dense_nodes = num_dense_nodes\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "        if causal:\n",
    "            self.padding = 'causal'\n",
    "        else:\n",
    "            self.padding = 'same'\n",
    "\n",
    "        if len(input_shape) == 1:\n",
    "            self.expand_dims = True\n",
    "        elif len(input_shape) == 2:\n",
    "            self.expand_dims = False\n",
    "        else:\n",
    "            print('ERROR: wrong input shape')\n",
    "            sys.exit()\n",
    "\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def residual_block(self, x, i, stack_nb):\n",
    "        original_x = x\n",
    "        tanh_out = Conv1D(self.nb_filters, 2, dilation_rate=2 ** i, padding=self.padding,\n",
    "                          name='dilated_conv_%d_tanh_s%d' % (2 ** i, stack_nb), activation='tanh')(x)\n",
    "        sigm_out = Conv1D(self.nb_filters, 2, dilation_rate=2 ** i, padding=self.padding,\n",
    "                          name='dilated_conv_%d_sigm_s%d' % (2 ** i, stack_nb), activation='sigmoid')(x)\n",
    "        x = Multiply(name='gated_activation_%d_s%d' % (i, stack_nb))([tanh_out, sigm_out])\n",
    "\n",
    "        res_x = Conv1D(self.nb_filters, 1, padding='same')(x)\n",
    "        skip_x = Conv1D(self.nb_filters, 1, padding='same')(x)\n",
    "        res_x = Add()([original_x, res_x])\n",
    "        return res_x, skip_x\n",
    "\n",
    "    def build_model(self):\n",
    "        input_layer = Input(shape=self.input_shape, name='input_part')\n",
    "        out = input_layer\n",
    "        skip_connections = []\n",
    "        out = Conv1D(self.nb_filters, 2,\n",
    "                     dilation_rate=1,\n",
    "                     padding=self.padding,\n",
    "                     name='initial_causal_conv'\n",
    "                     )(out)\n",
    "        for stack_nb in range(self.nb_stacks):\n",
    "            for i in range(0, self.dilation_depth + 1):\n",
    "                out, skip_out = self.residual_block(out, i, stack_nb)\n",
    "                skip_connections.append(skip_out)\n",
    "\n",
    "        if self.use_skip_connections:\n",
    "            out = Add()(skip_connections)\n",
    "        out = Activation('relu')(out)\n",
    "        # added a mean-pooling layer after the dilated convolutions that aggregated the activations to coarser frames\n",
    "        # spanning 10 milliseconds (160× downsampling)\n",
    "        # mean pooling layer adjust pool_size to change downsampling\n",
    "        out = AveragePooling1D(self.pool_size, padding='same', name='mean_pooling_layer_downsampling')(out)\n",
    "\n",
    "        # few non-causal convolutions\n",
    "        # In notebooks 11, 12 and 13 self.kernel_size_2 was incorrectly represented as pooling sizes.\n",
    "        out = Conv1D(self.nb_filters, self.kernel_size_2, strides=2, padding='same', activation='relu')(out)\n",
    "        out = Conv1D(self.nb_filters, self.kernel_size_2, strides=2, padding='same', activation='relu')(out)\n",
    "        out = Conv1D(self.output_shape, self.kernel_size_2, strides=2, padding='same', activation='relu')(out)\n",
    "        out = Conv1D(self.output_shape, self.kernel_size_2, strides=2, padding='same', activation='relu')(out)\n",
    "\n",
    "\n",
    "        out = Flatten()(out)\n",
    "        out = Dense(self.num_dense_nodes, activation='relu')(out)\n",
    "        out = Dense(self.output_shape, activation='softmax')(out)\n",
    "\n",
    "        return Model(input_layer, out)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def get_summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def get_receptive_field(self):\n",
    "        return self.nb_stacks * (2 ** (self.dilation_depth + 1)) - (self.nb_stacks - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnc = WaveNetClassifier(((3000,32)), (7),\n",
    "                        kernel_size=2,\n",
    "                        dilation_depth=8,\n",
    "                        nb_stacks=3,\n",
    "                        nb_filters=64,\n",
    "                        pool_size=126,\n",
    "                        kernel_size_2=2,\n",
    "                        num_dense_nodes=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhFcRSbwZCCw"
   },
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DeW2AmQ2ZGFC"
   },
   "source": [
    "### Fixed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxXVIaedsPxK"
   },
   "outputs": [],
   "source": [
    "# Try all bins to start with\n",
    "bin_range = (0,63)\n",
    "data_shape = (3000, 32)\n",
    "n_filters = 64\n",
    "activation = 'softmax'\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Parameters for data generators\n",
    "data_gen_params = {'dim': data_shape,\n",
    "                   'batch_size': batch_size,\n",
    "                   'n_classes': nb_classes,\n",
    "                   'data_directory': DATA_PATH_NO_MTI,\n",
    "                   'bin_range': bin_range,\n",
    "                   'every_second_cell': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CsyeQlBQZUle"
   },
   "source": [
    "### Parameters to Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAqGS4oWZXE-"
   },
   "outputs": [],
   "source": [
    "space = [\n",
    "    Integer(16, 128, name=\"n_filters\"),\n",
    "    Integer(2, 5, name=\"kernel_size\"),\n",
    "    Integer(2, 9, name=\"dilation_depth\"),\n",
    "    Integer(1, 4, name=\"number_of_stacks\"),\n",
    "    Integer(4, 200, name=\"pool_size\"),\n",
    "    Integer(2, 8, name=\"kernel_size_2\"),\n",
    "    Integer(64, 1024, name='num_dense_nodes'),\n",
    "    Integer(-1, 5, name='early_stopping_patience')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmvMHPqiZP6x"
   },
   "source": [
    "### Objective Function to Minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzWFM-axZS2V"
   },
   "outputs": [],
   "source": [
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    wnc = WaveNetClassifier((data_shape), (nb_classes),\n",
    "                            kernel_size=params[\"kernel_size\"],\n",
    "                            dilation_depth=params[\"dilation_depth\"],\n",
    "                            nb_stacks=params[\"number_of_stacks\"],\n",
    "                            nb_filters=params[\"n_filters\"],\n",
    "                            pool_size=int(params[\"pool_size\"]),\n",
    "                            kernel_size_2=int(params[\"kernel_size_2\"]),\n",
    "                            num_dense_nodes=params[\"num_dense_nodes\"])\n",
    "\n",
    "    model = wnc.get_model()\n",
    "\n",
    "    training_generator = DataGenerator(partition[\"train\"],\n",
    "                                       labels,\n",
    "                                       **data_gen_params, shuffle=True)\n",
    "    \n",
    "    validation_generator = DataGenerator(partition[\"validation\"],\n",
    "                                         labels,\n",
    "                                         **data_gen_params, shuffle=False)\n",
    "\n",
    "    model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    patience = params[\"early_stopping_patience\"]\n",
    "    callback_list = []\n",
    "    # -1 used to represent no early stopping\n",
    "    if patience != -1:\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=patience)\n",
    "        callback_list.append(early_stopping)\n",
    "\n",
    "    # Train model on dataset\n",
    "    history = model.fit_generator(generator=training_generator,\n",
    "                                  validation_data=validation_generator,\n",
    "                                  epochs=epochs,\n",
    "                                  callbacks=callback_list,\n",
    "                                  verbose=1)\n",
    "    \n",
    "    K.clear_session()\n",
    "\n",
    "    return -(history.history[\"val_acc\"][-1]) # return negative of val_acc as minimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oU1PMTWxbA8A"
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZIFbhblcFTD"
   },
   "outputs": [],
   "source": [
    "checkpoint = CheckpointSaver(RESULTS_PATH + \"res_gp_checkpoint.pkl\")\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfd4x0jxsY6S"
   },
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hTA-T_0QsiY2"
   },
   "outputs": [],
   "source": [
    "LOAD_CHECKPOINT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jozj15HsfmA"
   },
   "outputs": [],
   "source": [
    "if LOAD_CHECKPOINT:\n",
    "    res = load(RESULTS_PATH + \"res_gp_checkpoint.pkl\")\n",
    "    x0 = res.x_iters\n",
    "    y0 = res.func_vals\n",
    "    random_starts = 0\n",
    "    \n",
    "else:\n",
    "    x0 = None\n",
    "    y0 = None\n",
    "    random_starts = 5 # default is 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAFCZnjYU36e"
   },
   "source": [
    "### Perform Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8_tpC-DZnyh"
   },
   "outputs": [],
   "source": [
    "res_gp = gp_minimize(objective, space, x0=x0, y0=y0,\n",
    "                     n_calls=130, n_random_starts=random_starts,\n",
    "                     random_state=0, callback=callbacks_list, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsCe4ugZt2Yt"
   },
   "source": [
    "### Save gp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lS-st190t2GS"
   },
   "outputs": [],
   "source": [
    "dump(res_gp, RESULTS_PATH + \"res_gp_complete.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEBqFCS9uImJ"
   },
   "source": [
    "### Load gp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "237ErDR_uKsk"
   },
   "outputs": [],
   "source": [
    "res_gp = load(RESULTS_PATH + \"res_gp_complete.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDOtEG4rZx-9"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNtsWK6Qu9OG"
   },
   "outputs": [],
   "source": [
    "# params at minimum\n",
    "res_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTZfDeBLvG50"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", -res_gp.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrAu-AsZwJzE"
   },
   "outputs": [],
   "source": [
    "plot_convergence(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCkKruT8wS_a"
   },
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G11rXhxlwbvm"
   },
   "outputs": [],
   "source": [
    "-res.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilGWuq3DCKpr"
   },
   "outputs": [],
   "source": [
    "plt.plot(-res.func_vals)\n",
    "plt.plot(np.full((len(res.func_vals)), -res.fun), label=\"Best Accuracy: \" + str(round(-res.fun, 3))+\"%\")\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1i7KpGZhDqxr"
   },
   "outputs": [],
   "source": [
    "res.x_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zobZQaLnvUDm"
   },
   "outputs": [],
   "source": [
    "plot_convergence(res_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WT_IUbWLPXHI"
   },
   "outputs": [],
   "source": [
    "plt.plot(-res_gp.func_vals)\n",
    "plt.plot(np.full((len(res_gp.func_vals)), -res_gp.fun), label=\"Best Accuracy: \" + str(round(-res_gp.fun, 3))+\"%\")\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "12_range_data_model_hyperparameter_search.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
