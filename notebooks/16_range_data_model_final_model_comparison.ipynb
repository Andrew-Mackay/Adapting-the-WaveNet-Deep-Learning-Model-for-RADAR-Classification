{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znku3TNhZY2m"
   },
   "source": [
    "# Final Evalaution of range data model\n",
    "\n",
    "The model was chosen in 11, the data input in notebook 12, the causal vs non-causal design compared in notebook 13, regularization investigated in notebook 14 and the hyperparameters chosen from 15.\n",
    "The early stopping patience to use was decided using notebook 9.\n",
    "\n",
    "First the model is trained on subjects A, B, D, E, F.\n",
    "The model is then evaluated on the test subject C. Up until this point the model has not been exposed to this data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZxhO7V0ZHUE"
   },
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGNeUj-JDXhs"
   },
   "outputs": [],
   "source": [
    "# Needed to allow editing using PyCharm etc\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwLbqieVYIJt"
   },
   "source": [
    "The following cell is needed for compatibility when using both CoLab and Local Jupyter notebook. It sets the appropriate file path for the data and also installs local packages such as models and data_loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XeU0HtoDXh6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "if path == '/content':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    BASE_PATH = '/content/gdrive/My Drive/Level-4-Project/'\n",
    "#     !cd gdrive/My\\ Drive/Level-4-Project/ && pip install --editable .\n",
    "    os.chdir('gdrive/My Drive/Level-4-Project/')\n",
    "    \n",
    "elif path == 'D:\\\\Google Drive\\\\Level-4-Project\\\\notebooks':\n",
    "    BASE_PATH = \"D:/Google Drive/Level-4-Project/\"\n",
    "    \n",
    "elif path == \"/export/home/2192793m\":\n",
    "    BASE_PATH = \"/export/home/2192793m/Level-4-Project/\"\n",
    "    \n",
    "    \n",
    "DATA_PATH_MTI = BASE_PATH + 'data/processed/range_FFT/3/MTI_applied/' # not used\n",
    "DATA_PATH_NO_MTI = BASE_PATH + 'data/processed/range_FFT/3/MTI_not_applied/'\n",
    "\n",
    "RESULTS_PATH = BASE_PATH + 'results/range_data_model_final_evaluation/'\n",
    "if not os.path.exists(RESULTS_PATH):\n",
    "    os.makedirs(RESULTS_PATH)\n",
    "    \n",
    "MODEL_PATH = BASE_PATH + 'models/range_data_model_final_evaluation/'\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QW7Fa5jTCDXo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras.callbacks import History, ModelCheckpoint, CSVLogger\n",
    "from keras.models import load_model\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.layers import Input, Conv1D, Multiply, Add, Reshape, Activation, AveragePooling1D, Lambda, Flatten, Dense,GlobalAveragePooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model, Model\n",
    "from keras.callbacks import History, ModelCheckpoint, EarlyStopping\n",
    "import sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tk_HAyYKYrI8"
   },
   "outputs": [],
   "source": [
    "# needed for CheckpointSaver\n",
    "# https://github.com/scikit-optimize/scikit-optimize/issues/678\n",
    "# ! pip install git+https://github.com/scikit-optimize/scikit-optimize/ \n",
    "    \n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.callbacks import CheckpointSaver\n",
    "from skopt import dump, load\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vxIKU3-fTUy7"
   },
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sj59Pvxv5CX9"
   },
   "outputs": [],
   "source": [
    "# Load in data dictionary.\n",
    "# This does not load in any actual data,\n",
    "# just the dictionary with the names of the files and their associated labels\n",
    "with open(DATA_PATH_NO_MTI + \"index.pkl\", \"rb\") as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQIwQ8EACdIQ"
   },
   "outputs": [],
   "source": [
    "def convert_label_to_int(label):\n",
    "    if label == \"walking\":\n",
    "        return 0\n",
    "    if label == \"pushing\":\n",
    "        return 1\n",
    "    if label == \"sitting\":\n",
    "        return 2\n",
    "    if label == \"pulling\":\n",
    "        return 3\n",
    "    if label == \"circling\":\n",
    "        return 4\n",
    "    if label == \"clapping\":\n",
    "        return 5\n",
    "    if label == \"bending\":\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_by_user(data, user):\n",
    "    labels = {}\n",
    "    partition = {'train':[], 'validation':[]} # contains list of training and validation ID's\n",
    "    validation_user = user # use user for validation\n",
    "\n",
    "    for user_letter, actions in data.items():\n",
    "        for action, results in actions.items():\n",
    "            for result in results:\n",
    "                for row in result:\n",
    "                    if user_letter == validation_user:\n",
    "                        partition[\"validation\"].append(row)\n",
    "                        labels[row] = convert_label_to_int(action)\n",
    "\n",
    "                    else:\n",
    "                        partition[\"train\"].append(row)\n",
    "                        labels[row] = convert_label_to_int(action)\n",
    "                        \n",
    "    return {\"complete_index\": labels, \"partition\":partition}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_by_fold(data, validation_fold):\n",
    "    labels = {}\n",
    "    partition = {'train':[], 'validation':[]} # contains list of training and validation ID's\n",
    "\n",
    "    for user_letter, actions in data.items():\n",
    "        for action, results in actions.items():\n",
    "            for result in results:\n",
    "                res = np.array(result)\n",
    "                # Split into 5 folds then take 1 fold for 20%\n",
    "                split_actions = np.array_split(res, 5)\n",
    "                for fold in range(5):\n",
    "                    data = split_actions[fold]\n",
    "                    if fold == validation_fold:\n",
    "                        for row in data:\n",
    "                            partition[\"validation\"].append(row)\n",
    "                            labels[row] = convert_label_to_int(action)\n",
    "\n",
    "                    else:\n",
    "                        for row in data:\n",
    "                            partition[\"train\"].append(row)\n",
    "                            labels[row] = convert_label_to_int(action) \n",
    "                            \n",
    "    return {\"complete_index\": labels, \"partition\":partition}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the model has only been validated on subject B. This has likely introduced bias into the model. To combat this, the hyperparameter search will using 20% of the data from every subject for validation. To do this it will be made sure that the data is selected in consecutive chunks to negate the issue of consecutive range profiels being almost identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "partition = {'train':[], 'validation':[]} # contains list of training and validation ID's\n",
    "\n",
    "for user_letter, actions in data.items():\n",
    "    for action, results in actions.items():\n",
    "        for result in results:\n",
    "            res = np.array(result)\n",
    "            # Split into 5 folds then take 1 fold for 20%\n",
    "            split_actions = np.array_split(res, 5)\n",
    "            for fold in range(5):\n",
    "                data = split_actions[fold]\n",
    "                if fold == 0:\n",
    "                    for row in data:\n",
    "                        partition[\"validation\"].append(row)\n",
    "                        labels[row] = convert_label_to_int(action)\n",
    "\n",
    "                else:\n",
    "                    for row in data:\n",
    "                        partition[\"train\"].append(row)\n",
    "                        labels[row] = convert_label_to_int(action)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4fd5mwu11f9"
   },
   "outputs": [],
   "source": [
    "target_names = [\"walking\", \"pushing\", \"sitting\", \"pulling\", \"circling\", \"clapping\", \"bending\"]\n",
    "nb_classes = len(target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ah1RGSSTYfQ"
   },
   "source": [
    "## DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gOcp1JeSop2"
   },
   "outputs": [],
   "source": [
    "'''Based on code from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly'''\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Generates data for Keras\"\"\"\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(3000),\n",
    "                 n_classes=7, shuffle=False, data_directory='data/',\n",
    "                 bin_range=(0,60), take_average=False, every_second_cell=False):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.data_directory = data_directory\n",
    "        self.bin_range=bin_range\n",
    "        self.take_average = take_average\n",
    "        self.every_second_cell = every_second_cell\n",
    "        self.indexes = None\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\"\"\"\n",
    "\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size samples\"\"\"\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            if self.take_average:\n",
    "                X[i,] = abs(np.average(np.load(self.data_directory + ID), axis=1)[:,np.newaxis])\n",
    "                \n",
    "            elif self.every_second_cell:\n",
    "                X[i,] = abs(np.load(self.data_directory + ID))[:,::2]\n",
    "                \n",
    "            else:\n",
    "                X[i,] = abs(np.load(self.data_directory + ID))[:,self.bin_range[0]:self.bin_range[1]]\n",
    "                \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3MQ0FACt9aa"
   },
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__yOu1WH_iBb"
   },
   "outputs": [],
   "source": [
    "def visualize_results(csvlog_path, metric, save=False, save_file_name=\"\"):\n",
    "    df = pd.read_csv(RESULTS_PATH + csvlog_path)\n",
    "    epoch = df['epoch'] +1\n",
    "    train = df[metric]\n",
    "    val = df['val_' + metric]\n",
    "    plt.figure()\n",
    "    plt.plot(epoch, train, label='train')\n",
    "    plt.plot(epoch, val, label='val')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    if save:\n",
    "        plt.savefig(RESULTS_PATH + save_file_name, format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88LpWZJeTfj2"
   },
   "source": [
    "## Model: Wavenet model adapted based on interpretation from Wavenet Paper\n",
    "\n",
    "Keras implementation of wavenet model taken from https://github.com/basveeling/wavenet and https://github.com/mjpyeon/wavenet-classifier\n",
    "\n",
    "This model has then been adapted to the classification task based on the intrustions from the paper \"WAVENET: A GENERATIVE MODEL FOR RAW AUDIO\" (https://arxiv.org/pdf/1609.03499.pdf)\n",
    "\n",
    "Specifically:\n",
    "\"For this task we added a mean-pooling layer after the dilated convolutions that aggregated the activations to coarser frames spanning 10 milliseconds (160× downsampling).  The pooling layer was followed by a few non-causal convolutions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNetClassifier:\n",
    "    def __init__(self, input_shape, output_shape, kernel_size=2, dilation_depth=9, nb_stacks=1, nb_filters=40,\n",
    "                 pool_size=80, kernel_size_2=100, use_skip_connections=True, causal=True, residual_l2=0.001,\n",
    "                 conv_l2=0.001, fully_l2=0.001, use_batch_norm=True, num_dense_nodes=512):\n",
    "\n",
    "        self.activation = 'softmax'\n",
    "        self.pool_size = pool_size\n",
    "        self.kernel_size_2 = kernel_size_2 # kernel size for later conV 1d (not dilated)\n",
    "        self.nb_stacks = nb_stacks\n",
    "        self.kernel_size = kernel_size # kernel size for dilated  layers\n",
    "        self.dilation_depth = dilation_depth\n",
    "        self.nb_filters = nb_filters\n",
    "        self.residual_l2 = residual_l2 # l2 value for residual layers\n",
    "        self.conv_l2 = conv_l2 # l2 value for stack of standard conv layers\n",
    "        self.fully_l2 = fully_l2 # l2 value for fully connected layer\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.num_dense_nodes = num_dense_nodes\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        if causal:\n",
    "            self.padding = 'causal'\n",
    "        else:\n",
    "            self.padding = 'same'\n",
    "\n",
    "        if len(input_shape) == 1:\n",
    "            self.expand_dims = True\n",
    "        elif len(input_shape) == 2:\n",
    "            self.expand_dims = False\n",
    "        else:\n",
    "            print('ERROR: wrong input shape')\n",
    "            sys.exit()\n",
    "\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def residual_block(self, x, i, stack_nb):\n",
    "        original_x = x\n",
    "        tanh_out = Conv1D(self.nb_filters, self.kernel_size, dilation_rate=2 ** i, padding=self.padding,\n",
    "                          name='dilated_conv_%d_tanh_s%d' % (2 ** i, stack_nb), activation='tanh',\n",
    "                          kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        sigm_out = Conv1D(self.nb_filters, self.kernel_size, dilation_rate=2 ** i, padding=self.padding,\n",
    "                          name='dilated_conv_%d_sigm_s%d' % (2 ** i, stack_nb), activation='sigmoid',\n",
    "                          kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        x = Multiply(name='gated_activation_%d_s%d' % (i, stack_nb))([tanh_out, sigm_out])\n",
    "\n",
    "        res_x = Conv1D(self.nb_filters, 1, padding='same', kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        skip_x = Conv1D(self.nb_filters, 1, padding='same', kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        res_x = Add()([original_x, res_x])\n",
    "        return res_x, skip_x\n",
    "\n",
    "    def build_model(self):\n",
    "        input_layer = Input(shape=self.input_shape, name='input_part')\n",
    "        out = input_layer\n",
    "        skip_connections = []\n",
    "        out = Conv1D(self.nb_filters, self.kernel_size,\n",
    "                     dilation_rate=1,\n",
    "                     padding=self.padding,\n",
    "                     name='initial_causal_conv'\n",
    "                     )(out)\n",
    "        for stack_nb in range(self.nb_stacks):\n",
    "            for i in range(0, self.dilation_depth + 1):\n",
    "                out, skip_out = self.residual_block(out, i, stack_nb)\n",
    "                skip_connections.append(skip_out)\n",
    "\n",
    "        if self.use_skip_connections:\n",
    "            out = Add()(skip_connections)\n",
    "        out = Activation('relu')(out)\n",
    "        # added a mean-pooling layer after the dilated convolutions that aggregated the activations to coarser frames\n",
    "        # spanning 10 milliseconds (160× downsampling)\n",
    "        # mean pooling layer adjust pool_size_1 to change downsampling\n",
    "                \n",
    "        out = AveragePooling1D(self.pool_size, padding='same', name='mean_pooling_layer_downsampling')(out)\n",
    "\n",
    "        # few non-causal convolutions\n",
    "        # In notebooks 11, 12 and 13 self.kernel_size_2 was incorrectly represented as pooling sizes.\n",
    "        out = Conv1D(self.nb_filters, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "        \n",
    "        out = Conv1D(self.nb_filters, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "        \n",
    "        out = Conv1D(self.output_shape, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "        \n",
    "        out = Conv1D(self.output_shape, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "\n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "            \n",
    "        out = Flatten()(out)\n",
    "        out = Dense(num_dense_nodes, activation='relu', kernel_regularizer=l2(self.fully_l2))(out)\n",
    "        out = Dense(self.output_shape, activation='softmax')(out)\n",
    "\n",
    "        return Model(input_layer, out)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def get_summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def get_receptive_field(self):\n",
    "        return self.nb_stacks * (self.kernel_size + (2*(self.kernel_size - 1) * ((2**self.dilation_depth) - 1))) - (self.nb_stacks - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhFcRSbwZCCw"
   },
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DeW2AmQ2ZGFC"
   },
   "source": [
    "### Fixed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxXVIaedsPxK"
   },
   "outputs": [],
   "source": [
    "bin_range = (0,63)\n",
    "data_shape = (3000, 32)\n",
    "\n",
    "activation = 'softmax'\n",
    "\n",
    "epochs = 10 # number of epochs limited to 10 to allow more searches (15 hours per evaluation = 11 searches in one week)\n",
    "batch_size = 16\n",
    "\n",
    "num_dense_nodes = 512\n",
    "\n",
    "residual_l2 = 0.001\n",
    "conv_l2 = 0.001\n",
    "fully_l2 = 0.001\n",
    "use_batch_norm = False\n",
    "\n",
    "# Parameters for data generators\n",
    "data_gen_params = {'dim': data_shape,\n",
    "                   'batch_size': batch_size,\n",
    "                   'n_classes': nb_classes,\n",
    "                   'data_directory': DATA_PATH_NO_MTI,\n",
    "                   'bin_range': bin_range,\n",
    "                   'every_second_cell': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CsyeQlBQZUle"
   },
   "source": [
    "### Parameters to Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAqGS4oWZXE-"
   },
   "outputs": [],
   "source": [
    "space = [\n",
    "    Integer(32, 128, name=\"n_filters\"),\n",
    "    Integer(2, 5, name=\"kernel_size\"),\n",
    "    Integer(2, 9, name=\"dilation_depth\"),\n",
    "    Integer(1, 4, name=\"number_of_stacks\"),\n",
    "    Integer(4, 10, name=\"pool_size\"),\n",
    "    Integer(2, 8, name=\"kernel_size_2\"),\n",
    "    Integer(-1, 4, name='early_stopping_patience')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmvMHPqiZP6x"
   },
   "source": [
    "### Objective Function to Minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzWFM-axZS2V"
   },
   "outputs": [],
   "source": [
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    wnc = WaveNetClassifier((data_shape), (nb_classes),\n",
    "                            kernel_size=int(params[\"kernel_size\"]),\n",
    "                            dilation_depth=params[\"dilation_depth\"],\n",
    "                            nb_stacks=params[\"number_of_stacks\"],\n",
    "                            nb_filters=params[\"n_filters\"],\n",
    "                            pool_size=int(params[\"pool_size\"]),\n",
    "                            kernel_size_2=int(params[\"kernel_size_2\"]),\n",
    "                            num_dense_nodes=num_dense_nodes,\n",
    "                            residual_l2=residual_l2,\n",
    "                            conv_l2=conv_l2,\n",
    "                            fully_l2=fully_l2,\n",
    "                            use_batch_norm=use_batch_norm)\n",
    "\n",
    "    model = wnc.get_model()\n",
    "\n",
    "    training_generator = DataGenerator(partition[\"train\"],\n",
    "                                       labels,\n",
    "                                       **data_gen_params, shuffle=True)\n",
    "    \n",
    "    validation_generator = DataGenerator(partition[\"validation\"],\n",
    "                                         labels,\n",
    "                                         **data_gen_params, shuffle=False)\n",
    "\n",
    "    model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    patience = params[\"early_stopping_patience\"]\n",
    "    callback_list = []\n",
    "    # -1 used to represent no early stopping\n",
    "    if patience != -1:\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "        callback_list.append(early_stopping)\n",
    "\n",
    "    # Train model on dataset\n",
    "    history = model.fit_generator(generator=training_generator,\n",
    "                                  validation_data=validation_generator,\n",
    "                                  epochs=epochs,\n",
    "                                  callbacks=callback_list,\n",
    "                                  verbose=1)\n",
    "    val_loss = history.history[\"val_loss\"][-1]\n",
    "    K.clear_session()\n",
    "\n",
    "    return val_loss # minimize validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oU1PMTWxbA8A"
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZIFbhblcFTD"
   },
   "outputs": [],
   "source": [
    "checkpoint = CheckpointSaver(RESULTS_PATH + \"res_gp_checkpoint.pkl\")\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfd4x0jxsY6S"
   },
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hTA-T_0QsiY2"
   },
   "outputs": [],
   "source": [
    "LOAD_CHECKPOINT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jozj15HsfmA"
   },
   "outputs": [],
   "source": [
    "if LOAD_CHECKPOINT:\n",
    "    res = load(RESULTS_PATH + \"res_gp_checkpoint.pkl\")\n",
    "    x0 = res.x_iters\n",
    "    y0 = res.func_vals\n",
    "    random_starts = 0\n",
    "    \n",
    "else:\n",
    "    x0 = None\n",
    "    y0 = None\n",
    "    random_starts = 5 # default is 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAFCZnjYU36e"
   },
   "source": [
    "### Perform Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8_tpC-DZnyh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,89,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_35/convolution/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_36/convolution/ExpandDims, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/add_147/_2445 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24725_loss/add_147\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-04809eefd325>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m res_gp = gp_minimize(objective, space, x0=x0, y0=y0,\n\u001b[0;32m      2\u001b[0m                      \u001b[0mn_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m130\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_random_starts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_starts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                      random_state=0, callback=callbacks_list, verbose=True)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\optimizer\\gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mnext_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[1;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[0mobjective_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-705814f73f5b>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(**params)\u001b[0m\n\u001b[0;32m     38\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                                   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                                   verbose=1)\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,89,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_35/convolution/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_36/convolution/ExpandDims, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/add_147/_2445 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24725_loss/add_147\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "res_gp = gp_minimize(objective, space, x0=x0, y0=y0,\n",
    "                     n_calls=130, n_random_starts=random_starts,\n",
    "                     random_state=0, callback=callbacks_list, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsCe4ugZt2Yt"
   },
   "source": [
    "### Save gp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lS-st190t2GS"
   },
   "outputs": [],
   "source": [
    "dump(res_gp, RESULTS_PATH + \"res_gp_complete.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEBqFCS9uImJ"
   },
   "source": [
    "### Load gp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "237ErDR_uKsk"
   },
   "outputs": [],
   "source": [
    "res_gp = load(RESULTS_PATH + \"res_gp_complete.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp\n",
    "res_gp = load(RESULTS_PATH + \"res_gp_checkpoint.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDOtEG4rZx-9"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_filters: 37\n",
      "kernel_size: 3\n",
      "dilation_depth: 5\n",
      "number_of_stacks: 3\n",
      "pool_size: 7\n",
      "kernel_size_2: 4\n",
      "early_stopping_patience: 3\n"
     ]
    }
   ],
   "source": [
    "dimensions = ['n_filters', 'kernel_size', 'dilation_depth', 'number_of_stacks',\n",
    "              'pool_size', 'kernel_size_2',\n",
    "              'early_stopping_patience']\n",
    "\n",
    "parameters = res_gp.x\n",
    "for index, parameter in enumerate(parameters):\n",
    "    print(dimensions[index] + \":\", parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest Loss achieved: 0.38\n"
     ]
    }
   ],
   "source": [
    "print(\"Lowest Loss achieved:\", str(round(res_gp.fun, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adapted from skopt.plots.plot_convergence\n",
    "n_calls = len(res_gp.x_iters)\n",
    "mins = [np.min(res_gp.func_vals[:i])\n",
    "        for i in range(1, n_calls + 1)]\n",
    "plt.plot(range(1, n_calls + 1), np.array(mins), marker='.')\n",
    "plt.title(\"Convergence Plot\")\n",
    "plt.ylabel(\"Classification Loss\")\n",
    "plt.xlabel(\"Number of Calls\")\n",
    "plt.grid()\n",
    "plt.savefig(RESULTS_PATH + \"convergence_plot.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(1, n_calls + 1), (np.array(res_gp.func_vals)), marker='x')\n",
    "plt.scatter([np.argmin(res_gp.func_vals)+1],[res_gp.fun],\n",
    "            marker='x', color='red',\n",
    "            label=\"Lowest Loss: \" + str(round(res_gp.fun, 2))+\"%\")\n",
    "plt.legend(bbox_to_anchor=(0.5,0.35), loc=\"upper left\")\n",
    "plt.ylabel(\"Classification Loss\")\n",
    "plt.xlabel(\"Number of Calls\")\n",
    "plt.grid()\n",
    "plt.title(\"Hyperparameter Search\")\n",
    "plt.savefig(RESULTS_PATH + \"hyperparameter_search.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters Tried:\n",
    "TODO: add rceptive field calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search: 1\n",
      "n_filters: 89\n",
      "kernel_size: 5\n",
      "dilation_depth: 8\n",
      "number_of_stacks: 4\n",
      "pool_size: 8\n",
      "kernel_size_2: 4\n",
      "early_stopping_patience: 0\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for count, parameters in enumerate(res_gp.x_iters):\n",
    "    print(\"Search:\", count+1)\n",
    "    for index, parameter in enumerate(parameters):\n",
    "        print(dimensions[index] + \":\", parameter)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "12_range_data_model_hyperparameter_search.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
