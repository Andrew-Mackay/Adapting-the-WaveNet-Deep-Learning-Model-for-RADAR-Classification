{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5_hkZDGFs6w",
    "colab_type": "text"
   },
   "source": [
    "# Creation of Doppler spectrograms from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "h3sAhsZQkJk0",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Uncomment to set matplotlib backend (much more efficient as no longer showing plot)\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "PYVEJvtQkJlH",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Needed for notebook version\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "h-6B7f68kJlc",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd() == '/content':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    BASE_PATH = '/content/gdrive/My Drive/Level-4-Project/'\n",
    "    os.chdir('gdrive/My Drive/Level-4-Project/')\n",
    "    \n",
    "elif os.getcwd() == 'D:\\\\Google Drive\\\\Level-4-Project\\\\notebooks':\n",
    "    BASE_PATH = \"D:/Google Drive/Level-4-Project/\"\n",
    "    \n",
    "else:\n",
    "    BASE_PATH = \"/export/home/2192793m/Level-4-Project/\"\n",
    "    \n",
    "INTERIM_PATH = BASE_PATH + 'data/interim/'\n",
    "PROCESSED_PATH = BASE_PATH + 'data/interim/doppler_spectrograms/'\n",
    "if not os.path.exists(PROCESSED_PATH):\n",
    "    os.makedirs(PROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "dTQ5EtETkJlu",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import mlab\n",
    "from matplotlib import colors\n",
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Zj2uWVoDkJlR",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "WINDOW_LENGTH = 3  # 3 second window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWRH8tAIB2iD",
    "colab_type": "text"
   },
   "source": [
    "### Function to aid processing Labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "s_OeCwmKBHDJ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def find_label(movement):\n",
    "    \"\"\"\n",
    "    Convert movement description to one word label\n",
    "    :param movement: movement description from experiment notes\n",
    "    :type movement: str\n",
    "    :return: one word label\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    if movement == \"Walking\":\n",
    "        return \"walking\"\n",
    "    if movement == \"Moving arm faster towards radar, slower away\":\n",
    "        return \"pushing\"\n",
    "    if movement == \"Sitting and standing\":\n",
    "        return \"sitting\"\n",
    "    if movement == \"Moving arm slower towards radar, faster away\":\n",
    "        return \"pulling\"\n",
    "    if movement == \"Circling arm forwards\":\n",
    "        return \"circling\"\n",
    "    if movement == \"Clapping\":\n",
    "        return \"clapping\"\n",
    "    if movement == \"Bending to pick up and back up\":\n",
    "        return \"bending\"\n",
    "\n",
    "\n",
    "def identify_angle(angle):\n",
    "    \"\"\"\n",
    "    Strips \" deg\" from input\n",
    "    For example:\n",
    "    \"0 deg\" would return \"0\"\n",
    "    :param angle: angle in format \"0 deg\"\n",
    "    :type angle: str\n",
    "    :return: angle\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    return angle.split()[0]\n",
    "\n",
    "\n",
    "def is_on_place(angle):\n",
    "    \"\"\"\n",
    "    Identifies if measurement has \"on place\" flag for it's aspect angle\n",
    "    :param angle: angle in format \"0 deg\"\n",
    "    :type angle: str\n",
    "    :return: if angle measurement is \"on place\"\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    if len(angle.split()) > 2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def assign_user_label(name):\n",
    "    \"\"\"\n",
    "    Takes in subjects name and returns a letter to represent that subject\n",
    "    :param name: \n",
    "    :type name: str\n",
    "    :return: Letter to represent subject\n",
    "    :rtype: str \n",
    "    \"\"\"\n",
    "    if name == \"Aleksandar\":\n",
    "        return \"A\"\n",
    "    if name == \"Francesco\":\n",
    "        return \"B\"\n",
    "    if name == \"Nadezhda\":\n",
    "        return \"C\"\n",
    "    if name == \"Leila\":\n",
    "        return \"D\"\n",
    "    if name == \"Hadi\":\n",
    "        return \"E\"\n",
    "    if name == \"Ivelina\":\n",
    "        return \"F\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnjLnmTQB9CA",
    "colab_type": "text"
   },
   "source": [
    "### Function to make a directory for the spectrograms to go in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "7fZEdtz7BRqc",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def make_directory(interim_path, window_size, user_label, angle_label, action_label):\n",
    "    \"\"\"\n",
    "    Make a directory path for the spectrograms to go in and return that path\n",
    "    :param interim_path: Path to interim directory\n",
    "    :type interim_path: str\n",
    "    :param window_size: Size of window used\n",
    "    :type window_size: int\n",
    "    :param user_label: Subject letter (A-F)\n",
    "    :type user_label: str\n",
    "    :param angle_label: Aspect Angle (0, 30, 45 or 60)\n",
    "    :type angle_label: str\n",
    "    :param action_label: Action type\n",
    "    :type action_label: str\n",
    "    :return: directory path to put spectrogram in\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    #  interim/window_size/user_label/angle_label/action_label\n",
    "    window_directory = interim_path + str(window_size)\n",
    "    if not os.path.exists(window_directory):\n",
    "        os.makedirs(window_directory)\n",
    "\n",
    "    user_directory = window_directory + \"/\" + user_label\n",
    "    if not os.path.exists(user_directory):\n",
    "        os.makedirs(user_directory)\n",
    "\n",
    "    angle_directory = user_directory + \"/\" + angle_label\n",
    "    if not os.path.exists(angle_directory):\n",
    "        os.makedirs(angle_directory)\n",
    "\n",
    "    action_directory = angle_directory + \"/\" + action_label\n",
    "    if not os.path.exists(action_directory):\n",
    "        os.makedirs(action_directory)\n",
    "\n",
    "    return action_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QH1mK5ECCYV",
    "colab_type": "text"
   },
   "source": [
    "### Function to compute spectrograms from the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "WAX_-MT6c_zY",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def make_spectrograms(df, window_length):\n",
    "    \"\"\"\n",
    "    Create an array of spectrograms from a 60 second radar recording \n",
    "    (based off of the code in \"03_data_processing_demonstration.ipynb\")\n",
    "    :param df: Data frame containing the radar measurements\n",
    "    :type df: DataFrame\n",
    "    :param window_length: Length to make the spectrograms\n",
    "    :type window_length: int\n",
    "    :return: array of spectrograms\n",
    "    :rtype: array of spectrograms\n",
    "    \"\"\"\n",
    "    # Grab RADAR settings from top of file\n",
    "    center_frequency = float(df.iloc[1])  # 5800000000Hz (5.6 GHz)\n",
    "    sweep_time = float(df.iloc[2]) / 1000  # convert to seconds (0.001 seconds)\n",
    "    number_of_time_samples = float(df.iloc[3])  # 128\n",
    "    bandwidth = float(df.iloc[4])  # 400000000Hz (400 MHz)\n",
    "    sampling_frequency = number_of_time_samples / sweep_time\n",
    "    '''\n",
    "    record length = 60s\n",
    "              = 60000 chirps with sweep time of 1ms\n",
    "              = (7680000 measurements / 128 time samples) with sweep time of 1ms\n",
    "    '''\n",
    "    record_length = (len(df.iloc[5:])/number_of_time_samples) * sweep_time\n",
    "\n",
    "    number_of_chirps = record_length / sweep_time  # 60000\n",
    "\n",
    "    # Put data values into an array\n",
    "    data = df.iloc[5:].apply(complex).values\n",
    "\n",
    "    # Reshape into chirps over time\n",
    "    data_time = np.reshape(data, (int(number_of_chirps), int(number_of_time_samples)))\n",
    "    data_time = np.rot90(data_time)\n",
    "\n",
    "\n",
    "    win = np.ones((int(number_of_time_samples), data_time.shape[1]))\n",
    "    # Apply fast fourier transform to give Range FFT\n",
    "    fft_applied = np.fft.fftshift(np.fft.fft((data_time * win), axis=0), 0)\n",
    "\n",
    "    # take relevant half (other half appears to contain only noise)\n",
    "    data_range = fft_applied[1:int(number_of_time_samples / 2), :]\n",
    "\n",
    "    '''\n",
    "    Moving Target Indicator (MTI) Filter:\n",
    "        * Suppress echos from clutter\n",
    "        * Clutter is stationary or close to stationary\n",
    "        * The MTI filter is a high pass filter that filters\n",
    "          out the low Doppler frequencies\n",
    "    Information taken from\n",
    "    http://www.diva-portal.se/smash/get/diva2:1143293/FULLTEXT01.pdf section 5.1\n",
    "    '''\n",
    "    x = data_range.shape[1]\n",
    "    # set ns to nearest even number to x\n",
    "    if x % 2 == 0:\n",
    "        ns = x\n",
    "    else:\n",
    "        ns = x - 1\n",
    "    data_range_MTI = np.zeros((data_range.shape[0], ns), dtype=np.complex128)\n",
    "    # create filter\n",
    "    (b, a) = butter(4, 0.01, btype=\"high\")\n",
    "    # apply filter\n",
    "    for i in range(data_range.shape[0]):\n",
    "        data_range_MTI[i, :ns] = lfilter(b, a, data_range[i, :ns], axis=0)\n",
    "   \n",
    "    \n",
    "    # Spectrogram processing for 2nd FFT to get Doppler FFT\n",
    "    bin_indl = 5\n",
    "    bin_indu = 25\n",
    "    time_window_length = 200\n",
    "    overlap_factor = 0.95\n",
    "    overlap_length = np.round(time_window_length * overlap_factor)\n",
    "    pad_factor = 4\n",
    "    fft_points = pad_factor * time_window_length\n",
    "\n",
    "    data_spec_MTI2 = 0\n",
    "    for rbin in range(bin_indl - 1, bin_indu):\n",
    "        s, f, t = mlab.specgram(data_range_MTI[rbin, :],\n",
    "                                Fs=1,\n",
    "                                window=np.hamming(time_window_length),\n",
    "                                noverlap=overlap_length,\n",
    "                                NFFT=time_window_length,\n",
    "                                mode='complex',\n",
    "                                pad_to=fft_points)\n",
    "\n",
    "        data_spec_MTI2 = data_spec_MTI2 + abs(s)\n",
    "\n",
    "    window_size = int(window_length * 100)\n",
    "    iterations = data_spec_MTI2.shape[1] - window_size\n",
    "    step_size = 10  # 0.1 seconds\n",
    "    spectrograms = []\n",
    "    for i in range(0, iterations, step_size):\n",
    "        center = int(data_spec_MTI2.shape[0]/2)\n",
    "        data_spec_small = data_spec_MTI2[(center-150):(center+150), i:(i + window_size)]\n",
    "        spectrograms.append(data_spec_small)\n",
    "\n",
    "    return spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qn5ztmz_CRe_",
    "colab_type": "text"
   },
   "source": [
    "## Create spectrograms from the raw data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLv3Yv6xkJl0",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(INTERIM_PATH + 'Labels.csv')\n",
    "df_labels.rename(columns={'dataset ID': 'dataset_id'}, inplace=True)\n",
    "df_labels[\"label\"] = df_labels.movement.apply(find_label)\n",
    "df_labels[\"user_label\"] = df_labels.person.apply(assign_user_label)\n",
    "df_labels[\"aspect_angle\"] = df_labels.angle.apply(identify_angle)\n",
    "df_labels[\"on_place\"] = df_labels.angle.apply(is_on_place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5qmhqx3ukJmF",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "image_width = 150\n",
    "image_height = 150\n",
    "minimum_value = 35\n",
    "norm = colors.Normalize(vmin=minimum_value, vmax=None, clip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": false,
    "id": "Ulc8rbMDkJmU",
    "colab_type": "code",
    "outputId": "6b572686-e162-479c-a909-13d8cea26b17",
    "colab": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 1 of 123\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3d3a6c55766e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         INTERIM_PATH, WINDOW_LENGTH, row.user_label, row.aspect_angle, row.label)\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mradar_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mspectrograms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_spectrograms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_spectrograms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mradar_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_row\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_numpy_spectrogram.npy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspectrograms\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# save matrix version of spectrograms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m     \"\"\"\n\u001b[0;32m    813\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "number_of_rows = df_labels.shape[0]\n",
    "current_row = 1\n",
    "for row in df_labels.itertuples():\n",
    "    print(\"Processing row\", current_row, \"of\", number_of_rows)\n",
    "    file_name = INTERIM_PATH + \"Dataset_\" + str(row.dataset_id) + \".dat\"\n",
    "    file_path = make_directory(\n",
    "        PROCESSED_PATH, WINDOW_LENGTH, row.user_label, row.aspect_angle, row.label)\n",
    "    \n",
    "    radar_df = pd.read_csv(file_name, header=None)[1]\n",
    "    \n",
    "    spectrograms = make_spectrograms(radar_df, WINDOW_LENGTH)\n",
    "#     current_row += 1\n",
    "    count = 1\n",
    "    for spectrogram in spectrograms:\n",
    "        fig = plt.figure(frameon=False)\n",
    "        fig.set_size_inches(image_width, image_height)\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "        ax.imshow(20 * np.log10(abs(spectrogram)), cmap='jet', norm=norm)\n",
    "        fig.savefig(file_path + \"/\" + str(current_row) + \"_\" + str(count)+\".png\", dpi=1)\n",
    "        plt.close(fig)\n",
    "        count += 1\n",
    "\n",
    "    current_row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "c6-Qx383kJmn",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "4_interim_dataset_creation_doppler_spectrogram.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [
    "kWRH8tAIB2iD",
    "PnjLnmTQB9CA"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
