# -*- coding: utf-8 -*-
"""raw_datasets_creation_v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lsqnD37MQDdHjBtsWPEKMOixIa6beKiu
"""

# Needed for notebook version
# %matplotlib inline
# Needed to allow editing using PyCharm
# %load_ext autoreload
# %autoreload 2

WINDOW_LENGTH = 3

import os
if os.getcwd() == '/content':
    from google.colab import drive
    drive.mount('/content/gdrive')
    BASE_PATH = '/content/gdrive/My Drive/Level-4-Project/'
    #!cd gdrive/My\ Drive/Level-4-Project/ && pip install --editable .
    os.chdir('gdrive/My Drive/Level-4-Project/')
    
elif os.getcwd() == 'D:\\Google Drive\\Level-4-Project\\notebooks\\data_processing' or os.getcwd() == 'D:\\Google Drive\\Level-4-Project\\src\\features':
    BASE_PATH = "D:/Google Drive/Level-4-Project/"
    
else:
    BASE_PATH = "/export/home/2192793m/Level-4-Project/"
    
DATA_PATH = BASE_PATH + 'data/'
RAW_PATH = DATA_PATH + 'raw/'
INTERIM_PATH = DATA_PATH + 'interim/'
INTERIM_PATH = 'D:/interim/raw_normalized/'

from src.features import make_spectrograms, process_labels, make_directory

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import mlab
from matplotlib import colors
from scipy.signal import butter, freqz, lfilter, spectrogram
import time
from sklearn import preprocessing
import pickle

df_labels = pd.read_csv(RAW_PATH + 'Labels.csv')
df_labels.rename(columns={'dataset ID':'dataset_id'}, inplace=True)

df_labels = process_labels.process_labels(df_labels)


# Switches out i for j to ensure python compatibility
def convert_to_complex_and_abs(complex_string):
    return abs(complex(complex_string[0].replace('i', 'j')))

labels = ["walking", "pushing", "sitting", "pulling", "circling", "clapping", "bending"]
processed = {"A":{}, "B":{}, "C":{}, "D":{}, "E":{}, "F":{}}
for name, item in processed.items():
    for label in labels:
        item[label] = []

number_of_rows = df_labels.shape[0]
current_row = 1
for row in df_labels.itertuples():
    if row.aspect_angle != "0":
        current_row += 1
        continue
        
    start_time = time.time()
    print("Processing row", current_row, "of", number_of_rows)
    file_name = RAW_PATH + "Dataset_" + str(row.dataset_id) + ".dat"

    radar_df = pd.read_table(file_name, sep="\n", header=None)
    # Put data values into an array
    data = radar_df.iloc[4:]
    data = data.apply(convert_to_complex_and_abs, axis=1)
    data = data.values
    length_of_window = 3  # 3 seconds
    length_of_recording = 60
    window_size = int(data.shape[0]/(length_of_recording/length_of_window))
    iterations = int(data.shape[0] - window_size)
    step_size = 10000
    windows_3_seconds_down_sampled = []
    down_sampling_factor = 512

    for i in range(0, iterations, step_size):
        windows_3_seconds_down_sampled.append(np.reshape(data[i:i+window_size], (-1, down_sampling_factor)).mean(axis=0))

    windows_3_seconds_down_sampled = np.array(windows_3_seconds_down_sampled)
    min_val = np.min(windows_3_seconds_down_sampled)
    windows_3_seconds_down_sampled = windows_3_seconds_down_sampled - min_val
    max_val = np.max(windows_3_seconds_down_sampled)
    windows_3_seconds_down_sampled = windows_3_seconds_down_sampled/max_val
    processed[row.user_label][row.label].append(windows_3_seconds_down_sampled)

    current_row += 1
    time_for_row = (time.time() - start_time)/60
    print("---Row took %s minutes ---" % (int(time_for_row)))

with open(INTERIM_PATH + "processed.pkl", "wb") as file:
    pickle.dump(processed, file)


