# -*- coding: utf-8 -*-
"""wavenet_dataset_creation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12zVlWDSrc66elkw-IBjQicmwhsHx8Sg3
"""

import os
path = os.getcwd()
if path == '/content':
    from google.colab import drive
    drive.mount('/content/gdrive')
    BASE_PATH = '/content/gdrive/My Drive/Level-4-Project/'
    # !cd gdrive/My\ Drive/Level-4-Project/ && pip install --editable .
    os.chdir('gdrive/My Drive/Level-4-Project/')
    
elif path == 'D:\\Google Drive\\Level-4-Project\\notebooks\\data_processing':
    BASE_PATH = "D:/Google Drive/Level-4-Project/"
    
elif path == "/export/home/2192793m":
    BASE_PATH = "/export/home/2192793m/Level-4-Project/"
    

DATA_PATH = BASE_PATH + 'data/'
RAW_PATH = DATA_PATH + 'raw/raw_converted/'
PROCESSED_PATH = DATA_PATH + 'processed/wavenet/'
    
from src.features import process_labels
import pandas as pd
from matplotlib import mlab
from scipy.signal import butter, freqz, lfilter, spectrogram
import numpy as np
import pickle

labels = ["walking", "pushing", "sitting", "pulling", "circling", "clapping", "bending"]
processed = {"A":{}, "B":{}, "C":{}, "D":{}, "E":{}, "F":{}}
for name, item in processed.items():
    for label in labels:
        item[label] = []

def nearest_odd_number(x):
    if(np.floor(x) % 2 == 0):
        return int(np.floor(x) + 1)
    else:
        return int(np.floor(x))

def create_range_fft(reshaped_data):
    win = np.ones(reshaped_data.shape)
    # Apply fast fourier transform should compute distance (range) from objects
    fft_applied = np.fft.fft((reshaped_data * win), axis=0)
    return fft_applied[:int(number_of_time_samples/2), :] # take half for some reason?

def MTI_filter(range_fft):
    # IIR Notch filter
    x = range_fft.shape[1]
    ns = nearest_odd_number(x) - 1
    data_range_MTI = np.zeros((range_fft.shape[0], ns), dtype=np.complex128)
    (b, a) = butter(4, 0.01, btype="high")
    # Apply Filter
    for i in range(range_fft.shape[0]):
        data_range_MTI[i, :ns] = lfilter(b, a, range_fft[i, :ns], axis=0)
    # Remove first range bin as has strong residual possibly from filtering?
    return data_range_MTI[1:, :]

def create_doppler_fft(range_fft):
    # Selects range bins
    bin_indl = 5
    bin_indu = 25

    time_window_length = 200
    overlap_factor = 0.95
    overlap_length = np.round(time_window_length * overlap_factor)
    pad_factor = 4
    fft_points = pad_factor * time_window_length

    data_spec_MTI2=0
    for rbin in range(bin_indl-1, bin_indu):    
        s, f, t = mlab.specgram(range_fft[rbin, :],
                                Fs=1,
                                window=np.hamming(time_window_length),
                                noverlap=overlap_length,
                                NFFT=time_window_length, 
                                mode='complex',
                                pad_to=fft_points )

        data_MTI_temp = np.fft.fftshift(s, 1)
        data_spec_MTI2=data_spec_MTI2+data_MTI_temp  
    return data_spec_MTI2

df_labels = pd.read_csv(RAW_PATH + 'Labels.csv')
df_labels.rename(columns={'dataset ID':'dataset_id'}, inplace=True)

df_labels = process_labels.process_labels(df_labels)

number_of_rows = df_labels.shape[0]
current_row = 1
for row in df_labels.itertuples():
    print(row.user_label, row.aspect_angle, row.label)
    if row.aspect_angle != "0":
        current_row += 1
        continue
        
    print("Processing row", current_row, "of", number_of_rows)
    file_name = RAW_PATH + "Dataset_" + str(row.dataset_id) + ".dat"
    radar_df = pd.read_csv(file_name, header=None)[1]
    
    # Grab RADAR settings from top of file
    center_frequency = float(radar_df.iloc[1])
    sweep_time = float(radar_df.iloc[2])/1000  # convert to seconds
    number_of_time_samples = float(radar_df.iloc[3])
    bandwidth = float(radar_df.iloc[4])
    sampling_frequency = number_of_time_samples/sweep_time
    record_length = 60
    number_of_chirps = record_length/sweep_time
    
    # Put data values into an array
    data = radar_df.iloc[5:].apply(complex).values
    
    # Reshape into chirps over time
    data_time = np.reshape(data, (int(number_of_chirps),int(number_of_time_samples)))
    data_time = np.rot90(data_time, k=-1)
    # compute range fft
    range_fft = create_range_fft(data_time)
    # Apply MTI filter to remove stationary objects
    MTI_filter_applied = MTI_filter(range_fft)
    # compute doppler fft
    doppler_fft = create_doppler_fft(MTI_filter_applied)
    # crop to bins with clear doppler signal
    doppler_fft = doppler_fft[300:500, :] 
                                              
    window_length = 3                      
    window_size = int(window_length * 100)
    iterations = doppler_fft.shape[1] - window_size
    step_size = 100  # 1 seconds (was originally 10)
    spectrograms = []
    for i in range(0, iterations, step_size):
        spectrograms.append(doppler_fft[:,i:(i + window_size)])

    processed[row.user_label][row.label].append(spectrograms)

    current_row += 1

with open(PROCESSED_PATH + "processed.pkl", "wb") as file:
    pickle.dump(processed, file)
