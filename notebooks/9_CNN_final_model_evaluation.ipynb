{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "chTLQ4gzP4zb"
   },
   "source": [
    "# Evaluation of the final CNN model\n",
    "The model was chosen in 7_CNN_model_comparison.ipynb and the hyperparameters chosen from 8_CNN_hyperparamete.ipynb.\n",
    "\n",
    "First the model is trained on subjects A, B, D, E, F.\n",
    "The model is then evaluated on the test subject C. Up until this point the model has not been exposed to this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZxhO7V0ZHUE"
   },
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5jAnxaaZLzZ"
   },
   "source": [
    "Allow editing of modules using editor (auto reloading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGNeUj-JDXhs"
   },
   "outputs": [],
   "source": [
    "# Needed to allow editing using PyCharm etc\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwLbqieVYIJt"
   },
   "source": [
    "The following cell is needed for compatibility when using both CoLab and Local Jupyter notebook. It sets the appropriate file path for the data and also installs local packages such as models and data_loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6421,
     "status": "ok",
     "timestamp": 1544198809784,
     "user": {
      "displayName": "Andrew Mackay",
      "photoUrl": "https://lh3.googleusercontent.com/-24hiGmdxZDE/AAAAAAAAAAI/AAAAAAAAL_I/RW7nqM11LkM/s64/photo.jpg",
      "userId": "06804410358976473893"
     },
     "user_tz": 0
    },
    "id": "3XeU0HtoDXh6",
    "outputId": "64e0441a-22cd-4271-a6aa-af54831533fc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "if path == '/content':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    BASE_PATH = '/content/gdrive/My Drive/Level-4-Project/'\n",
    "#     !cd gdrive/My\\ Drive/Level-4-Project/ && pip install --editable .\n",
    "    os.chdir('gdrive/My Drive/Level-4-Project/')\n",
    "    \n",
    "elif path == 'D:\\\\Google Drive\\\\Level-4-Project\\\\notebooks':\n",
    "    BASE_PATH = \"D:/Google Drive/Level-4-Project/\"\n",
    "    \n",
    "elif path == \"/export/home/2192793m\":\n",
    "    BASE_PATH = \"/export/home/2192793m/Level-4-Project/\"\n",
    "    \n",
    "DATA_PATH = BASE_PATH + 'data/processed/doppler_spectrograms/3/'\n",
    "\n",
    "RESULTS_PATH = BASE_PATH + 'results/CNN_final_model_evaluation/'\n",
    "HYPERPARAMETER_PATH = BASE_PATH + 'results/CNN_hyperparameter_search/'\n",
    "MODEL_PATH = BASE_PATH + 'models/CNN_final_model_evaluation/'\n",
    "\n",
    "if not os.path.exists(RESULTS_PATH):\n",
    "    os.makedirs(RESULTS_PATH)\n",
    "    \n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgYwaq1eZb5u"
   },
   "source": [
    "Import remaining packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8rzmlEhpe_R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "import sys\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import csv\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tk_HAyYKYrI8"
   },
   "outputs": [],
   "source": [
    "# ! pip install scikit-optimize\n",
    "from skopt import load\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PsHOJ9lEpe_V"
   },
   "outputs": [],
   "source": [
    "# Needed as originally code was for theano backend but now using tensor flow\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ssk69nuAiB68"
   },
   "source": [
    "## Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5r9302zCpe_j"
   },
   "outputs": [],
   "source": [
    "target_names = [\"walking\", \"pushing\", \"sitting\", \"pulling\", \"circling\", \"clapping\", \"bending\"]\n",
    "nb_classes = len(target_names)\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 75, 75\n",
    "\n",
    "users = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1f1naWmkElm"
   },
   "outputs": [],
   "source": [
    "def load_data(user_letter):\n",
    "    with open(DATA_PATH + user_letter + \"_data.pkl\", 'rb') as data_file:\n",
    "        data = pickle.load(data_file)\n",
    "        data = data.reshape(data.shape[0], 1, 75, 75)\n",
    "        \n",
    "    with open(DATA_PATH + user_letter + \"_labels.pkl\", 'rb') as labels_file:\n",
    "        labels = pickle.load(labels_file)\n",
    "        labels = np.reshape(labels, (len(labels), 1))\n",
    "\n",
    "        \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_bsC10bq026"
   },
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for user in users:\n",
    "    data, labels = load_data(user)\n",
    "    datasets[user] = {\"data\":data, \"labels\":labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymyzQSDQiRL3"
   },
   "outputs": [],
   "source": [
    "def split_train_validation(validation_user):\n",
    "    train_data = None\n",
    "    train_labels = None\n",
    "    first_round = True\n",
    "    validation_data = []\n",
    "    validation_labels = []\n",
    "    for user in users:\n",
    "        data = datasets[user][\"data\"]\n",
    "        labels = datasets[user][\"labels\"]\n",
    "        if user == validation_user:\n",
    "            validation_data = data\n",
    "            validation_labels = labels\n",
    "            \n",
    "        else:\n",
    "            if first_round:\n",
    "                train_data = data\n",
    "                train_labels = labels\n",
    "                first_round = False\n",
    "            else:\n",
    "                train_data = np.concatenate((train_data, data))\n",
    "                train_labels = np.concatenate((train_labels, labels))\n",
    "            \n",
    "    train_labels = np_utils.to_categorical(train_labels, nb_classes)\n",
    "    validation_labels = np_utils.to_categorical(validation_labels, nb_classes)\n",
    "    train_data = train_data.astype('float32')\n",
    "    validation_data = validation_data.astype('float32')\n",
    "    train_data /= 255\n",
    "    validation_data /= 255 \n",
    "    \n",
    "    return {\n",
    "        \"train_data\": train_data,\n",
    "        \"train_labels\": train_labels,\n",
    "        \"validation_data\": validation_data,\n",
    "        \"validation_labels\": validation_labels\n",
    "       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qK0TcJIfsz7q"
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_e0io4rM1O6N"
   },
   "outputs": [],
   "source": [
    "def make_model(nb_filters, img_rows, img_cols, nb_classes, activation,\n",
    "               dropout, num_dense_nodes, num_dense_layers,\n",
    "               kernel_size, pooling_size):\n",
    "    \n",
    "    kernel_size = (kernel_size, kernel_size)\n",
    "    pooling_size = (pooling_size, pooling_size)\n",
    "    \n",
    "    model = Sequential(name=nb_filters)\n",
    "    nb_filters = nb_filters.split(\"-\")\n",
    "    size_1 = int(nb_filters[0])\n",
    "    size_2 = int(nb_filters[1])\n",
    "\n",
    "    model.add(Convolution2D(size_1, kernel_size, padding='same', input_shape=(1, img_rows, img_cols), activation=activation))\n",
    "    model.add(Convolution2D(size_1, kernel_size, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pooling_size))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution2D(size_2, kernel_size, padding='same', activation=activation))\n",
    "    model.add(Convolution2D(size_2, kernel_size, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pooling_size))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    for i in range(num_dense_layers):\n",
    "        model.add(Dense(num_dense_nodes, activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEBqFCS9uImJ"
   },
   "source": [
    "### Load hyperparameter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need objective function to load data\n",
    "space = [\n",
    "    Categorical(['adam', 'sgd_standard', 'sgd_nestrov'], name='optimizer'),\n",
    "    Real(0.0001, 0.1, \"log-uniform\", name='learning_rate'),\n",
    "    Categorical(['relu', 'sigmoid', 'tanh'], name='activation'),\n",
    "    Real(0.1, 0.9, name='dropout'),\n",
    "    Integer(16, 1024, name='num_dense_nodes'),\n",
    "    Integer(1,3, name='num_dense_layers'),\n",
    "    Integer(2,5, name='kernel_size'),\n",
    "    Integer(2,4, name='pooling_size'),\n",
    "    Integer(8, 1024, name='batch_size')\n",
    "]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    average_accuracy = 0\n",
    "    average_loss = 0\n",
    "    for user in users:\n",
    "        data_split = split_train_validation(user)\n",
    "        train_data = data_split[\"train_data\"]\n",
    "        train_labels = data_split[\"train_labels\"]\n",
    "        validation_data = data_split[\"validation_data\"]\n",
    "        validation_labels = data_split[\"validation_labels\"]\n",
    "\n",
    "        model = make_model(\"8-16\", img_rows, img_cols, nb_classes,\n",
    "                           params[\"activation\"], params['dropout'],\n",
    "                           params['num_dense_nodes'],\n",
    "                           params['num_dense_layers'], params['kernel_size'],\n",
    "                           params['pooling_size'])\n",
    "        if params['optimizer'] == 'adam':\n",
    "            selected_optimizer = Adam(lr=params['learning_rate'])\n",
    "            \n",
    "        elif params['optimizer'] == 'sgd_standard':\n",
    "            selected_optimizer = SGD(lr=params['learning_rate'])\n",
    "            \n",
    "        else:\n",
    "            #nestrov momentum\n",
    "            selected_optimizer = SGD(lr=params['learning_rate'], decay=1e-6, \n",
    "                                     momentum=0.9, nesterov=True)\n",
    "            \n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=selected_optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(\n",
    "            train_data,\n",
    "            train_labels,\n",
    "            batch_size=params['batch_size'],\n",
    "            epochs=nb_epoch,\n",
    "            shuffle=True, \n",
    "            verbose=1)\n",
    "\n",
    "        evaluation = model.evaluate(validation_data, validation_labels,\n",
    "                                    batch_size=params['batch_size'], verbose=0)\n",
    "\n",
    "        average_loss += evaluation[0]\n",
    "        average_accuracy += evaluation[1]\n",
    "        \n",
    "    return -(average_accuracy/len(users)) # return negative as minimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "237ErDR_uKsk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macka\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.20.2 when using version 0.20.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "dimensions = ['optimizer', 'learning_rate', 'activation', 'dropout',\n",
    "              'num_dense_nodes', 'num_dense_layers', 'kernel_size',\n",
    "              'pooling_size','batch_size']\n",
    "# res_gp = load(HYPERPARAMETER_PATH + \"res_gp_complete.pkl\")\n",
    "res_gp = load(HYPERPARAMETER_PATH + \"res_gp_checkpoint.pkl\") # used for testing\n",
    "parameters = res_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REWSu0eOVxMR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer: adam\n",
      "learning_rate: 0.0022567198219888875\n",
      "activation: relu\n",
      "dropout: 0.4533687369990764\n",
      "num_dense_nodes: 1003\n",
      "num_dense_layers: 2\n",
      "kernel_size: 3\n",
      "pooling_size: 3\n",
      "batch_size: 903\n"
     ]
    }
   ],
   "source": [
    "for index, parameter in enumerate(parameters):\n",
    "    print(dimensions[index] + \":\", parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xUFmx9viVI7z"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ndLxKnSZEu-"
   },
   "outputs": [],
   "source": [
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pcF98TL5VN_o"
   },
   "outputs": [],
   "source": [
    "model = make_model(\"8-16\", img_rows, img_cols, nb_classes, parameters[2],\n",
    "               parameters[3], parameters[4], parameters[5],\n",
    "               parameters[6], parameters[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKw8W26uW029"
   },
   "outputs": [],
   "source": [
    "data_split = split_train_validation(\"C\") # subject c is test subject\n",
    "train_data = data_split[\"train_data\"]\n",
    "train_labels = data_split[\"train_labels\"]\n",
    "test_data = data_split[\"validation_data\"]\n",
    "test_labels = data_split[\"validation_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilRFgczIW_45"
   },
   "outputs": [],
   "source": [
    "optimizer = parameters[0] \n",
    "learning_rate = parameters[1]\n",
    "if optimizer == 'adam':\n",
    "    selected_optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "elif optimizer == 'sgd_standard':\n",
    "    selected_optimizer = SGD(lr=learning_rate)\n",
    "\n",
    "else:\n",
    "    #nestrov momentum\n",
    "    selected_optimizer = SGD(lr=learning_rate, decay=1e-6, momentum=0.9,\n",
    "                             nesterov=True)\n",
    "               \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=selected_optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGLMYGftXT4T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36985 samples, validate on 7966 samples\n",
      "Epoch 1/20\n",
      "36985/36985 [==============================] - 52s 1ms/step - loss: 1.2550 - acc: 0.5119 - val_loss: 0.9298 - val_acc: 0.5743\n",
      "Epoch 2/20\n",
      "36985/36985 [==============================] - 31s 849us/step - loss: 0.5711 - acc: 0.7985 - val_loss: 0.9800 - val_acc: 0.5796\n",
      "Epoch 3/20\n",
      "36985/36985 [==============================] - 32s 860us/step - loss: 0.3526 - acc: 0.8770 - val_loss: 0.9160 - val_acc: 0.6693\n",
      "Epoch 4/20\n",
      "36985/36985 [==============================] - 32s 853us/step - loss: 0.2585 - acc: 0.9068 - val_loss: 0.9200 - val_acc: 0.6666\n",
      "Epoch 5/20\n",
      "36985/36985 [==============================] - 32s 859us/step - loss: 0.2248 - acc: 0.9192 - val_loss: 0.9239 - val_acc: 0.6864\n",
      "Epoch 6/20\n",
      "36985/36985 [==============================] - 32s 866us/step - loss: 0.1959 - acc: 0.9289 - val_loss: 1.0098 - val_acc: 0.6622\n",
      "Epoch 7/20\n",
      "36985/36985 [==============================] - 32s 863us/step - loss: 0.1755 - acc: 0.9348 - val_loss: 0.9166 - val_acc: 0.6963\n",
      "Epoch 8/20\n",
      "36985/36985 [==============================] - 32s 859us/step - loss: 0.1625 - acc: 0.9391 - val_loss: 0.9543 - val_acc: 0.7116\n",
      "Epoch 9/20\n",
      "36985/36985 [==============================] - 32s 865us/step - loss: 0.1565 - acc: 0.9426 - val_loss: 0.8120 - val_acc: 0.7149\n",
      "Epoch 10/20\n",
      "36985/36985 [==============================] - 32s 866us/step - loss: 0.1483 - acc: 0.9447 - val_loss: 0.8626 - val_acc: 0.7358\n",
      "Epoch 11/20\n",
      "36985/36985 [==============================] - 32s 866us/step - loss: 0.1448 - acc: 0.9451 - val_loss: 0.8793 - val_acc: 0.7496\n",
      "Epoch 12/20\n",
      "36985/36985 [==============================] - 32s 865us/step - loss: 0.1359 - acc: 0.9494 - val_loss: 1.0333 - val_acc: 0.7150\n",
      "Epoch 13/20\n",
      "36985/36985 [==============================] - 32s 861us/step - loss: 0.1328 - acc: 0.9500 - val_loss: 0.8582 - val_acc: 0.7587\n",
      "Epoch 14/20\n",
      "36985/36985 [==============================] - 32s 861us/step - loss: 0.1265 - acc: 0.9524 - val_loss: 0.9579 - val_acc: 0.7423\n",
      "Epoch 15/20\n",
      "36985/36985 [==============================] - 32s 853us/step - loss: 0.1191 - acc: 0.9537 - val_loss: 0.8691 - val_acc: 0.7573\n",
      "Epoch 16/20\n",
      "36985/36985 [==============================] - 32s 864us/step - loss: 0.1180 - acc: 0.9557 - val_loss: 0.8507 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "36985/36985 [==============================] - 32s 876us/step - loss: 0.1171 - acc: 0.9560 - val_loss: 0.7541 - val_acc: 0.7755\n",
      "Epoch 18/20\n",
      "36985/36985 [==============================] - 32s 877us/step - loss: 0.1119 - acc: 0.9574 - val_loss: 0.9561 - val_acc: 0.7415\n",
      "Epoch 19/20\n",
      "36985/36985 [==============================] - 32s 879us/step - loss: 0.1111 - acc: 0.9579 - val_loss: 0.9642 - val_acc: 0.7581\n",
      "Epoch 20/20\n",
      "36985/36985 [==============================] - 32s 875us/step - loss: 0.1135 - acc: 0.9574 - val_loss: 0.9193 - val_acc: 0.7381\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_labels,\n",
    "                    batch_size=parameters[8],\n",
    "                    epochs=nb_epoch,\n",
    "                    shuffle=True, \n",
    "                    validation_data=(test_data, test_labels),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-UiKUBcWZTMl"
   },
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nhg74UlvZO0R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7966/7966 [==============================] - 2s 288us/step\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(test_data, test_labels,\n",
    "                            batch_size=parameters[8], verbose=1)\n",
    "\n",
    "loss = evaluation[0]\n",
    "accuracy = evaluation[1]\n",
    "\n",
    "test_pred = model.predict_classes(test_data)\n",
    "report = classification_report(np.argmax(test_labels,axis=1),\n",
    "                               test_pred, target_names=target_names)\n",
    "conf_matrix = confusion_matrix(np.argmax(test_labels,axis=1), test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NUSNL4FJZZ22"
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHapivwDZY7q"
   },
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH + \"final_trained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_fDcgsnZWmO"
   },
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FvfALPe4ZViU"
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"history\": history.history,\n",
    "    \"loss\": loss,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"confusion_matrix\": conf_matrix,\n",
    "    \"classification_report\": report\n",
    "}\n",
    "with open(RESULTS_PATH + \"results_dictionary.pkl\", 'wb') as results_file:\n",
    "    pickle.dump(results, results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvU7qrKvZilk"
   },
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2uKXbW7dx8-"
   },
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"results_dictionary.pkl\", 'rb') as results_file:\n",
    "    results = pickle.load(results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xo1MQX8HZdEM"
   },
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAQT0GUGehoN"
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TG23dv0ZiER"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-03d873805157>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"history\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"history\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create count of the number of epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mepoch_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_acc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "training_acc = results[\"history\"]['acc']\n",
    "test_acc = results[\"history\"]['val_acc']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_acc) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_acc, 'r--')\n",
    "plt.plot(epoch_count, test_acc, 'b-')\n",
    "plt.legend(['Training Accuracy', 'Test Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Comparison of Training vs Test Accuracy\")\n",
    "if True:\n",
    "    plt.savefig(RESULTS_PATH + \"training_vs_test_acc.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8w4V_UCpek2w"
   },
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gOHRHu1eoZa"
   },
   "outputs": [],
   "source": [
    "training_loss = results[\"history\"]['loss']\n",
    "test_loss = results[\"history\"]['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Comparison of Training vs Test Loss\")\n",
    "if True:\n",
    "    plt.savefig(RESULTS_PATH + \"training_vs_test_loss.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lj9PbHEyepnH"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGvi00vuZf9G"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, save=False, path='/'):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(path, format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cHUVuo_rcOis"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_matrix, target_names,\n",
    "                      save=True, path=RESULTS_PATH + \"confusion_matrix.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "9_CNN_final_model_evaluation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
