{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znku3TNhZY2m"
   },
   "source": [
    "# Hyperparameter search over range data model\n",
    "\n",
    "Due to the time the model takes to train (over 1 hour per epoch), using a 5 fold cross validation strategy (applied in notebook 8 for the CNN model) would take close to 50 hours per parameter configuration (assuming 10 epochs). Therefore to perform any meaningful search, it would take several weeks.\n",
    "\n",
    "Furthermore, up until now the model has been only evaluated on subject B which has made the model bias towards this subject. To try and adjust for this the test set for the hyperparamter optimization will be taken from all subjects (except C). 20\\% of the data from each subject will be used for validation for early stopping whilst a seperate 20% will be used for testing. The data will be taken in consecutive chunks as there is little variation between two consecutive spectrograms.\n",
    "\n",
    "The following parameters will remain fixed:\n",
    "* Optimizer: 'adam'\n",
    "* Batch size: 32\n",
    "* Number of dense layers: 1\n",
    "* Learning rate: 0.001\n",
    "* Number of dense nodes: 512\n",
    "* L2: 0.001\n",
    "* Batch norm: False\n",
    "\n",
    "Limited to 10 epochs as this takes around 15 hours == 11 evalauations in one week\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZxhO7V0ZHUE"
   },
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGNeUj-JDXhs"
   },
   "outputs": [],
   "source": [
    "# Plot graphs inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwLbqieVYIJt"
   },
   "source": [
    "The following cell is needed for compatibility when using both CoLab and Local Jupyter notebook. It sets the appropriate file path for the data and also installs local packages such as models and data_loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XeU0HtoDXh6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# SET PATH TO FOLDER HERE\n",
    "BASE_PATH = \"/home/user/hyperparameter_search/\"\n",
    "DATA_PATH = BASE_PATH + 'MTI_not_applied/'\n",
    "\n",
    "RESULTS_PATH = BASE_PATH + 'results/'\n",
    "if not os.path.exists(RESULTS_PATH):\n",
    "    os.makedirs(RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QW7Fa5jTCDXo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.layers import Input, Conv1D, Multiply, Add, Activation, AveragePooling1D, Flatten, Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tk_HAyYKYrI8"
   },
   "outputs": [],
   "source": [
    "# needed for CheckpointSaver\n",
    "# https://github.com/scikit-optimize/scikit-optimize/issues/678\n",
    "# ! pip install git+https://github.com/scikit-optimize/scikit-optimize/ \n",
    "    \n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.callbacks import CheckpointSaver\n",
    "from skopt import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vxIKU3-fTUy7"
   },
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sj59Pvxv5CX9"
   },
   "outputs": [],
   "source": [
    "# Load in data dictionary.\n",
    "# This does not load in any actual data,\n",
    "# just the dictionary with the names of the files and their associated labels\n",
    "with open(DATA_PATH_NO_MTI + \"index.pkl\", \"rb\") as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYNFp-60ZFe2"
   },
   "outputs": [],
   "source": [
    "# Remove user C as this user is reserved for the test set\n",
    "try:\n",
    "    del data[\"C\"]\n",
    "except KeyError:\n",
    "    print (\"Key 'C' not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQIwQ8EACdIQ"
   },
   "outputs": [],
   "source": [
    "def convert_label_to_int(label):\n",
    "    if label == \"walking\":\n",
    "        return 0\n",
    "    if label == \"pushing\":\n",
    "        return 1\n",
    "    if label == \"sitting\":\n",
    "        return 2\n",
    "    if label == \"pulling\":\n",
    "        return 3\n",
    "    if label == \"circling\":\n",
    "        return 4\n",
    "    if label == \"clapping\":\n",
    "        return 5\n",
    "    if label == \"bending\":\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the model has only been validated on subject B. This has likely introduced bias into the model. To combat this, the hyperparameter search will using 20% of the data from every subject for validation. To do this it will be made sure that the data is selected in consecutive chunks to negate the issue of consecutive range profiels being almost identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_by_fold(data, test_fold, validation_fold, total_folds=5):\n",
    "    labels = {}\n",
    "    partition = {'train': [], 'validation': [], 'test': []}\n",
    "\n",
    "    for user_letter, actions in data.items():\n",
    "        for action, results in actions.items():\n",
    "            for result in results:\n",
    "                res = np.array(result)\n",
    "                # Split into 5 folds then take 1 fold for 20%\n",
    "                split_actions = np.array_split(res, total_folds)\n",
    "                for fold in range(5):\n",
    "                    data = split_actions[fold]\n",
    "                    if fold == test_fold:\n",
    "                        for row in data:\n",
    "                            partition[\"test\"].append(row)\n",
    "                            labels[row] = convert_label_to_int(action)\n",
    "                            \n",
    "                    elif fold == validation_fold:\n",
    "                        for row in data:\n",
    "                            partition[\"validation\"].append(row)\n",
    "                            labels[row] = convert_label_to_int(action)\n",
    "\n",
    "                    else:\n",
    "                        for row in data:\n",
    "                            partition[\"train\"].append(row)\n",
    "                            labels[row] = convert_label_to_int(action) \n",
    "                            \n",
    "    return {\"complete_index\": labels, \"partition\": partition}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into 60% train, 20% validation and 20% test\n",
    "data_split = split_data_by_fold(data, 0, 1, 5)\n",
    "partition = data_split[\"partition\"]\n",
    "labels = data_split[\"complete_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4fd5mwu11f9"
   },
   "outputs": [],
   "source": [
    "target_names = [\"walking\", \"pushing\", \"sitting\", \"pulling\", \"circling\", \"clapping\", \"bending\"]\n",
    "nb_classes = len(target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ah1RGSSTYfQ"
   },
   "source": [
    "## DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gOcp1JeSop2"
   },
   "outputs": [],
   "source": [
    "'''Based on code from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly'''\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Generates data for Keras\"\"\"\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(3000),\n",
    "                 n_classes=7, shuffle=False, data_directory='data/',\n",
    "                 bin_range=(0,60), take_average=False, every_second_cell=False):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.data_directory = data_directory\n",
    "        self.bin_range=bin_range\n",
    "        self.take_average = take_average\n",
    "        self.every_second_cell = every_second_cell\n",
    "        self.indexes = None\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\"\"\"\n",
    "\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size samples\"\"\"\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            if self.take_average:\n",
    "                X[i,] = abs(np.average(np.load(self.data_directory + ID), axis=1)[:,np.newaxis])\n",
    "                \n",
    "            elif self.every_second_cell:\n",
    "                X[i,] = abs(np.load(self.data_directory + ID))[:,::2]\n",
    "                \n",
    "            else:\n",
    "                X[i,] = abs(np.load(self.data_directory + ID))[:,self.bin_range[0]:self.bin_range[1]]\n",
    "                \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3MQ0FACt9aa"
   },
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__yOu1WH_iBb"
   },
   "outputs": [],
   "source": [
    "def visualize_results(csvlog_path, metric, save=False, save_file_name=\"\"):\n",
    "    df = pd.read_csv(RESULTS_PATH + csvlog_path)\n",
    "    epoch = df['epoch'] + 1\n",
    "    train = df[metric]\n",
    "    val = df['val_' + metric]\n",
    "    plt.figure()\n",
    "    plt.plot(epoch, train, label='train')\n",
    "    plt.plot(epoch, val, label='val')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    if save:\n",
    "        plt.savefig(RESULTS_PATH + save_file_name, format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88LpWZJeTfj2"
   },
   "source": [
    "## Model: Wavenet model adapted based on interpretation from Wavenet Paper\n",
    "\n",
    "Keras implementation of wavenet model taken from https://github.com/basveeling/wavenet and https://github.com/mjpyeon/wavenet-classifier\n",
    "\n",
    "This model has then been adapted to the classification task based on the intrustions from the paper \"WAVENET: A GENERATIVE MODEL FOR RAW AUDIO\" (https://arxiv.org/pdf/1609.03499.pdf)\n",
    "\n",
    "Specifically:\n",
    "\"For this task we added a mean-pooling layer after the dilated convolutions that aggregated the activations to coarser frames spanning 10 milliseconds (160× downsampling).  The pooling layer was followed by a few non-causal convolutions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNetClassifier:\n",
    "    def __init__(self, input_shape, output_shape, kernel_size=2, dilation_depth=9, nb_stacks=1, nb_filters=40,\n",
    "                 pool_size=80, kernel_size_2=100, use_skip_connections=True, causal=True, residual_l2=0.001,\n",
    "                 conv_l2=0.001, fully_l2=0.001, use_batch_norm=True, num_dense_nodes=512):\n",
    "\n",
    "        self.activation = 'softmax'\n",
    "        self.pool_size = pool_size\n",
    "        self.kernel_size_2 = kernel_size_2 # kernel size for later conV 1d (not dilated)\n",
    "        self.nb_stacks = nb_stacks\n",
    "        self.kernel_size = kernel_size # kernel size for dilated  layers\n",
    "        self.dilation_depth = dilation_depth\n",
    "        self.nb_filters = nb_filters\n",
    "        self.residual_l2 = residual_l2 # l2 value for residual layers\n",
    "        self.conv_l2 = conv_l2 # l2 value for stack of standard conv layers\n",
    "        self.fully_l2 = fully_l2 # l2 value for fully connected layer\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.num_dense_nodes = num_dense_nodes\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        if causal:\n",
    "            self.padding = 'causal'\n",
    "        else:\n",
    "            self.padding = 'same'\n",
    "\n",
    "        if len(input_shape) == 1:\n",
    "            self.expand_dims = True\n",
    "        elif len(input_shape) == 2:\n",
    "            self.expand_dims = False\n",
    "        else:\n",
    "            print('ERROR: wrong input shape')\n",
    "            sys.exit()\n",
    "\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def residual_block(self, x, i, stack_nb):\n",
    "        original_x = x\n",
    "        tanh_out = Conv1D(self.nb_filters, self.kernel_size, dilation_rate=2 ** i, padding=self.padding,\n",
    "                          name='dilated_conv_%d_tanh_s%d' % (2 ** i, stack_nb), activation='tanh',\n",
    "                          kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        sigm_out = Conv1D(self.nb_filters, self.kernel_size, dilation_rate=2 ** i, padding=self.padding,\n",
    "                          name='dilated_conv_%d_sigm_s%d' % (2 ** i, stack_nb), activation='sigmoid',\n",
    "                          kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        x = Multiply(name='gated_activation_%d_s%d' % (i, stack_nb))([tanh_out, sigm_out])\n",
    "\n",
    "        res_x = Conv1D(self.nb_filters, 1, padding='same', kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        skip_x = Conv1D(self.nb_filters, 1, padding='same', kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        res_x = Add()([original_x, res_x])\n",
    "        return res_x, skip_x\n",
    "\n",
    "    def build_model(self):\n",
    "        input_layer = Input(shape=self.input_shape, name='input_part')\n",
    "        out = input_layer\n",
    "        skip_connections = []\n",
    "        out = Conv1D(self.nb_filters, self.kernel_size,\n",
    "                     dilation_rate=1,\n",
    "                     padding=self.padding,\n",
    "                     name='initial_causal_conv'\n",
    "                     )(out)\n",
    "        for stack_nb in range(self.nb_stacks):\n",
    "            for i in range(0, self.dilation_depth + 1):\n",
    "                out, skip_out = self.residual_block(out, i, stack_nb)\n",
    "                skip_connections.append(skip_out)\n",
    "\n",
    "        if self.use_skip_connections:\n",
    "            out = Add()(skip_connections)\n",
    "        out = Activation('relu')(out)\n",
    "        # added a mean-pooling layer after the dilated convolutions that aggregated the activations to coarser frames\n",
    "        # spanning 10 milliseconds (160× downsampling)\n",
    "        # mean pooling layer adjust pool_size_1 to change downsampling\n",
    "                \n",
    "        out = AveragePooling1D(self.pool_size, padding='same', name='mean_pooling_layer_downsampling')(out)\n",
    "\n",
    "        # few non-causal convolutions\n",
    "        # In notebooks 11, 12 and 13 self.kernel_size_2 was incorrectly represented as pooling sizes.\n",
    "        out = Conv1D(self.nb_filters, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "        \n",
    "        out = Conv1D(self.nb_filters, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "        \n",
    "        out = Conv1D(self.output_shape, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "        \n",
    "        out = Conv1D(self.output_shape, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "\n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "            \n",
    "        out = Flatten()(out)\n",
    "        out = Dense(num_dense_nodes, activation='relu', kernel_regularizer=l2(self.fully_l2))(out)\n",
    "        out = Dense(self.output_shape, activation='softmax')(out)\n",
    "\n",
    "        return Model(input_layer, out)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def get_summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def get_receptive_field(self):\n",
    "        k = self.kernel_size\n",
    "        n = self.dilation_depth\n",
    "        s = self.nb_stacks\n",
    "        r_s = k + (2*(k-1)*((2**(n-1))-1))  # receptive field for one stack\n",
    "        return (s*r_s) - (s-1)  # total receptive field for 's' number of stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhFcRSbwZCCw"
   },
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DeW2AmQ2ZGFC"
   },
   "source": [
    "### Fixed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxXVIaedsPxK"
   },
   "outputs": [],
   "source": [
    "bin_range = (0, 63)\n",
    "data_shape = (3000, 32)\n",
    "\n",
    "activation = 'softmax'\n",
    "\n",
    "epochs = 10  # number of epochs limited to 10 to allow more searches (15 hours per evaluation = 11 searches in one week)\n",
    "batch_size = 16\n",
    "\n",
    "num_dense_nodes = 512\n",
    "\n",
    "residual_l2 = 0.001\n",
    "conv_l2 = 0.001\n",
    "fully_l2 = 0.001\n",
    "use_batch_norm = False\n",
    "\n",
    "# Parameters for data generators\n",
    "data_gen_params = {'dim': data_shape,\n",
    "                   'batch_size': batch_size,\n",
    "                   'n_classes': nb_classes,\n",
    "                   'data_directory': DATA_PATH_NO_MTI,\n",
    "                   'bin_range': bin_range,\n",
    "                   'every_second_cell': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CsyeQlBQZUle"
   },
   "source": [
    "### Parameters to Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAqGS4oWZXE-"
   },
   "outputs": [],
   "source": [
    "space = [\n",
    "    Integer(32, 128, name=\"n_filters\"),\n",
    "    Integer(2, 5, name=\"kernel_size\"),\n",
    "    Integer(2, 9, name=\"dilation_depth\"),\n",
    "    Integer(1, 4, name=\"number_of_stacks\"),\n",
    "    Integer(4, 10, name=\"pool_size\"),\n",
    "    Integer(2, 8, name=\"kernel_size_2\"),\n",
    "    Integer(-1, 4, name='early_stopping_patience')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmvMHPqiZP6x"
   },
   "source": [
    "### Objective Function to Minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzWFM-axZS2V"
   },
   "outputs": [],
   "source": [
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    wnc = WaveNetClassifier((data_shape), (nb_classes),\n",
    "                            kernel_size=int(params[\"kernel_size\"]),\n",
    "                            dilation_depth=params[\"dilation_depth\"],\n",
    "                            nb_stacks=params[\"number_of_stacks\"],\n",
    "                            nb_filters=params[\"n_filters\"],\n",
    "                            pool_size=int(params[\"pool_size\"]),\n",
    "                            kernel_size_2=int(params[\"kernel_size_2\"]),\n",
    "                            num_dense_nodes=num_dense_nodes,\n",
    "                            residual_l2=residual_l2,\n",
    "                            conv_l2=conv_l2,\n",
    "                            fully_l2=fully_l2,\n",
    "                            use_batch_norm=use_batch_norm)\n",
    "\n",
    "    model = wnc.get_model()\n",
    "\n",
    "    training_generator = DataGenerator(partition[\"train\"],\n",
    "                                       labels,\n",
    "                                       **data_gen_params, shuffle=True)\n",
    "    \n",
    "    validation_generator = DataGenerator(partition[\"validation\"],\n",
    "                                         labels,\n",
    "                                         **data_gen_params, shuffle=False)\n",
    "    \n",
    "    test_generator = DataGenerator(partition[\"test\"],\n",
    "                                         labels,\n",
    "                                         **data_gen_params, shuffle=False)\n",
    "    \n",
    "    model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    patience = params[\"early_stopping_patience\"]\n",
    "    callback_list = []\n",
    "    # -1 used to represent no early stopping\n",
    "    if patience != -1:\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "        callback_list.append(early_stopping)\n",
    "\n",
    "    # Train model on dataset\n",
    "    model.fit_generator(generator=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        epochs=epochs,\n",
    "                        callbacks=callback_list,\n",
    "                        verbose=1)\n",
    "    \n",
    "    evaluation = model.evaluate_generator(test_generator)\n",
    "    \n",
    "    val_loss = evaluation[0]\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    return val_loss  # minimize validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oU1PMTWxbA8A"
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZIFbhblcFTD"
   },
   "outputs": [],
   "source": [
    "checkpoint = CheckpointSaver(RESULTS_PATH + \"res_gp_checkpoint.pkl\")\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfd4x0jxsY6S"
   },
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hTA-T_0QsiY2"
   },
   "outputs": [],
   "source": [
    "LOAD_CHECKPOINT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jozj15HsfmA"
   },
   "outputs": [],
   "source": [
    "if LOAD_CHECKPOINT:\n",
    "    res = load(RESULTS_PATH + \"res_gp_checkpoint.pkl\")\n",
    "    x0 = res.x_iters\n",
    "    y0 = res.func_vals\n",
    "    random_starts = 0\n",
    "    \n",
    "else:\n",
    "    x0 = None\n",
    "    y0 = None\n",
    "    random_starts = 5  # default is 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAFCZnjYU36e"
   },
   "source": [
    "### Perform Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8_tpC-DZnyh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,89,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_35/convolution/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_36/convolution/ExpandDims, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/add_147/_2445 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24725_loss/add_147\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-04809eefd325>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m res_gp = gp_minimize(objective, space, x0=x0, y0=y0,\n\u001b[0;32m      2\u001b[0m                      \u001b[0mn_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m130\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_random_starts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_starts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                      random_state=0, callback=callbacks_list, verbose=True)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\optimizer\\gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mnext_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[1;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[0mobjective_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-705814f73f5b>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(**params)\u001b[0m\n\u001b[0;32m     38\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                                   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                                   verbose=1)\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,89,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_35/convolution/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_36/convolution/ExpandDims, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/add_147/_2445 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24725_loss/add_147\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "res_gp = gp_minimize(objective, space, x0=x0, y0=y0,\n",
    "                     n_calls=130, n_random_starts=random_starts,\n",
    "                     random_state=0, callback=callbacks_list, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsCe4ugZt2Yt"
   },
   "source": [
    "### Save gp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lS-st190t2GS"
   },
   "outputs": [],
   "source": [
    "dump(res_gp, RESULTS_PATH + \"res_gp_complete.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEBqFCS9uImJ"
   },
   "source": [
    "### Load gp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "237ErDR_uKsk"
   },
   "outputs": [],
   "source": [
    "res_gp = load(RESULTS_PATH + \"res_gp_complete.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp\n",
    "res_gp = load(RESULTS_PATH + \"res_gp_checkpoint.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDOtEG4rZx-9"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 3\n",
      "number_of_stacks: 2\n",
      "pool_size: 6\n",
      "kernel_size_2: 2\n",
      "early_stopping_patience: 4\n"
     ]
    }
   ],
   "source": [
    "dimensions = ['n_filters', 'kernel_size', 'dilation_depth', 'number_of_stacks',\n",
    "              'pool_size', 'kernel_size_2',\n",
    "              'early_stopping_patience']\n",
    "\n",
    "parameters = res_gp.x\n",
    "for index, parameter in enumerate(parameters):\n",
    "    print(dimensions[index] + \":\", parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest Loss achieved: 0.15\n"
     ]
    }
   ],
   "source": [
    "print(\"Lowest Loss achieved:\", str(round(res_gp.fun, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adapted from skopt.plots.plot_convergence\n",
    "n_calls = len(res_gp.x_iters)\n",
    "mins = [np.min(res_gp.func_vals[:i])\n",
    "        for i in range(1, n_calls + 1)]\n",
    "plt.plot(range(1, n_calls + 1), np.array(mins), marker='.')\n",
    "plt.title(\"Convergence Plot\")\n",
    "plt.ylabel(\"Classification Loss\")\n",
    "plt.xlabel(\"Number of Calls\")\n",
    "plt.grid()\n",
    "plt.savefig(RESULTS_PATH + \"convergence_plot.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(1, n_calls + 1), (np.array(res_gp.func_vals)), marker='x')\n",
    "plt.scatter([np.argmin(res_gp.func_vals)+1], [res_gp.fun],\n",
    "            marker='x', color='red',\n",
    "            label=\"Lowest Loss: \" + str(round(res_gp.fun, 2)))\n",
    "plt.legend(bbox_to_anchor=(0.5,0.35), loc=\"upper left\")\n",
    "plt.ylabel(\"Classification Loss\")\n",
    "plt.xlabel(\"Number of Calls\")\n",
    "plt.grid()\n",
    "plt.title(\"Hyperparameter Search\")\n",
    "plt.savefig(RESULTS_PATH + \"hyperparameter_search.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters Tried:\n",
    "TODO: add rceptive field calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search: 1\n",
      "n_filters: 89\n",
      "kernel_size: 5\n",
      "dilation_depth: 8\n",
      "number_of_stacks: 4\n",
      "pool_size: 8\n",
      "kernel_size_2: 4\n",
      "early_stopping_patience: 0\n",
      " \n",
      "Search: 2\n",
      "n_filters: 37\n",
      "kernel_size: 3\n",
      "dilation_depth: 5\n",
      "number_of_stacks: 3\n",
      "pool_size: 7\n",
      "kernel_size_2: 4\n",
      "early_stopping_patience: 3\n",
      " \n",
      "Search: 3\n",
      "n_filters: 64\n",
      "kernel_size: 4\n",
      "dilation_depth: 5\n",
      "number_of_stacks: 4\n",
      "pool_size: 5\n",
      "kernel_size_2: 7\n",
      "early_stopping_patience: 1\n",
      " \n",
      "Search: 4\n",
      "n_filters: 109\n",
      "kernel_size: 4\n",
      "dilation_depth: 7\n",
      "number_of_stacks: 3\n",
      "pool_size: 7\n",
      "kernel_size_2: 5\n",
      "early_stopping_patience: 3\n",
      " \n",
      "Search: 5\n",
      "n_filters: 42\n",
      "kernel_size: 3\n",
      "dilation_depth: 3\n",
      "number_of_stacks: 3\n",
      "pool_size: 5\n",
      "kernel_size_2: 3\n",
      "early_stopping_patience: 1\n",
      " \n",
      "Search: 6\n",
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 9\n",
      "number_of_stacks: 3\n",
      "pool_size: 10\n",
      "kernel_size_2: 7\n",
      "early_stopping_patience: 4\n",
      " \n",
      "Search: 7\n",
      "n_filters: 110\n",
      "kernel_size: 2\n",
      "dilation_depth: 7\n",
      "number_of_stacks: 3\n",
      "pool_size: 4\n",
      "kernel_size_2: 4\n",
      "early_stopping_patience: 3\n",
      " \n",
      "Search: 8\n",
      "n_filters: 128\n",
      "kernel_size: 3\n",
      "dilation_depth: 2\n",
      "number_of_stacks: 1\n",
      "pool_size: 4\n",
      "kernel_size_2: 8\n",
      "early_stopping_patience: -1\n",
      " \n",
      "Search: 9\n",
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 9\n",
      "number_of_stacks: 3\n",
      "pool_size: 10\n",
      "kernel_size_2: 8\n",
      "early_stopping_patience: 1\n",
      " \n",
      "Search: 10\n",
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 5\n",
      "number_of_stacks: 3\n",
      "pool_size: 7\n",
      "kernel_size_2: 2\n",
      "early_stopping_patience: 4\n",
      " \n",
      "Search: 11\n",
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 3\n",
      "number_of_stacks: 2\n",
      "pool_size: 6\n",
      "kernel_size_2: 2\n",
      "early_stopping_patience: 4\n",
      " \n",
      "Search: 12\n",
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 2\n",
      "number_of_stacks: 1\n",
      "pool_size: 4\n",
      "kernel_size_2: 2\n",
      "early_stopping_patience: 4\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for count, parameters in enumerate(res_gp.x_iters):\n",
    "    print(\"Search:\", count+1)\n",
    "    for index, parameter in enumerate(parameters):\n",
    "        print(dimensions[index] + \":\", parameter)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with parameters before search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_range = (0, 63)\n",
    "data_shape = (3000, 32)\n",
    "\n",
    "activation = 'softmax'\n",
    "\n",
    "epochs = 10  # number of epochs limited to 10 to allow more searches (15 hours per evaluation = 11 searches in one week)\n",
    "batch_size = 16\n",
    "\n",
    "num_dense_nodes = 512\n",
    "\n",
    "residual_l2 = 0.001\n",
    "conv_l2 = 0.001\n",
    "fully_l2 = 0.001\n",
    "use_batch_norm = False\n",
    "\n",
    "# Parameters for data generators\n",
    "data_gen_params = {'dim': data_shape,\n",
    "                   'batch_size': batch_size,\n",
    "                   'n_classes': nb_classes,\n",
    "                   'data_directory': DATA_PATH_NO_MTI,\n",
    "                   'bin_range': bin_range,\n",
    "                   'every_second_cell': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_filters\": 64,\n",
    "    \"kernel_size\": 2,\n",
    "    \"dilation_depth\": 8,\n",
    "    \"number_of_stacks\": 3,\n",
    "    \"pool_size\": 4,\n",
    "    \"kernel_size_2\": 8,\n",
    "    \"early_stopping_patience\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [64, 2, 8, 3, 4, 8, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,64,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropInput-0-VecPermuteNHWCToNCHW-LayoutOptimizer, conv1d_48/convolution/ExpandDims_1, training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0c6f798bc2b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[1;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[0mobjective_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-705814f73f5b>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(**params)\u001b[0m\n\u001b[0;32m     38\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                                   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                                   verbose=1)\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,64,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropInput-0-VecPermuteNHWCToNCHW-LayoutOptimizer, conv1d_48/convolution/ExpandDims_1, training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "loss = objective(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9c7d9083178b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"base_evaluation.pkl\", 'wb') as file:\n",
    "    pickle.dump(loss, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"base_evaluation.pkl\", 'rb') as file:\n",
    "    loss = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Loss: 0.7047507423046598\n"
     ]
    }
   ],
   "source": [
    "print(\"Base Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "12_range_data_model_hyperparameter_search.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
