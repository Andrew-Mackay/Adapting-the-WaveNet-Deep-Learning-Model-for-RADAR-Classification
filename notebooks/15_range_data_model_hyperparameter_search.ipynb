{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znku3TNhZY2m"
   },
   "source": [
    "# Hyperparameter search over range data model\n",
    "\n",
    "Due to the time the model takes to train (over 1 hour per epoch), using a 5 fold cross validation strategy (applied in notebook 8 for the CNN model) would take close to 50 hours per parameter configuration (assuming 10 epochs). Therefore to perform any meaningful search, it would take several weeks.\n",
    "\n",
    "Furthermore, up until now the model has been only evaluated on subject B which has made the model bias towards this subject. To try and adjust for this the test set for the hyperparamter optimization will be taken from all subjects (except C). 20\\% of the data from each subject will be used for validation. The data will be taken in consecutive chunks as there is little variation between two consecutive spectrograms.\n",
    "\n",
    "The following parameters will remain fixed:\n",
    "* Optimizer: 'adam'\n",
    "* Batch size: 32\n",
    "* Number of dense layers: 1\n",
    "* Learning rate: 0.001\n",
    "* Number of dense nodes: 512\n",
    "* L2: 0.001\n",
    "* Batch norm: False\n",
    "\n",
    "Limited to 10 epochs as this takes around 15 hours == 11 evalauations in one week\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZxhO7V0ZHUE"
   },
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGNeUj-JDXhs"
   },
   "outputs": [],
   "source": [
    "# Plot graphs inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwLbqieVYIJt"
   },
   "source": [
    "The following cell is needed for compatibility when using both CoLab and Local Jupyter notebook. It sets the appropriate file path for the data and also installs local packages such as models and data_loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XeU0HtoDXh6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "if path == '/content':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    BASE_PATH = '/content/gdrive/My Drive/Level-4-Project/'\n",
    "    os.chdir('gdrive/My Drive/Level-4-Project/')\n",
    "    \n",
    "elif path == 'D:\\\\Google Drive\\\\Level-4-Project\\\\notebooks':\n",
    "    BASE_PATH = \"D:/Google Drive/Level-4-Project/\"\n",
    "    \n",
    "elif path == \"/export/home/2192793m\":\n",
    "    BASE_PATH = \"/export/home/2192793m/Level-4-Project/\"\n",
    "    \n",
    "    \n",
    "DATA_PATH_MTI = BASE_PATH + 'data/processed/range_FFT/3/MTI_applied/' # not used\n",
    "DATA_PATH_NO_MTI = BASE_PATH + 'data/processed/range_FFT/3/MTI_not_applied/'\n",
    "\n",
    "RESULTS_PATH = BASE_PATH + 'results/range_data_model_hyperparameter_search/'\n",
    "if not os.path.exists(RESULTS_PATH):\n",
    "    os.makedirs(RESULTS_PATH)\n",
    "    \n",
    "MODEL_PATH = BASE_PATH + 'models/range_data_model_hyperparameter_search/'\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QW7Fa5jTCDXo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.layers import Input, Conv1D, Multiply, Add, Activation, AveragePooling1D, Flatten, Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tk_HAyYKYrI8"
   },
   "outputs": [],
   "source": [
    "# needed for CheckpointSaver\n",
    "# https://github.com/scikit-optimize/scikit-optimize/issues/678\n",
    "# ! pip install git+https://github.com/scikit-optimize/scikit-optimize/ \n",
    "    \n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.callbacks import CheckpointSaver\n",
    "from skopt import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vxIKU3-fTUy7"
   },
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sj59Pvxv5CX9"
   },
   "outputs": [],
   "source": [
    "# Load in data dictionary.\n",
    "# This does not load in any actual data,\n",
    "# just the dictionary with the names of the files and their associated labels\n",
    "with open(DATA_PATH_NO_MTI + \"index.pkl\", \"rb\") as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYNFp-60ZFe2"
   },
   "outputs": [],
   "source": [
    "# Remove user C as this user is reserved for the test set\n",
    "try:\n",
    "    del data[\"C\"]\n",
    "except KeyError:\n",
    "    print (\"Key 'C' not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQIwQ8EACdIQ"
   },
   "outputs": [],
   "source": [
    "def convert_label_to_int(label):\n",
    "    \"\"\"\n",
    "    Convert each label to an integer\n",
    "    :param label: action label to convert\n",
    "    :return: integer representation of the action\n",
    "    \"\"\"\n",
    "    if label == \"walking\":\n",
    "        return 0\n",
    "    if label == \"pushing\":\n",
    "        return 1\n",
    "    if label == \"sitting\":\n",
    "        return 2\n",
    "    if label == \"pulling\":\n",
    "        return 3\n",
    "    if label == \"circling\":\n",
    "        return 4\n",
    "    if label == \"clapping\":\n",
    "        return 5\n",
    "    if label == \"bending\":\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the model has only been validated on subject B. This has likely introduced bias into the model. To combat this, the hyperparameter search will using 20% of the data from every subject for validation. To do this it will be made sure that the data is selected in consecutive chunks to negate the issue of consecutive range profiels being almost identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "partition = {'train': [], 'validation': []}  # contains list of training and validation ID's\n",
    "\n",
    "for user_letter, actions in data.items():\n",
    "    for action, results in actions.items():\n",
    "        for result in results:\n",
    "            res = np.array(result)\n",
    "            # Split into 5 folds then take 1 fold for 20%\n",
    "            split_actions = np.array_split(res, 5)\n",
    "            for fold in range(5):\n",
    "                data = split_actions[fold]\n",
    "                if fold == 0:\n",
    "                    for row in data:\n",
    "                        partition[\"validation\"].append(row)\n",
    "                        labels[row] = convert_label_to_int(action)\n",
    "\n",
    "                else:\n",
    "                    for row in data:\n",
    "                        partition[\"train\"].append(row)\n",
    "                        labels[row] = convert_label_to_int(action)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4fd5mwu11f9"
   },
   "outputs": [],
   "source": [
    "target_names = [\"walking\", \"pushing\", \"sitting\", \"pulling\", \"circling\", \"clapping\", \"bending\"]\n",
    "nb_classes = len(target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ah1RGSSTYfQ"
   },
   "source": [
    "## DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gOcp1JeSop2"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Based on code from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "    Keras data generator\n",
    "    \"\"\"\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(3000),\n",
    "                 n_classes=7, shuffle=False, data_directory='data/',\n",
    "                 bin_range=(0,60), take_average=False, every_second_cell=False):\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        :param list_IDs: IDs of files to train with\n",
    "        :param labels: index to get associated label from file id\n",
    "        :param batch_size: batch size\n",
    "        :param dim: dimension of the input data\n",
    "        :param n_classes: number of classes\n",
    "        :param shuffle: shuffle data after each epoch toggle\n",
    "        :param data_directory: path to the data\n",
    "        :param bin_range: which range bins to use\n",
    "        :param take_average: use the average of all cells toggle\n",
    "        :param every_second_cell: use every second cell toggle\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.data_directory = data_directory\n",
    "        self.bin_range=bin_range\n",
    "        self.take_average = take_average\n",
    "        self.every_second_cell = every_second_cell\n",
    "        self.indexes = None\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\"\"\"\n",
    "\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size samples\"\"\"\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            if self.take_average:\n",
    "                X[i,] = abs(np.average(np.load(self.data_directory + ID), axis=1)[:,np.newaxis])\n",
    "                \n",
    "            elif self.every_second_cell:\n",
    "                X[i,] = abs(np.load(self.data_directory + ID))[:,::2]\n",
    "                \n",
    "            else:\n",
    "                X[i,] = abs(np.load(self.data_directory + ID))[:,self.bin_range[0]:self.bin_range[1]]\n",
    "                \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3MQ0FACt9aa"
   },
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__yOu1WH_iBb"
   },
   "outputs": [],
   "source": [
    "def visualize_results(csvlog_path, metric, save=False, save_file_name=\"\"):\n",
    "    \"\"\"\n",
    "    plot graph of training and validation results\n",
    "    :param csvlog_path: path where results file is located\n",
    "    :param metric: metric to plot\n",
    "    :param save: save the graph toggle\n",
    "    :param save_file_name: name of file to save\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(RESULTS_PATH + csvlog_path)\n",
    "    epoch = df['epoch'] +1\n",
    "    train = df[metric]\n",
    "    val = df['val_' + metric]\n",
    "    plt.figure()\n",
    "    plt.plot(epoch, train, label='train')\n",
    "    plt.plot(epoch, val, label='val')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    if save:\n",
    "        plt.savefig(RESULTS_PATH + save_file_name, format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88LpWZJeTfj2"
   },
   "source": [
    "## Model: Wavenet model adapted based on interpretation from Wavenet Paper\n",
    "\n",
    "Keras implementation of wavenet model taken from https://github.com/basveeling/wavenet and https://github.com/mjpyeon/wavenet-classifier\n",
    "\n",
    "This model has then been adapted to the classification task based on the intrustions from the paper \"WAVENET: A GENERATIVE MODEL FOR RAW AUDIO\" (https://arxiv.org/pdf/1609.03499.pdf)\n",
    "\n",
    "Specifically:\n",
    "\"For this task we added a mean-pooling layer after the dilated convolutions that aggregated the activations to coarser frames spanning 10 milliseconds (160× downsampling).  The pooling layer was followed by a few non-causal convolutions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNetClassifier:\n",
    "    \"\"\"\n",
    "    Keras implementation of the WaveNet model based on implementations by\n",
    "    https://github.com/basveeling/wavenet and https://github.com/mjpyeon/wavenet-classifier\n",
    "    \n",
    "    This model has then been adapted to the classification task based on the\n",
    "    instructions from the paper \"WAVENET: A GENERATIVE MODEL FOR RAW AUDIO\" \n",
    "    (https://arxiv.org/pdf/1609.03499.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, output_shape, kernel_size=2, dilation_depth=9, nb_stacks=1, nb_filters=40,\n",
    "                 pool_size=80, kernel_size_2=100, use_skip_connections=True, causal=True, residual_l2=0.001,\n",
    "                 conv_l2=0.001, fully_l2=0.001, use_batch_norm=True, num_dense_nodes=512):\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        :param input_shape: input shape of the data\n",
    "        :param output_shape: number of classes\n",
    "        :param kernel_size: kernel size for conv layers in stacks\n",
    "        :param dilation_depth: number of dilated CNN layers per stack\n",
    "        :param nb_stacks: number of stacks of dilated blocks\n",
    "        :param nb_filters: number of filters for each conv layer\n",
    "        :param pool_size: pooling size for average pooling layer\n",
    "        :param kernel_size_2: kernel size for conv layers after stacks\n",
    "        :param use_skip_connections: use skip connections toggle\n",
    "        :param causal: use causal variant of model toggle\n",
    "        :param residual_l2: value for l2 regularization in residual block\n",
    "        :param conv_l2: l2 value for stack of standard conv layers\n",
    "        :param fully_l2: l2 value for fully connected layer\n",
    "        :param use_batch_norm: use batch norm toggle\n",
    "        :param num_dense_nodes: number of dense nodes in fully connected layer\n",
    "        \"\"\"\n",
    "        self.activation = 'softmax'\n",
    "        self.pool_size = pool_size\n",
    "        self.kernel_size_2 = kernel_size_2 # kernel size for later conV 1d (not dilated)\n",
    "        self.nb_stacks = nb_stacks\n",
    "        self.kernel_size = kernel_size # kernel size for dilated  layers\n",
    "        self.dilation_depth = dilation_depth\n",
    "        self.nb_filters = nb_filters\n",
    "        self.residual_l2 = residual_l2 # l2 value for residual layers\n",
    "        self.conv_l2 = conv_l2 # l2 value for stack of standard conv layers\n",
    "        self.fully_l2 = fully_l2 # l2 value for fully connected layer\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.num_dense_nodes = num_dense_nodes\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        if causal:\n",
    "            self.padding = 'causal'\n",
    "        else:\n",
    "            self.padding = 'same'\n",
    "\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def residual_block(self, x, i, stack_nb):\n",
    "        \"\"\"\n",
    "        add a residual block\n",
    "        :param x: current model\n",
    "        :param i: dilation rate modifier\n",
    "        :param stack_nb: stack number\n",
    "        :return: model with residual block added, model for skip connection link\n",
    "        \"\"\"\n",
    "        original_x = x\n",
    "        tanh_out = Conv1D(self.nb_filters, self.kernel_size, dilation_rate=2 ** i, padding=self.padding,\n",
    "                          name='dilated_conv_%d_tanh_s%d' % (2 ** i, stack_nb), activation='tanh',\n",
    "                          kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        sigm_out = Conv1D(self.nb_filters, self.kernel_size, dilation_rate=2 ** i, padding=self.padding,\n",
    "                          name='dilated_conv_%d_sigm_s%d' % (2 ** i, stack_nb), activation='sigmoid',\n",
    "                          kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        x = Multiply(name='gated_activation_%d_s%d' % (i, stack_nb))([tanh_out, sigm_out])\n",
    "\n",
    "        res_x = Conv1D(self.nb_filters, 1, padding='same', kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        skip_x = Conv1D(self.nb_filters, 1, padding='same', kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        res_x = Add()([original_x, res_x])\n",
    "        return res_x, skip_x\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Build the model\n",
    "        :return: keras model\n",
    "        \"\"\"\n",
    "        input_layer = Input(shape=self.input_shape, name='input_part')\n",
    "        out = input_layer\n",
    "        skip_connections = []\n",
    "        out = Conv1D(self.nb_filters, self.kernel_size,\n",
    "                     dilation_rate=1,\n",
    "                     padding=self.padding,\n",
    "                     name='initial_causal_conv'\n",
    "                     )(out)\n",
    "        for stack_nb in range(self.nb_stacks):\n",
    "            for i in range(0, self.dilation_depth + 1):\n",
    "                out, skip_out = self.residual_block(out, i, stack_nb)\n",
    "                skip_connections.append(skip_out)\n",
    "\n",
    "        if self.use_skip_connections:\n",
    "            out = Add()(skip_connections)\n",
    "        out = Activation('relu')(out)\n",
    "        # added a mean-pooling layer after the dilated convolutions that aggregated the activations to coarser frames\n",
    "        # spanning 10 milliseconds (160× downsampling)\n",
    "        # mean pooling layer adjust pool_size_1 to change downsampling\n",
    "                \n",
    "        out = AveragePooling1D(self.pool_size, padding='same', name='mean_pooling_layer_downsampling')(out)\n",
    "\n",
    "        # few non-causal convolutions\n",
    "        # In notebooks 11, 12 and 13 self.kernel_size_2 was incorrectly represented as pooling sizes.\n",
    "        out = Conv1D(self.nb_filters, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "        \n",
    "        out = Conv1D(self.nb_filters, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "        \n",
    "        out = Conv1D(self.output_shape, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "        \n",
    "        out = Conv1D(self.output_shape, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "\n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "            \n",
    "        out = Flatten()(out)\n",
    "        out = Dense(num_dense_nodes, activation='relu', kernel_regularizer=l2(self.fully_l2))(out)\n",
    "        out = Dense(self.output_shape, activation='softmax')(out)\n",
    "\n",
    "        return Model(input_layer, out)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def get_summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def get_receptive_field(self):\n",
    "        \"\"\"\n",
    "        Compute the receptive field of the model\n",
    "        :return: receptive field\n",
    "        \"\"\"\n",
    "        k = self.kernel_size\n",
    "        n = self.dilation_depth\n",
    "        s = self.nb_stacks\n",
    "        r_s = k + (2*(k-1)*((2**(n-1))-1))  # receptive field for one stack\n",
    "        return (s*r_s) - (s-1)  # total receptive field for 's' number of stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhFcRSbwZCCw"
   },
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DeW2AmQ2ZGFC"
   },
   "source": [
    "### Fixed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxXVIaedsPxK"
   },
   "outputs": [],
   "source": [
    "bin_range = (0, 63)\n",
    "data_shape = (3000, 32)\n",
    "\n",
    "activation = 'softmax'\n",
    "\n",
    "epochs = 10  # number of epochs limited to 10 to allow more searches (15 hours per evaluation = 11 searches in one week)\n",
    "batch_size = 16\n",
    "\n",
    "num_dense_nodes = 512\n",
    "\n",
    "residual_l2 = 0.001\n",
    "conv_l2 = 0.001\n",
    "fully_l2 = 0.001\n",
    "use_batch_norm = False\n",
    "\n",
    "# Parameters for data generators\n",
    "data_gen_params = {'dim': data_shape,\n",
    "                   'batch_size': batch_size,\n",
    "                   'n_classes': nb_classes,\n",
    "                   'data_directory': DATA_PATH_NO_MTI,\n",
    "                   'bin_range': bin_range,\n",
    "                   'every_second_cell': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CsyeQlBQZUle"
   },
   "source": [
    "### Parameters to Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAqGS4oWZXE-"
   },
   "outputs": [],
   "source": [
    "space = [\n",
    "    Integer(32, 128, name=\"n_filters\"),\n",
    "    Integer(2, 5, name=\"kernel_size\"),\n",
    "    Integer(2, 9, name=\"dilation_depth\"),\n",
    "    Integer(1, 4, name=\"number_of_stacks\"),\n",
    "    Integer(4, 10, name=\"pool_size\"),\n",
    "    Integer(2, 8, name=\"kernel_size_2\"),\n",
    "    Integer(-1, 4, name='early_stopping_patience')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmvMHPqiZP6x"
   },
   "source": [
    "### Objective Function to Minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzWFM-axZS2V"
   },
   "outputs": [],
   "source": [
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    \"\"\"\n",
    "    Objective function to be minimised during search. Returns validation loss\n",
    "    :return: validation loss\n",
    "    \"\"\"\n",
    "    wnc = WaveNetClassifier((data_shape), (nb_classes),\n",
    "                            kernel_size=int(params[\"kernel_size\"]),\n",
    "                            dilation_depth=params[\"dilation_depth\"],\n",
    "                            nb_stacks=params[\"number_of_stacks\"],\n",
    "                            nb_filters=params[\"n_filters\"],\n",
    "                            pool_size=int(params[\"pool_size\"]),\n",
    "                            kernel_size_2=int(params[\"kernel_size_2\"]),\n",
    "                            num_dense_nodes=num_dense_nodes,\n",
    "                            residual_l2=residual_l2,\n",
    "                            conv_l2=conv_l2,\n",
    "                            fully_l2=fully_l2,\n",
    "                            use_batch_norm=use_batch_norm)\n",
    "\n",
    "    model = wnc.get_model()\n",
    "\n",
    "    training_generator = DataGenerator(partition[\"train\"],\n",
    "                                       labels,\n",
    "                                       **data_gen_params, shuffle=True)\n",
    "    \n",
    "    validation_generator = DataGenerator(partition[\"validation\"],\n",
    "                                         labels,\n",
    "                                         **data_gen_params, shuffle=False)\n",
    "\n",
    "    model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    patience = params[\"early_stopping_patience\"]\n",
    "    callback_list = []\n",
    "    # -1 used to represent no early stopping\n",
    "    if patience != -1:\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "        callback_list.append(early_stopping)\n",
    "\n",
    "    # Train model on dataset\n",
    "    history = model.fit_generator(generator=training_generator,\n",
    "                                  validation_data=validation_generator,\n",
    "                                  epochs=epochs,\n",
    "                                  callbacks=callback_list,\n",
    "                                  verbose=1)\n",
    "    val_loss = history.history[\"val_loss\"][-1]\n",
    "    K.clear_session()\n",
    "\n",
    "    return val_loss  # minimize validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oU1PMTWxbA8A"
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZIFbhblcFTD"
   },
   "outputs": [],
   "source": [
    "checkpoint = CheckpointSaver(RESULTS_PATH + \"res_gp_checkpoint.pkl\")\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfd4x0jxsY6S"
   },
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hTA-T_0QsiY2"
   },
   "outputs": [],
   "source": [
    "LOAD_CHECKPOINT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jozj15HsfmA"
   },
   "outputs": [],
   "source": [
    "if LOAD_CHECKPOINT:\n",
    "    res = load(RESULTS_PATH + \"res_gp_checkpoint.pkl\")\n",
    "    x0 = res.x_iters\n",
    "    y0 = res.func_vals\n",
    "    random_starts = 0\n",
    "    \n",
    "else:\n",
    "    x0 = None\n",
    "    y0 = None\n",
    "    random_starts = 5  # default is 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAFCZnjYU36e"
   },
   "source": [
    "### Perform Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8_tpC-DZnyh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,89,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_35/convolution/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_36/convolution/ExpandDims, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/add_147/_2445 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24725_loss/add_147\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-04809eefd325>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m res_gp = gp_minimize(objective, space, x0=x0, y0=y0,\n\u001b[0;32m      2\u001b[0m                      \u001b[0mn_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m130\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_random_starts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_starts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                      random_state=0, callback=callbacks_list, verbose=True)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\optimizer\\gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mnext_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[1;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[0mobjective_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-705814f73f5b>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(**params)\u001b[0m\n\u001b[0;32m     38\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                                   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                                   verbose=1)\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,89,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_35/convolution/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_36/convolution/ExpandDims, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/add_147/_2445 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24725_loss/add_147\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "res_gp = gp_minimize(objective, space, x0=x0, y0=y0,\n",
    "                     n_calls=130, n_random_starts=random_starts,\n",
    "                     random_state=0, callback=callbacks_list, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsCe4ugZt2Yt"
   },
   "source": [
    "### Save gp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lS-st190t2GS"
   },
   "outputs": [],
   "source": [
    "dump(res_gp, RESULTS_PATH + \"res_gp_complete.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEBqFCS9uImJ"
   },
   "source": [
    "### Load gp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "237ErDR_uKsk"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Google Drive/Level-4-Project/results/range_data_model_hyperparameter_search/res_gp_complete.pkl'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-81a4a2a29953>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres_gp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRESULTS_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"res_gp_complete.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mReconstructed\u001b[0m \u001b[0mOptimizeResult\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \"\"\"\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Google Drive/Level-4-Project/results/range_data_model_hyperparameter_search/res_gp_complete.pkl'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "res_gp = load(RESULTS_PATH + \"res_gp_complete.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp\n",
    "res_gp = load(RESULTS_PATH + \"res_gp_checkpoint.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDOtEG4rZx-9"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 3\n",
      "number_of_stacks: 2\n",
      "pool_size: 6\n",
      "kernel_size_2: 2\n",
      "early_stopping_patience: 4\n"
     ]
    }
   ],
   "source": [
    "dimensions = ['n_filters', 'kernel_size', 'dilation_depth', 'number_of_stacks',\n",
    "              'pool_size', 'kernel_size_2',\n",
    "              'early_stopping_patience']\n",
    "\n",
    "parameters = res_gp.x\n",
    "for index, parameter in enumerate(parameters):\n",
    "    print(dimensions[index] + \":\", parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest Loss achieved: 0.15\n"
     ]
    }
   ],
   "source": [
    "print(\"Lowest Loss achieved:\", str(round(res_gp.fun, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcXFWZ//HPt7ds3SFkoRsIJATSDYgsJkAABxIEBxgFRx0lCm5gRgWXcZxRZxTX3wzI6OAMKCIiOgIZBkGBwQGUtCgYloBsgYQQCISQBJIA6ezd/fz+qNtN0fRSSer27ar6vl+veqXuvafueU4I9dQ9595zFBGYmZkBVGUdgJmZDR1OCmZm1s1JwczMujkpmJlZNycFMzPr5qRgZmbdnBTMKoCkKyV9O+s4bOhzUrDMSfqApPsltUl6QdJvJL0167hKjaRWSZuTv8eXJF0vafcdOE9I2i+NGG3oc1KwTEn6PHAR8C9AI7A38APgtCzjyiepJusYtsO5EVEPNANjgH/POB4rMU4KlhlJuwDfBM6JiOsjYkNEbIuImyLiH5IywyRdJGlF8rpI0rDk2ExJyyX9vaTVyVXGR5NjMyStlFSdV99fS3o4eV8l6UuSnpK0RtK1ksYmxyYnv5bPkvQscEey/0OSliXlvyrpGUknbMf5Pizp2eRX/D/nxVUt6Z+Sz66XtEDSXsmx/SXdLmmtpEWS3lfI321ErAV+CRzUx9/9xyUtSc57o6Q9kv13JkUeSq443l9IfVY+nBQsS0cBw4Eb+inzz8AM4FDgEOAI4Ct5x5uAXYA9gbOASyTtGhHzgQ3A8XllPwBcnbz/DPAu4DhgD2AdcEmPuo8DDgD+UtKB5K5gPgjsnldnl0LO91agBXgbcJ6kA5L9nwdmA6cAo4GPARsljQJuT2LeLSnzA0lv6vNvKyFpPPAe4MFejh0P/CvwvqQty4C5ABFxbFLskIioj4j/HqguKzMR4ZdfmbzIfcGuHKDMU8Apedt/CTyTvJ8JbAJq8o6vBmYk778NXJG8byCXJCYl248Db8v73O7ANqAGmAwEMCXv+HnANXnbI4GtwAnbcb6JecfvBU5P3i8CTuul7e8H/tBj34+Ar/Xxd9UKbAReBp4HrgImJMeuBL6dvP8J8J28z9UnsU5OtgPYL+t/H35l8yqlvlIrP2uA8ZJqIqK9jzJ7kPsl22VZsq/7HD0+u5HclxzkfmHfLemTwLuBByKi61yTgBskdeZ9toPcuEaX53rE0b0dERslrck7Xsj5VvYR517kkl9Pk4AjJb2ct68G+K9eynb5TERc3s9xyLXlga6NiGhL2rIn8MwAn7Uy5+4jy9KfgM3kul36soLcl2OXvZN9A4qIheSSyMm8vusIcl/wJ0fEmLzX8Ih4Pv8Uee9fACZ2bUgaAYzbzvP15Tlg3z72/77HOesj4pMFnLM/r/s7TbqpxpG7urAK56RgmYmIV8h1y1wi6V2SRkqqlXSypO8kxa4BviJpQtJPfh7wi+2o5mpy/f3HAv+Tt/9S4P9JmgSQnL+/O56uA94p6WhJdcA3AO3E+fJdDnxL0lTlHCxpHHAz0CzpzOTvpVbS4XljETvqauCjkg5NBu3/BbgnIp5Jjq8CpuxkHVainBQsUxHxPXIDrV8BXiT36/hc4FdJkW8D9wMPA4+Q6/bYnoewriE39nBHRLyUt//7wI3AbZLWA/OBI/uJ8zHg0+QGZF8A1pMbv9iyI+fr4XvAtcBtwKvk+vxHRMR64O3A6eR+3a8ELgCGFXjevtryO+Cr5O5OeoHcVcrpeUW+DvxM0suF3u1k5UMRXmTHbHtJqic3oDs1Ip7OOh6zYvGVglmBJL0z6eIaBfwbuSuXZ7KNyqy4nBTMCncauW6cFcBUcreU+lLbyoq7j8zMrJuvFMzMrFtqD69JugJ4B7A6InqdfyUpdzi5OzXeHxHXDXTe8ePHx+TJk4sWZ5o2bNjAqFGjsg4jFeXcNijv9rltpWtn2rdgwYKXImLCQOXSfKL5SuBi4Od9FUgmK7sAuLXQk06ePJn7779/p4MbDK2trcycOTPrMFJRzm2D8m6f21a6dqZ9kpYNXCrF7qOIuBNYO0CxT5O7V3p1WnGYmVnhUh1oljQZuLm37iNJe5J7svJ4cg/r3NxX95GkOcAcgMbGxmlz585NK+Siamtro76+fuCCJaic2wbl3T63rXTtTPtmzZq1ICKmD1QuywnxLgK+GBEdkvotGBGXAZcBTJ8+PUrl8rCcL2XLuW1Q3u1z20rXYLQvy6QwHZibJITxwCmS2iPiV/1/zMzM0pJZUoiIfbreS7qSXPeRE4KZWYbSvCW1ayKy8ZKWA18DagEi4tK06jUzsx2XWlKIiNnbUfYjacXRZcGydcxfuoYZU8YxbdKuaVdnZlaSKmLltQXL1vGBH89na3snw2qquOrjM5wYzMx6URHTXMxfuoat7Z0EsLWjk/lL1wz4GTOzSlQRSWHGlHHU1eSaWl0lZkwZN8AnzMwqU0UkhWmTduWqs4+ktlqceGCju47MzPpQEUkBYPrksRy4xy6s27At61DMzIasikkKAC2N9SxetT7rMMzMhqzKSgpNo1mzYSsvtW0ZuLCZWQWqrKTQ2ADA4pW+WjAz601FJYXmptzsgovchWRm1quKSgoT6oex68haFvlKwcysVxWVFCTR3NjgKwUzsz5UVFIA2L+pgcUr15Pm4kJmZqWq4pJCc1MDG7Z28PzLm7IOxcxsyKm4pNB9B5K7kMzM3qDiksLUJCk84cFmM7M3qLiksMuIWnbfZbifVTAz60XFJQWAlqYGFq1qyzoMM7MhpzKTQmMDT61uo72jM+tQzMyGlIpMCs2NDWzt6OSZNRuzDsXMbEipyKTQ0pQbbPaTzWZmr1eRSWG/3eqpkudAMjPrqSKTwvDaaiaPG+U7kMzMeqjIpAC5cQU/wGZm9nqVmxSaGnhmzQY2b+vIOhQzsyEjtaQg6QpJqyU92sfxD0p6OHndLemQtGLpTUtjA50BS1b7eQUzsy5pXilcCZzUz/GngeMi4mDgW8BlKcbyBi1dC+54XMHMrFtNWieOiDslTe7n+N15m/OBiWnF0pvJ40ZRV13lcQUzszxKc12BJCncHBEHDVDuC8D+EXF2H8fnAHMAGhsbp82dO7co8X31rk3sOkx8fvrwopyvp7a2Nurr61M5d9bKuW1Q3u1z20rXzrRv1qxZCyJi+kDlUrtSKJSkWcBZwFv7KhMRl5F0L02fPj1mzpxZlLqnrXyQe59eS7HO11Nra2tq585aObcNyrt9blvpGoz2ZXr3kaSDgcuB0yJizWDX39zUwIpXNvPq5m2DXbWZ2ZCUWVKQtDdwPXBmRCzOIobuBXc82GxmBqTYfSTpGmAmMF7ScuBrQC1ARFwKnAeMA34gCaC9kP6uYmpOksKiVeuZPnnsYFZtZjYkpXn30ewBjp8N9DqwPFgm7jqCUXXVvlIwM0tU7BPNAJJobmrwxHhmZomKTgqQG1dYtHI9ad6aa2ZWKio+KTQ3NrBu4zZebNuSdShmZpmr+KTQteDO4pWeA8nMzEmh6bU7kMzMKl3FJ4Xx9cMYN6rOdyCZmeGkAOTGFXylYGbmpADkupAWr1pPZ6fvQDKzyuakQO5KYePWDp5/eVPWoZiZZcpJgbzBZo8rmFmFc1IAmhuTVdg8rmBmFc5JAWgYXsueY0Z4FTYzq3hOConmxnp3H5lZxXNSSDQ3NfDUi21s6+jMOhQzs8w4KST2b2pgW0fwzEsbsg7FzCwzTgqJ/AV3zMwqlZNCYt8J9VTJS3OaWWVzUkgMr61m8vhRvlIws4rmpJCna8EdM7NK5aSQp6WpgWVrN7Jpa0fWoZiZZcJJIU9LYwMRsGS1F9wxs8rkpJCn2QvumFmFc1LIM2nsSOpqqjzdhZlVrO1KCpKqJI0usOwVklZLerSP45L0H5KWSHpY0lu2J5Y01FRXsd+Eep7wYLOZVagBk4KkqyWNljQKWAgskvQPBZz7SuCkfo6fDExNXnOAHxZwztS1NDX4WQUzq1iFXCkcGBGvAu8CbgH2Bs4c6EMRcSewtp8ipwE/j5z5wBhJuxcQT6pamhpY+epmXtm4LetQzMwGXSFJoVZSLbmk8OuI2AYUY93KPYHn8raXJ/sy1ZJMd7F4ta8WzKzy1BRQ5kfAM8BDwJ2SJgGvFqFu9bKv12QjaQ65LiYaGxtpbW0tQvW9W7spN0vqTXcuYMMztTt1rra2tlRjzVI5tw3Ku31uW+kalPZFxHa/gJoCy00GHu3j2I+A2Xnbi4DdBzrntGnTIk2dnZ3xpvP+L75ywyM7fa558+btfEBDVDm3LaK82+e2la6daR9wfxTwvV3IQPNnk4FmSfqJpAeA44uQj24EPpScdwbwSkS8UITz7hRJuQV3fFuqmVWgQsYUPha5gea3AxOAjwLnD/QhSdcAfwJaJC2XdJakT0j6RFLkFmApsAT4MfCpHWlAGlqaRrN41fquKxgzs4pRyJhCV9//KcBPI+IhSb2NB7xORMwe4HgA5xRQ/6Braaznmnu38eL6Lew2enjW4ZiZDZpCrhQWSLqNXFK4VVIDUNZrVnq6CzOrVIUkhbOALwGHR8RGoI5cF1LZ6rot1dNom1mlGbD7KCI6JU0EPpD0Gv0+Im5KPbIMjasfxvj6OicFM6s4hdx9dD7wWXJTXCwEPiPpX9MOLGstTQ2eGM/MKk4h3UenACdGxBURcQW5+Yz+Kt2wstfc2MDiVW10dvoOJDOrHIXOkjom7/0uaQQy1LQ0NrBpWwfL123KOhQzs0FTyC2p/wo8KGkeudtTjwW+nGpUQ0D+HUh7jxuZcTRmZoNjwCuFiLgGmAFcn7yOAu5MOa7MNXffgVSMaZ7MzEpDIVcKJNNP3Ni1LelZclNol636YTVM3HUEi1Z5vWYzqxw7uhzngE80l4OWRi+4Y2aVZUeTQkXcktPc1MBTL7axtb2sH+A2M+vWZ/eRpP+k9y9/8fq7kcpWS2MD7Z3BM2s2dI8xmJmVs/7GFO7fwWNloysRPLFyvZOCmVWEPpNCRPxsMAMZivbdbRTVVcqNKxySdTRmZunb0TGFijCsppp9xo/ybKlmVjGcFAbQ0ug5kMyscjgpDKC5sYFn125k49b2rEMxM0vdgA+vSZoAfByYnF8+Ij6WXlhDR0tTPRHw5Ko2DtmrIm66MrMKVsgTzb8G/gD8FuhIN5yhp3u6i1XrnRTMrOwVkhRGRsQXU49kiJo0bhTDaqr8ZLOZVYRCxhRulnRK6pEMUdVVYmpjve9AMrOKUEhS+Cy5xLBZ0vrkVVFThzb7DiQzqxCFTJ3dEBFVETE8ed8QEaMHI7ihoqWxgVWvbuHljVuzDsXMLFUFTZ0t6VRyi+sAtEbEzemFNPR0L7izcj1HThmXcTRmZukZ8EpB0vnkupAWJq/PJvsGJOkkSYskLZH0pV6O7y1pnqQHJT08VMcu9k+SgruQzKzcFXKlcApwaER0Akj6GfAg8IYv+XySqoFLgBOB5cB9km6MiIV5xb4CXBsRP5R0IHALuechhpSm0cNpGF7jwWYzK3uFPtGcf4P+LgV+5ghgSUQsjYitwFzgtB5lAugan9gFWFHguQeVpGTBHa/CZmblTRH9r5cjaTZwPjCP3FoKxwJfjoi5A3zuvcBJEXF2sn0mcGREnJtXZnfgNmBXYBRwQkQs6OVcc4A5AI2NjdPmzu236lRc+dgW7lvZzsXHj0QqbOG5trY26uvrU44sG+XcNijv9rltpWtn2jdr1qwFETF9oHIDdh9FxDWSWoHDySWFL0bEygJi6O2bs2cGmg1cGRHflXQU8F+SDurqqsqL4TLgMoDp06fHzJkzC6i+uJbVPUPrjY9xwFuOommX4QV9prW1lSxiHQzl3DYo7/a5baVrMNrXZ/eRpP2TP98C7E5uXOA5YI9k30CWA3vlbU/kjd1DZwHXAkTEn4DhwPhCgx9MLU2vTXdhZlau+rtS+Dy5Lpvv9nIsgOMHOPd9wFRJ+wDPA6cDH+hR5lngbcCVkg4glxReLCDuQdc1B9Liles5rnlCxtGYmaWjv5XX5iRvT46IzfnHJA3YfxIR7ZLOBW4FqoErIuIxSd8E7o+IG4G/B34s6e/IJZqPxECDHBkZO6qOCQ3DfKVgZmWtkFtS7wZ6dhf1tu8NIuIWcreZ5u87L+/9QuCYAmIYErzgjpmVuz6TgqQmYE9ghKTDeG3geDQwchBiG3KaGxu4+t5ldHQG1VWF3YFkZlZK+rtS+EvgI+QGiL+Xt3898E8pxjRk7d/UwOZtnTy3diOTx4/KOhwzs6Lrb0zhZ8DPJL0nIn45iDENWc15dyA5KZhZOSrkOYVfSvor4E3k7g7q2v/NNAMbiqbulntoZPHK9fzlm5oyjsbMrPgKmRDvUuD9wKfJjSv8DTAp5biGpFHDathr7AjfgWRmZauQuY+OjogPAesi4hvAUbz+obSK0tLYwCIvzWlmZaqQpLAp+XOjpD2AbcA+6YU0tLU0NfD0SxvY0t6RdShmZkVX6BrNY4ALgQeAZ8jNeFqRmhsbaO8Mnn5pQ9ahmJkVXSEDzd9K3v5S0s3A8Ih4Jd2whq6WvFXY9m+qqFVJzawCFDLQfE5ypUBEbAGqJH0q9ciGqCnj66mpkp9sNrOyVEj30ccj4uWujYhYB3w8vZCGtrqaKvYZP4pFXnDHzMpQIUmhSnmryiTLbNalF9LQ19zUwKJVr2YdhplZ0RWSFG4FrpX0NknHA9cA/5duWEPb/o0NPLd2Exu2tGcdiplZURWSFL4I3AF8EjgH+B3wj2kGNdR1TXfx5Gp3IZlZeSnk7qNO4IfJy8g9wAa56S4O3WtMxtGYmRVPf1NnXxsR75P0CG9cW5mIODjVyIawvcaOZHhtlae7MLOy09+VwueSP98xGIGUkuoqMXU3T3dhZuWnvzGFm5M/vx0Ry3q+BiO4oaylqcFXCmZWdvq7UqiT9GHgaEnv7nkwIq5PL6yhr6WxgesWLGfthq2MHVXRd+iaWRnpLyl8AvggMAZ4Z49jAVR0Uui6A2nxqvXMmDIu42jMzIqjv5XX/gj8UdL9EfGTQYypJHTfgeSkYGZlpL+7j46PiDuAde4+eqPG0cMYPbyGJzzYbGZlpL/uo+PIPbTWs+sI3H2EJPZvGs1iJwUzKyP9dR99Lfnzo4MXTmlpbqrn139eQUSQNz2UmVnJKmTq7M9KGq2cyyU9IOnthZxc0kmSFklaIulLfZR5n6SFkh6TdPX2NiBLLY0NrN/czspXN2cdiplZURQy99HHIuJV4O3AbsBHgfMH+lAym+olwMnAgcBsSQf2KDMV+DJwTES8idcemCsJzY2vLbhjZlYOCkkKXf0ipwA/jYiH8vb15whgSUQsjYit5JbwPK1HmY8DlyRrNBARqwsLe2jIX4XNzKwcDDghHrBA0m3APsCXJTUAnQV8bk/gubzt5cCRPco0A0i6C6gGvh4Rb5iWW9IcYA5AY2Mjra2tBVQ/OMYME3c+tISWeO4Nx9ra2oZUrMVUzm2D8m6f21a6BqN9hSSFs4BDgaURsVHSWHJdSAPp7Wqi58R6NcBUYCYwEfiDpIPyV3oDiIjLgMsApk+fHjNnziyg+sHx5qfuYd3Grcyc+RdvONba2spQirWYyrltUN7tc9tK12C0r5Duo6OARRHxsqQzgK8ArxTwueXAXnnbE4EVvZT5dURsi4ingUXkkkTJaGls4MlVbXR0vmEiWTOzklNIUvghsFHSIeQW11kG/LyAz90HTJW0j6Q64HTgxh5lfgXMApA0nlx30tICYx8Smpsa2NLeybNrN2YdipnZTiskKbRHRJAbJP5+RHwfaBjoQxHRDpxLbjnPx4FrI+IxSd+UdGpS7FZgjaSFwDzgHyJizY40JCstvgPJzMpIIWMK6yV9GTgDODa51bS2kJNHxC3ALT32nZf3PoDPJ6+SNLWxHimXFE46qCnrcMzMdkohVwrvB7YAZ0XESnJ3FV2YalQlZGRdDXuPHclir61gZmWgkDWaVwLfy9t+lsLGFCpGc6MX3DGz8lDINBczJN0nqU3SVkkdkgq5+6hitDQ28PRLG9jS3pF1KGZmO6WQ7qOLgdnAk8AI4Gxy01dYormpgY7OYOmLG7IOxcxspxSSFIiIJUB1RHRExE/JPWxmCd+BZGblopC7jzYmzxn8WdJ3gBeAUemGVVr2GT+K2mp5XMHMSl4hVwpnkpuX6FxgA7mnlN+TZlClpq6miinj673gjpmVvELuPlqWvN0EfCPdcEpXc1MDDz67LuswzMx2Sn9rND/CGyew6xYRB6cSUYlqaaznpodW0LalnfphhfTKmZkNPf19e71j0KIoA10L7ixetZ637L1rxtGYme2Y/sYUaoGJEbEs/wXsTWED1BVl/6bRAB5XMLOS1l9SuAjo7RtuU3LM8kzcdQQjaqt9B5KZlbT+ksLkiHi4586IuB+YnFpEJaqqSjQ31nsOJDMraf0lheH9HBtR7EDKQXNjA4tWtmUdhpnZDusvKdwn6eM9d0o6C1iQXkilq6WpgZfatrCmbUvWoZiZ7ZD+Bow/B9wg6YO8lgSmA3XAX6cdWClqaUqmu1i1nqPrh2UcjZnZ9uszKUTEKuBoSbOAg5Ld/xsRdwxKZCWoaw6kxSvXc/S+4zOOxsxs+xXyRPM8cktl2gAmNAxjzMhaFq3yuIKZlaaCZkm1wkiiubHBdyCZWclyUiiylsYGFq9cT275aTOz0uKkUGQtTQ2s39LOilc2Zx2Kmdl2c1Iosq47kDzdhZmVIieFImve7bXbUs3MSo2TQpHtMrKWptHDfaVgZiUp1aQg6SRJiyQtkfSlfsq9V1JImp5mPIOluanBVwpmVpJSSwqSqoFLgJOBA4HZkg7spVwD8BngnrRiGWz7NzXw5Oo2Ojp9B5KZlZY0rxSOAJZExNKI2ArMBU7rpdy3gO8AZXO7TnNjA1vbO1m90UnBzEpLmovl7Ak8l7e9HDgyv4Ckw4C9IuJmSV/o60SS5gBzABobG2ltbS1+tEXU9koHAEte2jjkY91RbW1tZds2KO/2uW2lazDal2ZSUC/7un86S6oC/h34yEAniojLgMsApk+fHjNnzixOhCnZtLWDb8z/P9a01zHUY91Rra2tZds2KO/2uW2lazDal2ZSWA7slbc9EViRt91AbqK9VkkATcCNkk5NFvIpWSPqqmlsGMbdK7Zy9T3Pdj+7kKZFK9fz2IpXeNMeu6Re36KV67n90S2sGDF4bVu+biNvO6CRaZO8/rVZmtJMCvcBUyXtAzwPnA58oOtgRLwCdE8lKqkV+EKpJwSABcvWsXr9FjoD/umGR7IOJzXzlg9u2378h6XMnXOUE4NZilJLChHRLulc4FagGrgiIh6T9E3g/oi4Ma26szZ/6Zru91WCd79lIu88ZI/U6rvpoRVc/8ByOiP9+gazrq76frlgOQFs6wi+e9sifnHWkVRV9dY7aWY7K80rBSLiFuCWHvvO66PszDRjGUwzpoyjrqaKrds6qaupYvYRe6f667Z+WA03P7yCbe2d1KZcX1ddWbQNxN1PreETv1jA995/KPXDUv3na1aR/H9VCqZN2pWrzp7BNb+9j9knHJ56d0dXffOXrmHGlHGp1pdp2/YZy0PLX+H/3fI4f33JXfz4Q9OZPH5UqvWbVRonhZRMm7Qr6/etG7T+72mTdh3UurJq27TJY9m/qYFzrn6AUy/+I/8x+zBmtuw2KHGYVQLPfWQl5+j9xnPjuW9ljzEj+NiV93Hp75/y+hVmReKkYCVpr7Ejuf5TR3Pym3fn/N88wWfn/plNWzuyDsus5DkpWMkaWVfDxbMP4x9PauGmh1fwnh/ezfJ1G7MOy6ykOSlYSZPEp2buxxUfOZzn1m3k1Ivv4k9PrRn4g2bWKycFKwuzWnbj1+ccw9hRdZzxk3u48q6nPc5gtgOcFKxsTJlQzw2fOppZLbvx9ZsW8o/XPczmbR5nMNseTgpWVhqG13LZmdP4zNum8j8LlnP6ZfNZ+UrZzMpuljonBSs7VVXi8yc2c+kZb2HxqvW88+I/smDZ2qzDMisJTgpWtk46aHdu+NQxjKit5vTL5jP33mezDslsyHNSsLLW0tTAjecew4wp4/jS9Y/w1V89ytb2zqzDMhuynBSs7I0ZWcdPP3I4c46dwn/NX8YZl9/DS21bsg7LbEhyUrCKUFNdxT+dcgDfP/1QHlr+Mqf+5x95ZPkrWYdlNuQ4KVhFOe3QPfnlJ49GEu+99G5+9eDzWYdkNqQ4KVjFOWjPXfj1ucdwyF5j+Nx//5lv37yQ9g6PM5iBk4JVqPH1w7jq7CP50FGTuPyPT/PRK+/j5Y1bsw7LLHNOClaxaqur+OZpB3HBe97MPUvXcurFd/HEylezDsssU04KVvHef/jeXDNnBpu3dfDuH9zNJXc8yc1PbWXBsnWp171g2ToumbdkUOrqqm+w2tZV32C2z3aeV14zI7e6202ffitnXH4PF962GIDrnrybsSPrqKtJ57fT1vZO1uZ1WaVZV8/60m5bz/qG1VRx9cdnDNpqfbbjnBTMEo2jh/POQ3bn329/kgAE7LnrCA7cfXQq9S184dXuL82068q6vi3tnXzjpsf44RnT2HPMiNTqtJ3npGCW55j9JvCD1qfYuq2Tutoqvn7qm1L7dbtg2To+ePl8trV3UluTbl359Q1G2/Lr29beCRILV7zKrAtbOf2IvfjUzP1o2mV4anXbjnNSMMszbdKuXHX2DK757X3MPuHwVL80u+qav3QNM6aMS71rZTDbll9fV/uadhnOJfOWcPU9zzL3vuf44JF788mZ+7Jbg5PDUOKkYNbDtEm7sn7fukHp/542addB7WcfzLZ11Zdf17/89Zv55HH78p93PMnP/7SMa+59ljNnTOJvj9uX8fXDBiUm61+qdx9JOknSIklLJH2pl+Ofl7RQ0sOSfidpUprxmFn29ho7ku+89xB+9/njOOXNu/OTPz7NX1wwj/N/8wRrN/hZkayllhQkVQOXACcDBwKzJR3Yo9iDwPSIOBi4DvhOWvGY2dAyefwovve+Q7n988dx4oGN/OjOp/hwn5FTAAAJ90lEQVSLC+7gu7ct4pWN27IOr2KleaVwBLAkIpZGxFZgLnBafoGImBcRG5PN+cDEFOMxsyFo3wn1/Mfsw7j1c8cys2U3/vOOJbz1gju46LeLeXWzk8NgU1qLm0t6L3BSRJydbJ8JHBkR5/ZR/mJgZUR8u5djc4A5AI2NjdPmzp2bSszF1tbWRn19fdZhpKKc2wbl3b6h3rbn1nfyqyVbWbCqg5E1cNI+tZw4qZYRNRrws0O9bTtrZ9o3a9asBRExfaByaQ409/ZfsNcMJOkMYDpwXG/HI+Iy4DKA6dOnx8yZM4sUYrpaW1splVi3Vzm3Dcq7faXQtjOBR59/hYt+u5jrH1/NvOfhb4/blw8dNYmRdX1/bZVC23bGYLQvze6j5cBeedsTgRU9C0k6Afhn4NSI8MonZgbkZrO9/MOH86tzjuHgiWM4/zdP8BcXzOPyPyxl09aOrMMrW2kmhfuAqZL2kVQHnA7cmF9A0mHAj8glhNUpxmJmJerQvcbws48dwS8/eRQH7D6ab//v4xx74Tx+etfTbN7m5FBsqSWFiGgHzgVuBR4Hro2IxyR9U9KpSbELgXrgfyT9WdKNfZzOzCrctElj+cXZR/Lfc2YwZfwovnHTQmZe2Mp/zV/GlnYnh2JJ9eG1iLgFuKXHvvPy3p+QZv1mVn6OnDKOuXNm8Ken1vDd2xfz1V89yqWtT/HOQ3Zn9fNbadhnnSfe2wl+otnMSo4kjt5vPEftO44/PPkS37p5IZf+fikANzx1N/s3NTChYTgjaqsYXlvN8Jpqhifvh9VWM6L2te3htVXJ8erXtvPf11Qzoq6aYTVVSK/dP7Ng2bpBm6Kkq76bn0o/6TkpmFnJksSxzRN412F78G+3LiaACFi/uZ26mm2sfrWDTds62Lytg83bOtm8rYMt7Tu+9OqwmlzCqBK8vHHb62bTHVFbXaxmvcGmbR08v24TAdz8zHyuOju9acidFMys5M2YMp5htUu6Z4D9/umH9fml2dkZbO3oZNPWDja3v5Ys8hPH5m2vP7YpObYlOfbAsy+zbuMrQO4++5F11ey3W3rPRyxZ3dZ9P/+29k7mL13jpGBm1pftmQG2qkoMr8p1D+2ontOe/+u7Dx60ac9ra6qYMWVcanU5KZhZWRjs2W3LddpzJwUzsx1QrtOepzp1tpmZlRYnBTMz6+akYGZm3ZwUzMysm5OCmZl1c1IwM7Nuqa28lhZJLwLLso6jQOOBl7IOIiXl3DYo7/a5baVrZ9o3KSImDFSo5JJCKZF0fyHL35Wicm4blHf73LbSNRjtc/eRmZl1c1IwM7NuTgrpuizrAFJUzm2D8m6f21a6Um+fxxTMzKybrxTMzKybk4KZmXVzUkiBpL0kzZP0uKTHJH0265iKTVK1pAcl3Zx1LMUkaYyk6yQ9kfz3OyrrmIpJ0t8l/yYflXSNpOFZx7SjJF0habWkR/P2jZV0u6Qnkz8Hb27rIuujfRcm/zYflnSDpDHFrtdJIR3twN9HxAHADOAcSQdmHFOxfRZ4POsgUvB94P8iYn/gEMqojZL2BD4DTI+Ig4Bq4PRso9opVwIn9dj3JeB3ETEV+F2yXaqu5I3tux04KCIOBhYDXy52pU4KKYiIFyLigeT9enJfLHtmG1XxSJoI/BVwedaxFJOk0cCxwE8AImJrRLycbVRFVwOMkFQDjARWZBzPDouIO4G1PXafBvwsef8z4F2DGlQR9da+iLgtItqTzfnAxGLX66SQMkmTgcOAe7KNpKguAv4R6Mw6kCKbArwI/DTpGrtc0qisgyqWiHge+DfgWeAF4JWIuC3bqIquMSJegNyPM2C3jONJ08eA3xT7pE4KKZJUD/wS+FxEvJp1PMUg6R3A6ohYkHUsKagB3gL8MCIOAzZQ2t0Pr5P0r58G7APsAYySdEa2UdmOkPTP5Lqpryr2uZ0UUiKpllxCuCoirs86niI6BjhV0jPAXOB4Sb/INqSiWQ4sj4iuq7rryCWJcnEC8HREvBgR24DrgaMzjqnYVknaHSD5c3XG8RSdpA8D7wA+GCk8aOakkAJJItcv/XhEfC/reIopIr4cERMjYjK5Qco7IqIsfm1GxErgOUktya63AQszDKnYngVmSBqZ/Bt9G2U0kJ64Efhw8v7DwK8zjKXoJJ0EfBE4NSI2plGHk0I6jgHOJPcr+s/J65Ssg7KCfBq4StLDwKHAv2QcT9EkV0DXAQ8Aj5D7/79kp4WQdA3wJ6BF0nJJZwHnAydKehI4MdkuSX2072KgAbg9+V65tOj1epoLMzPr4isFMzPr5qRgZmbdnBTMzKybk4KZmXVzUjAzs25OClZyJIWk7+Ztf0HS14t07islvbcY5xqgnr9JZmGd18uxZkm3SFqSlLlWUmM/55rcNZOmpJnlNnOtDS4nBStFW4B3SxqfdSD5JFVvR/GzgE9FxKwe5xgO/C+5qTb2S2ba/SEwoXiRmvXNScFKUTu5h67+rueBnr/0JbUlf86U9PvkV/diSedL+qCkeyU9ImnfvNOcIOkPSbl3JJ+vTuayvy+Zy/5v8847T9LV5B4I6xnP7OT8j0q6INl3HvBW4FJJF/b4yAeAP0XETV07ImJeRDyaXBH8QdIDyavfKSokHZf38OSDkhr6K28GuQnAzErRJcDDkr6zHZ85BDiA3HTES4HLI+II5RZB+jTwuaTcZOA4YF9gnqT9gA+Rm1X0cEnDgLskdc0wegS5Oe6fzq9M0h7ABcA0YB1wm6R3RcQ3JR0PfCEi7u8R40FAX5MNrgZOjIjNkqYC1wDT+2nvF4BzIuKuZHLGzf2UNQN8pWAlKpl19ufkFo0p1H3JWhdbgKeAri/1R8glgi7XRkRnRDxJLnnsD7wd+JCkP5ObBn0cMDUpf2/PhJA4HGhNJqDrmtHy2O2It6da4MeSHgH+Bxho4aa7gO9J+gwwJm8efrM+OSlYKbuIXN98/poH7ST/rpNJ3+ryjm3Je9+Zt93J66+ae879EoCAT0fEoclrn7y1CDb0EZ8KbUiex8hdWfTm74BV5K54pvP6tr1BRJwPnA2MAOZL2n8H4rEK46RgJSsi1gLXkksMXZ7htS/V08j9ut5efyOpKhlnmAIsAm4FPplMid51h9BAC/DcAxwnaXwyCD0b+P0An7kaOFrSX3XtkHSSpDcDuwAvREQnuQkX+x3YlrRvRDwSERcA95O74jHrl5OClbrvAvl3If2Y3BfxvcCR9P0rvj+LyH15/wb4RERsJrf06ELggeT2zx8xwJhcsvLXl4F5wEPAAxHR71TOEbGJ3Fz5n1Zu8fmFwEfIjSf8APiwpPlAcwFt+1wywP0QsIkUVumy8uNZUs3MrJuvFMzMrJuTgpmZdXNSMDOzbk4KZmbWzUnBzMy6OSmYmVk3JwUzM+v2/wEEYNkg6/7PLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adapted from skopt.plots.plot_convergence\n",
    "n_calls = len(res_gp.x_iters)\n",
    "mins = [np.min(res_gp.func_vals[:i])\n",
    "        for i in range(1, n_calls + 1)]\n",
    "plt.plot(range(1, n_calls + 1), np.array(mins), marker='.')\n",
    "plt.title(\"Convergence Plot\")\n",
    "plt.ylabel(\"Classification Loss\")\n",
    "plt.xlabel(\"Number of Calls\")\n",
    "plt.grid()\n",
    "plt.savefig(RESULTS_PATH + \"convergence_plot.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(1, n_calls + 1), (np.array(res_gp.func_vals)), marker='x')\n",
    "plt.scatter([np.argmin(res_gp.func_vals)+1],[res_gp.fun],\n",
    "            marker='x', color='red',\n",
    "            label=\"Lowest Loss: \" + str(round(res_gp.fun, 2)))\n",
    "plt.legend(bbox_to_anchor=(0.5,0.35), loc=\"upper left\")\n",
    "plt.ylabel(\"Classification Loss\")\n",
    "plt.xlabel(\"Number of Calls\")\n",
    "plt.ylim(0,2.5)\n",
    "plt.grid()\n",
    "plt.title(\"Hyperparameter Search\")\n",
    "plt.savefig(RESULTS_PATH + \"hyperparameter_search.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters Tried:\n",
    "TODO: add rceptive field calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search: 1\n",
      "n_filters: 89\n",
      "kernel_size: 5\n",
      "dilation_depth: 8\n",
      "number_of_stacks: 4\n",
      "pool_size: 8\n",
      "kernel_size_2: 4\n",
      "early_stopping_patience: 0\n",
      " \n",
      "Search: 2\n",
      "n_filters: 37\n",
      "kernel_size: 3\n",
      "dilation_depth: 5\n",
      "number_of_stacks: 3\n",
      "pool_size: 7\n",
      "kernel_size_2: 4\n",
      "early_stopping_patience: 3\n",
      " \n",
      "Search: 3\n",
      "n_filters: 64\n",
      "kernel_size: 4\n",
      "dilation_depth: 5\n",
      "number_of_stacks: 4\n",
      "pool_size: 5\n",
      "kernel_size_2: 7\n",
      "early_stopping_patience: 1\n",
      " \n",
      "Search: 4\n",
      "n_filters: 109\n",
      "kernel_size: 4\n",
      "dilation_depth: 7\n",
      "number_of_stacks: 3\n",
      "pool_size: 7\n",
      "kernel_size_2: 5\n",
      "early_stopping_patience: 3\n",
      " \n",
      "Search: 5\n",
      "n_filters: 42\n",
      "kernel_size: 3\n",
      "dilation_depth: 3\n",
      "number_of_stacks: 3\n",
      "pool_size: 5\n",
      "kernel_size_2: 3\n",
      "early_stopping_patience: 1\n",
      " \n",
      "Search: 6\n",
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 9\n",
      "number_of_stacks: 3\n",
      "pool_size: 10\n",
      "kernel_size_2: 7\n",
      "early_stopping_patience: 4\n",
      " \n",
      "Search: 7\n",
      "n_filters: 110\n",
      "kernel_size: 2\n",
      "dilation_depth: 7\n",
      "number_of_stacks: 3\n",
      "pool_size: 4\n",
      "kernel_size_2: 4\n",
      "early_stopping_patience: 3\n",
      " \n",
      "Search: 8\n",
      "n_filters: 128\n",
      "kernel_size: 3\n",
      "dilation_depth: 2\n",
      "number_of_stacks: 1\n",
      "pool_size: 4\n",
      "kernel_size_2: 8\n",
      "early_stopping_patience: -1\n",
      " \n",
      "Search: 9\n",
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 9\n",
      "number_of_stacks: 3\n",
      "pool_size: 10\n",
      "kernel_size_2: 8\n",
      "early_stopping_patience: 1\n",
      " \n",
      "Search: 10\n",
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 5\n",
      "number_of_stacks: 3\n",
      "pool_size: 7\n",
      "kernel_size_2: 2\n",
      "early_stopping_patience: 4\n",
      " \n",
      "Search: 11\n",
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 3\n",
      "number_of_stacks: 2\n",
      "pool_size: 6\n",
      "kernel_size_2: 2\n",
      "early_stopping_patience: 4\n",
      " \n",
      "Search: 12\n",
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 2\n",
      "number_of_stacks: 1\n",
      "pool_size: 4\n",
      "kernel_size_2: 2\n",
      "early_stopping_patience: 4\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for count, parameters in enumerate(res_gp.x_iters):\n",
    "    print(\"Search:\", count+1)\n",
    "    for index, parameter in enumerate(parameters):\n",
    "        print(dimensions[index] + \":\", parameter)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with parameters before search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_range = (0, 63)\n",
    "data_shape = (3000, 32)\n",
    "\n",
    "activation = 'softmax'\n",
    "\n",
    "epochs = 10  # number of epochs limited to 10 to allow more searches (15 hours per evaluation = 11 searches in one week)\n",
    "batch_size = 16\n",
    "\n",
    "num_dense_nodes = 512\n",
    "\n",
    "residual_l2 = 0.001\n",
    "conv_l2 = 0.001\n",
    "fully_l2 = 0.001\n",
    "use_batch_norm = False\n",
    "\n",
    "# Parameters for data generators\n",
    "data_gen_params = {'dim': data_shape,\n",
    "                   'batch_size': batch_size,\n",
    "                   'n_classes': nb_classes,\n",
    "                   'data_directory': DATA_PATH_NO_MTI,\n",
    "                   'bin_range': bin_range,\n",
    "                   'every_second_cell': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_filters\": 64,\n",
    "    \"kernel_size\": 2,\n",
    "    \"dilation_depth\": 8,\n",
    "    \"number_of_stacks\": 3,\n",
    "    \"pool_size\": 4,\n",
    "    \"kernel_size_2\": 8,\n",
    "    \"early_stopping_patience\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [64, 2, 8, 3, 4, 8, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,64,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropInput-0-VecPermuteNHWCToNCHW-LayoutOptimizer, conv1d_48/convolution/ExpandDims_1, training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0c6f798bc2b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[1;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[0mobjective_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-705814f73f5b>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(**params)\u001b[0m\n\u001b[0;32m     38\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                                   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                                   verbose=1)\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,64,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropInput-0-VecPermuteNHWCToNCHW-LayoutOptimizer, conv1d_48/convolution/ExpandDims_1, training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "loss = objective(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9c7d9083178b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"base_evaluation.pkl\", 'wb') as file:\n",
    "    pickle.dump(loss, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"base_evaluation.pkl\", 'rb') as file:\n",
    "    loss = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Loss: 0.7047507423046598\n"
     ]
    }
   ],
   "source": [
    "print(\"Base Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "12_range_data_model_hyperparameter_search.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
