{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znku3TNhZY2m"
   },
   "source": [
    "# Hyperparameter search over range data model\n",
    "\n",
    "Due to the time the model takes to train (over 1 hour per epoch), using a 5 fold cross validation strategy (applied in notebook 8 for the CNN model) would take close to 50 hours per parameter configuration (assuming 10 epochs). Therefore to perform any meaningful search, it would take several weeks.\n",
    "\n",
    "Furthermore, up until now the model has been only evaluated on subject B which has made the model bias towards this subject. To try and adjust for this the test set for the hyperparamter optimization will be taken from all subjects (except C). 20\\% of the data from each subject will be used for validation. The data will be taken in consecutive chunks as there is little variation between two consecutive spectrograms.\n",
    "\n",
    "The following parameters will remain fixed:\n",
    "* Optimizer: 'adam'\n",
    "* Batch size: 32\n",
    "* Number of dense layers: 1\n",
    "* Learning rate: 0.001\n",
    "* Number of dense nodes: 512\n",
    "* L2: 0.001\n",
    "* Batch norm: False\n",
    "\n",
    "Limited to 10 epochs as this takes around 15 hours == 11 evalauations in one week\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZxhO7V0ZHUE"
   },
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGNeUj-JDXhs"
   },
   "outputs": [],
   "source": [
    "# Needed to allow editing using PyCharm etc\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwLbqieVYIJt"
   },
   "source": [
    "The following cell is needed for compatibility when using both CoLab and Local Jupyter notebook. It sets the appropriate file path for the data and also installs local packages such as models and data_loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XeU0HtoDXh6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "if path == '/content':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    BASE_PATH = '/content/gdrive/My Drive/Level-4-Project/'\n",
    "#     !cd gdrive/My\\ Drive/Level-4-Project/ && pip install --editable .\n",
    "    os.chdir('gdrive/My Drive/Level-4-Project/')\n",
    "    \n",
    "elif path == 'D:\\\\Google Drive\\\\Level-4-Project\\\\notebooks':\n",
    "    BASE_PATH = \"D:/Google Drive/Level-4-Project/\"\n",
    "    \n",
    "elif path == \"/export/home/2192793m\":\n",
    "    BASE_PATH = \"/export/home/2192793m/Level-4-Project/\"\n",
    "    \n",
    "    \n",
    "DATA_PATH_MTI = BASE_PATH + 'data/processed/range_FFT/3/MTI_applied/' # not used\n",
    "DATA_PATH_NO_MTI = BASE_PATH + 'data/processed/range_FFT/3/MTI_not_applied/'\n",
    "\n",
    "RESULTS_PATH = BASE_PATH + 'results/range_data_model_hyperparameter_search/'\n",
    "if not os.path.exists(RESULTS_PATH):\n",
    "    os.makedirs(RESULTS_PATH)\n",
    "    \n",
    "MODEL_PATH = BASE_PATH + 'models/range_data_model_hyperparameter_search/'\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QW7Fa5jTCDXo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras.callbacks import History, ModelCheckpoint, CSVLogger\n",
    "from keras.models import load_model\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.layers import Input, Conv1D, Multiply, Add, Reshape, Activation, AveragePooling1D, Lambda, Flatten, Dense,GlobalAveragePooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model, Model\n",
    "from keras.callbacks import History, ModelCheckpoint, EarlyStopping\n",
    "import sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tk_HAyYKYrI8"
   },
   "outputs": [],
   "source": [
    "# needed for CheckpointSaver\n",
    "# https://github.com/scikit-optimize/scikit-optimize/issues/678\n",
    "# ! pip install git+https://github.com/scikit-optimize/scikit-optimize/ \n",
    "    \n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.callbacks import CheckpointSaver\n",
    "from skopt import dump, load\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vxIKU3-fTUy7"
   },
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sj59Pvxv5CX9"
   },
   "outputs": [],
   "source": [
    "# Load in data dictionary.\n",
    "# This does not load in any actual data,\n",
    "# just the dictionary with the names of the files and their associated labels\n",
    "with open(DATA_PATH_NO_MTI + \"index.pkl\", \"rb\") as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYNFp-60ZFe2"
   },
   "outputs": [],
   "source": [
    "#Remove user C as this user is reserved for the test set\n",
    "try:\n",
    "    del data[\"C\"]\n",
    "except KeyError:\n",
    "    print (\"Key 'C' not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQIwQ8EACdIQ"
   },
   "outputs": [],
   "source": [
    "def convert_label_to_int(label):\n",
    "    if label == \"walking\":\n",
    "        return 0\n",
    "    if label == \"pushing\":\n",
    "        return 1\n",
    "    if label == \"sitting\":\n",
    "        return 2\n",
    "    if label == \"pulling\":\n",
    "        return 3\n",
    "    if label == \"circling\":\n",
    "        return 4\n",
    "    if label == \"clapping\":\n",
    "        return 5\n",
    "    if label == \"bending\":\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the model has only been validated on subject B. This has likely introduced bias into the model. To combat this, the hyperparameter search will using 20% of the data from every subject for validation. To do this it will be made sure that the data is selected in consecutive chunks to negate the issue of consecutive range profiels being almost identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "partition = {'train':[], 'validation':[]} # contains list of training and validation ID's\n",
    "\n",
    "for user_letter, actions in data.items():\n",
    "    for action, results in actions.items():\n",
    "        for result in results:\n",
    "            res = np.array(result)\n",
    "            # Split into 5 folds then take 1 fold for 20%\n",
    "            split_actions = np.array_split(res, 5)\n",
    "            for fold in range(5):\n",
    "                data = split_actions[fold]\n",
    "                if fold == 0:\n",
    "                    for row in data:\n",
    "                        partition[\"validation\"].append(row)\n",
    "                        labels[row] = convert_label_to_int(action)\n",
    "\n",
    "                else:\n",
    "                    for row in data:\n",
    "                        partition[\"train\"].append(row)\n",
    "                        labels[row] = convert_label_to_int(action)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4fd5mwu11f9"
   },
   "outputs": [],
   "source": [
    "target_names = [\"walking\", \"pushing\", \"sitting\", \"pulling\", \"circling\", \"clapping\", \"bending\"]\n",
    "nb_classes = len(target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ah1RGSSTYfQ"
   },
   "source": [
    "## DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gOcp1JeSop2"
   },
   "outputs": [],
   "source": [
    "'''Based on code from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly'''\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Generates data for Keras\"\"\"\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(3000),\n",
    "                 n_classes=7, shuffle=False, data_directory='data/',\n",
    "                 bin_range=(0,60), take_average=False, every_second_cell=False):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.data_directory = data_directory\n",
    "        self.bin_range=bin_range\n",
    "        self.take_average = take_average\n",
    "        self.every_second_cell = every_second_cell\n",
    "        self.indexes = None\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\"\"\"\n",
    "\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size samples\"\"\"\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            if self.take_average:\n",
    "                X[i,] = abs(np.average(np.load(self.data_directory + ID), axis=1)[:,np.newaxis])\n",
    "                \n",
    "            elif self.every_second_cell:\n",
    "                X[i,] = abs(np.load(self.data_directory + ID))[:,::2]\n",
    "                \n",
    "            else:\n",
    "                X[i,] = abs(np.load(self.data_directory + ID))[:,self.bin_range[0]:self.bin_range[1]]\n",
    "                \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3MQ0FACt9aa"
   },
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__yOu1WH_iBb"
   },
   "outputs": [],
   "source": [
    "def visualize_results(csvlog_path, metric, save=False, save_file_name=\"\"):\n",
    "    df = pd.read_csv(RESULTS_PATH + csvlog_path)\n",
    "    epoch = df['epoch'] +1\n",
    "    train = df[metric]\n",
    "    val = df['val_' + metric]\n",
    "    plt.figure()\n",
    "    plt.plot(epoch, train, label='train')\n",
    "    plt.plot(epoch, val, label='val')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    if save:\n",
    "        plt.savefig(RESULTS_PATH + save_file_name, format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88LpWZJeTfj2"
   },
   "source": [
    "## Model: Wavenet model adapted based on interpretation from Wavenet Paper\n",
    "\n",
    "Keras implementation of wavenet model taken from https://github.com/basveeling/wavenet and https://github.com/mjpyeon/wavenet-classifier\n",
    "\n",
    "This model has then been adapted to the classification task based on the intrustions from the paper \"WAVENET: A GENERATIVE MODEL FOR RAW AUDIO\" (https://arxiv.org/pdf/1609.03499.pdf)\n",
    "\n",
    "Specifically:\n",
    "\"For this task we added a mean-pooling layer after the dilated convolutions that aggregated the activations to coarser frames spanning 10 milliseconds (160× downsampling).  The pooling layer was followed by a few non-causal convolutions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNetClassifier:\n",
    "    def __init__(self, input_shape, output_shape, kernel_size=2, dilation_depth=9, nb_stacks=1, nb_filters=40,\n",
    "                 pool_size=80, kernel_size_2=100, use_skip_connections=True, causal=True, residual_l2=0.001,\n",
    "                 conv_l2=0.001, fully_l2=0.001, use_batch_norm=True, num_dense_nodes=512):\n",
    "\n",
    "        self.activation = 'softmax'\n",
    "        self.pool_size = pool_size\n",
    "        self.kernel_size_2 = kernel_size_2 # kernel size for later conV 1d (not dilated)\n",
    "        self.nb_stacks = nb_stacks\n",
    "        self.kernel_size = kernel_size # kernel size for dilated  layers\n",
    "        self.dilation_depth = dilation_depth\n",
    "        self.nb_filters = nb_filters\n",
    "        self.residual_l2 = residual_l2 # l2 value for residual layers\n",
    "        self.conv_l2 = conv_l2 # l2 value for stack of standard conv layers\n",
    "        self.fully_l2 = fully_l2 # l2 value for fully connected layer\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.num_dense_nodes = num_dense_nodes\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        if causal:\n",
    "            self.padding = 'causal'\n",
    "        else:\n",
    "            self.padding = 'same'\n",
    "\n",
    "        if len(input_shape) == 1:\n",
    "            self.expand_dims = True\n",
    "        elif len(input_shape) == 2:\n",
    "            self.expand_dims = False\n",
    "        else:\n",
    "            print('ERROR: wrong input shape')\n",
    "            sys.exit()\n",
    "\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def residual_block(self, x, i, stack_nb):\n",
    "        original_x = x\n",
    "        tanh_out = Conv1D(self.nb_filters, self.kernel_size, dilation_rate=2 ** i, padding=self.padding,\n",
    "                          name='dilated_conv_%d_tanh_s%d' % (2 ** i, stack_nb), activation='tanh',\n",
    "                          kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        sigm_out = Conv1D(self.nb_filters, self.kernel_size, dilation_rate=2 ** i, padding=self.padding,\n",
    "                          name='dilated_conv_%d_sigm_s%d' % (2 ** i, stack_nb), activation='sigmoid',\n",
    "                          kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        x = Multiply(name='gated_activation_%d_s%d' % (i, stack_nb))([tanh_out, sigm_out])\n",
    "\n",
    "        res_x = Conv1D(self.nb_filters, 1, padding='same', kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        skip_x = Conv1D(self.nb_filters, 1, padding='same', kernel_regularizer=l2(self.residual_l2))(x)\n",
    "        res_x = Add()([original_x, res_x])\n",
    "        return res_x, skip_x\n",
    "\n",
    "    def build_model(self):\n",
    "        input_layer = Input(shape=self.input_shape, name='input_part')\n",
    "        out = input_layer\n",
    "        skip_connections = []\n",
    "        out = Conv1D(self.nb_filters, self.kernel_size,\n",
    "                     dilation_rate=1,\n",
    "                     padding=self.padding,\n",
    "                     name='initial_causal_conv'\n",
    "                     )(out)\n",
    "        for stack_nb in range(self.nb_stacks):\n",
    "            for i in range(0, self.dilation_depth + 1):\n",
    "                out, skip_out = self.residual_block(out, i, stack_nb)\n",
    "                skip_connections.append(skip_out)\n",
    "\n",
    "        if self.use_skip_connections:\n",
    "            out = Add()(skip_connections)\n",
    "        out = Activation('relu')(out)\n",
    "        # added a mean-pooling layer after the dilated convolutions that aggregated the activations to coarser frames\n",
    "        # spanning 10 milliseconds (160× downsampling)\n",
    "        # mean pooling layer adjust pool_size_1 to change downsampling\n",
    "                \n",
    "        out = AveragePooling1D(self.pool_size, padding='same', name='mean_pooling_layer_downsampling')(out)\n",
    "\n",
    "        # few non-causal convolutions\n",
    "        # In notebooks 11, 12 and 13 self.kernel_size_2 was incorrectly represented as pooling sizes.\n",
    "        out = Conv1D(self.nb_filters, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "        \n",
    "        out = Conv1D(self.nb_filters, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "        \n",
    "        out = Conv1D(self.output_shape, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "        \n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "        \n",
    "        out = Conv1D(self.output_shape, self.kernel_size_2, strides=2, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(self.conv_l2))(out)\n",
    "\n",
    "        if self.use_batch_norm:\n",
    "            out = BatchNormalization()(out)\n",
    "            \n",
    "        out = Flatten()(out)\n",
    "        out = Dense(num_dense_nodes, activation='relu', kernel_regularizer=l2(self.fully_l2))(out)\n",
    "        out = Dense(self.output_shape, activation='softmax')(out)\n",
    "\n",
    "        return Model(input_layer, out)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def get_summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def get_receptive_field(self):\n",
    "        return self.nb_stacks * (self.kernel_size + (2*(self.kernel_size - 1) * ((2**self.dilation_depth) - 1))) - (self.nb_stacks - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhFcRSbwZCCw"
   },
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DeW2AmQ2ZGFC"
   },
   "source": [
    "### Fixed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxXVIaedsPxK"
   },
   "outputs": [],
   "source": [
    "bin_range = (0,63)\n",
    "data_shape = (3000, 32)\n",
    "\n",
    "activation = 'softmax'\n",
    "\n",
    "epochs = 10 # number of epochs limited to 10 to allow more searches (15 hours per evaluation = 11 searches in one week)\n",
    "batch_size = 16\n",
    "\n",
    "num_dense_nodes = 512\n",
    "\n",
    "residual_l2 = 0.001\n",
    "conv_l2 = 0.001\n",
    "fully_l2 = 0.001\n",
    "use_batch_norm = False\n",
    "\n",
    "# Parameters for data generators\n",
    "data_gen_params = {'dim': data_shape,\n",
    "                   'batch_size': batch_size,\n",
    "                   'n_classes': nb_classes,\n",
    "                   'data_directory': DATA_PATH_NO_MTI,\n",
    "                   'bin_range': bin_range,\n",
    "                   'every_second_cell': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CsyeQlBQZUle"
   },
   "source": [
    "### Parameters to Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAqGS4oWZXE-"
   },
   "outputs": [],
   "source": [
    "space = [\n",
    "    Integer(32, 128, name=\"n_filters\"),\n",
    "    Integer(2, 5, name=\"kernel_size\"),\n",
    "    Integer(2, 9, name=\"dilation_depth\"),\n",
    "    Integer(1, 4, name=\"number_of_stacks\"),\n",
    "    Integer(4, 10, name=\"pool_size\"),\n",
    "    Integer(2, 8, name=\"kernel_size_2\"),\n",
    "    Integer(-1, 4, name='early_stopping_patience')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmvMHPqiZP6x"
   },
   "source": [
    "### Objective Function to Minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzWFM-axZS2V"
   },
   "outputs": [],
   "source": [
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    wnc = WaveNetClassifier((data_shape), (nb_classes),\n",
    "                            kernel_size=int(params[\"kernel_size\"]),\n",
    "                            dilation_depth=params[\"dilation_depth\"],\n",
    "                            nb_stacks=params[\"number_of_stacks\"],\n",
    "                            nb_filters=params[\"n_filters\"],\n",
    "                            pool_size=int(params[\"pool_size\"]),\n",
    "                            kernel_size_2=int(params[\"kernel_size_2\"]),\n",
    "                            num_dense_nodes=num_dense_nodes,\n",
    "                            residual_l2=residual_l2,\n",
    "                            conv_l2=conv_l2,\n",
    "                            fully_l2=fully_l2,\n",
    "                            use_batch_norm=use_batch_norm)\n",
    "\n",
    "    model = wnc.get_model()\n",
    "\n",
    "    training_generator = DataGenerator(partition[\"train\"],\n",
    "                                       labels,\n",
    "                                       **data_gen_params, shuffle=True)\n",
    "    \n",
    "    validation_generator = DataGenerator(partition[\"validation\"],\n",
    "                                         labels,\n",
    "                                         **data_gen_params, shuffle=False)\n",
    "\n",
    "    model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    patience = params[\"early_stopping_patience\"]\n",
    "    callback_list = []\n",
    "    # -1 used to represent no early stopping\n",
    "    if patience != -1:\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "        callback_list.append(early_stopping)\n",
    "\n",
    "    # Train model on dataset\n",
    "    history = model.fit_generator(generator=training_generator,\n",
    "                                  validation_data=validation_generator,\n",
    "                                  epochs=epochs,\n",
    "                                  callbacks=callback_list,\n",
    "                                  verbose=1)\n",
    "    val_loss = history.history[\"val_loss\"][-1]\n",
    "    K.clear_session()\n",
    "\n",
    "    return val_loss # minimize validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oU1PMTWxbA8A"
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZIFbhblcFTD"
   },
   "outputs": [],
   "source": [
    "checkpoint = CheckpointSaver(RESULTS_PATH + \"res_gp_checkpoint.pkl\")\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfd4x0jxsY6S"
   },
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hTA-T_0QsiY2"
   },
   "outputs": [],
   "source": [
    "LOAD_CHECKPOINT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jozj15HsfmA"
   },
   "outputs": [],
   "source": [
    "if LOAD_CHECKPOINT:\n",
    "    res = load(RESULTS_PATH + \"res_gp_checkpoint.pkl\")\n",
    "    x0 = res.x_iters\n",
    "    y0 = res.func_vals\n",
    "    random_starts = 0\n",
    "    \n",
    "else:\n",
    "    x0 = None\n",
    "    y0 = None\n",
    "    random_starts = 5 # default is 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAFCZnjYU36e"
   },
   "source": [
    "### Perform Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8_tpC-DZnyh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,89,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_35/convolution/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_36/convolution/ExpandDims, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/add_147/_2445 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24725_loss/add_147\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-04809eefd325>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m res_gp = gp_minimize(objective, space, x0=x0, y0=y0,\n\u001b[0;32m      2\u001b[0m                      \u001b[0mn_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m130\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_random_starts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_starts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                      random_state=0, callback=callbacks_list, verbose=True)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\optimizer\\gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mnext_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[1;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[0mobjective_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-705814f73f5b>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(**params)\u001b[0m\n\u001b[0;32m     38\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                                   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                                   verbose=1)\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,89,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_35/convolution/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_36/convolution/ExpandDims, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/add_147/_2445 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_24725_loss/add_147\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "res_gp = gp_minimize(objective, space, x0=x0, y0=y0,\n",
    "                     n_calls=130, n_random_starts=random_starts,\n",
    "                     random_state=0, callback=callbacks_list, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsCe4ugZt2Yt"
   },
   "source": [
    "### Save gp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lS-st190t2GS"
   },
   "outputs": [],
   "source": [
    "dump(res_gp, RESULTS_PATH + \"res_gp_complete.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEBqFCS9uImJ"
   },
   "source": [
    "### Load gp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "237ErDR_uKsk"
   },
   "outputs": [],
   "source": [
    "res_gp = load(RESULTS_PATH + \"res_gp_complete.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp\n",
    "res_gp = load(RESULTS_PATH + \"res_gp_checkpoint.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDOtEG4rZx-9"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 9\n",
      "number_of_stacks: 3\n",
      "pool_size: 10\n",
      "kernel_size_2: 7\n",
      "early_stopping_patience: 4\n"
     ]
    }
   ],
   "source": [
    "dimensions = ['n_filters', 'kernel_size', 'dilation_depth', 'number_of_stacks',\n",
    "              'pool_size', 'kernel_size_2',\n",
    "              'early_stopping_patience']\n",
    "\n",
    "parameters = res_gp.x\n",
    "for index, parameter in enumerate(parameters):\n",
    "    print(dimensions[index] + \":\", parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest Loss achieved: 0.24\n"
     ]
    }
   ],
   "source": [
    "print(\"Lowest Loss achieved:\", str(round(res_gp.fun, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adapted from skopt.plots.plot_convergence\n",
    "n_calls = len(res_gp.x_iters)\n",
    "mins = [np.min(res_gp.func_vals[:i])\n",
    "        for i in range(1, n_calls + 1)]\n",
    "plt.plot(range(1, n_calls + 1), np.array(mins), marker='.')\n",
    "plt.title(\"Convergence Plot\")\n",
    "plt.ylabel(\"Classification Loss\")\n",
    "plt.xlabel(\"Number of Calls\")\n",
    "plt.grid()\n",
    "plt.savefig(RESULTS_PATH + \"convergence_plot.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(1, n_calls + 1), (np.array(res_gp.func_vals)), marker='x')\n",
    "plt.scatter([np.argmin(res_gp.func_vals)+1],[res_gp.fun],\n",
    "            marker='x', color='red',\n",
    "            label=\"Lowest Loss: \" + str(round(res_gp.fun, 2)))\n",
    "plt.legend(bbox_to_anchor=(0.5,0.35), loc=\"upper left\")\n",
    "plt.ylabel(\"Classification Loss\")\n",
    "plt.xlabel(\"Number of Calls\")\n",
    "plt.grid()\n",
    "plt.title(\"Hyperparameter Search\")\n",
    "plt.savefig(RESULTS_PATH + \"hyperparameter_search.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters Tried:\n",
    "TODO: add rceptive field calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search: 1\n",
      "n_filters: 89\n",
      "kernel_size: 5\n",
      "dilation_depth: 8\n",
      "number_of_stacks: 4\n",
      "pool_size: 8\n",
      "kernel_size_2: 4\n",
      "early_stopping_patience: 0\n",
      " \n",
      "Search: 2\n",
      "n_filters: 37\n",
      "kernel_size: 3\n",
      "dilation_depth: 5\n",
      "number_of_stacks: 3\n",
      "pool_size: 7\n",
      "kernel_size_2: 4\n",
      "early_stopping_patience: 3\n",
      " \n",
      "Search: 3\n",
      "n_filters: 64\n",
      "kernel_size: 4\n",
      "dilation_depth: 5\n",
      "number_of_stacks: 4\n",
      "pool_size: 5\n",
      "kernel_size_2: 7\n",
      "early_stopping_patience: 1\n",
      " \n",
      "Search: 4\n",
      "n_filters: 109\n",
      "kernel_size: 4\n",
      "dilation_depth: 7\n",
      "number_of_stacks: 3\n",
      "pool_size: 7\n",
      "kernel_size_2: 5\n",
      "early_stopping_patience: 3\n",
      " \n",
      "Search: 5\n",
      "n_filters: 42\n",
      "kernel_size: 3\n",
      "dilation_depth: 3\n",
      "number_of_stacks: 3\n",
      "pool_size: 5\n",
      "kernel_size_2: 3\n",
      "early_stopping_patience: 1\n",
      " \n",
      "Search: 6\n",
      "n_filters: 32\n",
      "kernel_size: 3\n",
      "dilation_depth: 9\n",
      "number_of_stacks: 3\n",
      "pool_size: 10\n",
      "kernel_size_2: 7\n",
      "early_stopping_patience: 4\n",
      " \n",
      "Search: 7\n",
      "n_filters: 110\n",
      "kernel_size: 2\n",
      "dilation_depth: 7\n",
      "number_of_stacks: 3\n",
      "pool_size: 4\n",
      "kernel_size_2: 4\n",
      "early_stopping_patience: 3\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for count, parameters in enumerate(res_gp.x_iters):\n",
    "    print(\"Search:\", count+1)\n",
    "    for index, parameter in enumerate(parameters):\n",
    "        print(dimensions[index] + \":\", parameter)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with parameters before search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_range = (0,63)\n",
    "data_shape = (3000, 32)\n",
    "\n",
    "activation = 'softmax'\n",
    "\n",
    "epochs = 10 # number of epochs limited to 10 to allow more searches (15 hours per evaluation = 11 searches in one week)\n",
    "batch_size = 16\n",
    "\n",
    "num_dense_nodes = 512\n",
    "\n",
    "residual_l2 = 0.001\n",
    "conv_l2 = 0.001\n",
    "fully_l2 = 0.001\n",
    "use_batch_norm = False\n",
    "\n",
    "# Parameters for data generators\n",
    "data_gen_params = {'dim': data_shape,\n",
    "                   'batch_size': batch_size,\n",
    "                   'n_classes': nb_classes,\n",
    "                   'data_directory': DATA_PATH_NO_MTI,\n",
    "                   'bin_range': bin_range,\n",
    "                   'every_second_cell': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_filters\": 64,\n",
    "    \"kernel_size\": 2,\n",
    "    \"dilation_depth\": 8,\n",
    "    \"number_of_stacks\": 3,\n",
    "    \"pool_size\": 4,\n",
    "    \"kernel_size_2\": 8,\n",
    "    \"early_stopping_patience\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [64, 2, 8, 3, 4, 8, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,64,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropInput-0-VecPermuteNHWCToNCHW-LayoutOptimizer, conv1d_48/convolution/ExpandDims_1, training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0c6f798bc2b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\skopt\\utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[1;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[0mobjective_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-705814f73f5b>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(**params)\u001b[0m\n\u001b[0;32m     38\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                                   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                                   verbose=1)\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,64,1,3000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropInput-0-VecPermuteNHWCToNCHW-LayoutOptimizer, conv1d_48/convolution/ExpandDims_1, training/Adam/gradients/conv1d_48/convolution/Conv2D_grad/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "loss = objective(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9c7d9083178b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"base_evaluation.pkl\", 'wb') as file:\n",
    "    pickle.dump(loss, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"base_evaluation.pkl\", 'rb') as file:\n",
    "    loss = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Base Loss:\", loss)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "12_range_data_model_hyperparameter_search.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
