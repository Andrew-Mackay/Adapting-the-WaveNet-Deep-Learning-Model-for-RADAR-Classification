{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LnU4VGgjH1mW"
   },
   "source": [
    "# Transferred DCNN (VGG16). \n",
    "## Training transferred model on all users except one then testing on that user.\n",
    "* This is done for each user in turn to help determine the accuracy and robustness of the model.\n",
    "* This is also evaluated for 3s, 2s, 1.5s and 1s spectrogram windows to compare the trade-off between accuracy and lower latency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results to be compared with /baseline_models/leave_one_user_out_cnn_64_128.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2sqmYc1yQb-k"
   },
   "source": [
    "### Summary\n",
    "*   1, 1.5, 2 and 3 second windows tested\n",
    "*   0 degree aspect angle\n",
    "*   All movements\n",
    "*   Transferred, pre-trained DCNN (VGG16)\n",
    "*   Datsets:\n",
    "    * 1: Miss out A\n",
    "    * 2: Miss out B\n",
    "    * 3: Miss out C\n",
    "    * 4: Miss out D\n",
    "    * 5: Miss out E\n",
    "    * 6: Miss out F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2sqmYc1yQb-k"
   },
   "source": [
    "*   Take a DCNN trained on image classification\n",
    "*   Adapt to spectrogram classification\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GnQp4LN6hYvM"
   },
   "source": [
    "Inspired by \"Micro-Doppler Based Classification of Human Aquatic Activities via Transfer Learning of Convolutional Neural Networks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train or Load Toggle\n",
    "These variables set whether to load results or train the model.\n",
    "* If set to True then the model will be trained, history saved, new graphs generated and saved and new analysis produced.\n",
    "* If set to False then a pre-trained version of the model will be loaded along with a history object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MODEL_3s = False\n",
    "TRAIN_MODEL_2s = True\n",
    "TRAIN_MODEL_1_5_s = False\n",
    "TRAIN_MODEL_1s = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZxhO7V0ZHUE"
   },
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5jAnxaaZLzZ"
   },
   "source": [
    "Allow editing of modules using editor (auto reloading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGNeUj-JDXhs"
   },
   "outputs": [],
   "source": [
    "# Needed to allow editing using PyCharm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwLbqieVYIJt"
   },
   "source": [
    "Needed for compatibility when using both CoLab and Local Jupyter notebook. It sets the appropriate file path for the data and also installs local packages such as models and data_loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53516,
     "status": "ok",
     "timestamp": 1542102526832,
     "user": {
      "displayName": "Andrew Mackay",
      "photoUrl": "https://lh3.googleusercontent.com/-24hiGmdxZDE/AAAAAAAAAAI/AAAAAAAAL_I/RW7nqM11LkM/s64/photo.jpg",
      "userId": "06804410358976473893"
     },
     "user_tz": 0
    },
    "id": "3XeU0HtoDXh6",
    "outputId": "77a3ff46-116e-4068-eab4-c4366511f4bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n",
      "Obtaining file:///content/gdrive/My%20Drive/Level-4-Project\n",
      "Installing collected packages: src\n",
      "  Running setup.py develop for src\n",
      "Successfully installed src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.getcwd() == '/content':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    BASE_PATH = '/content/gdrive/My Drive/Level-4-Project/'\n",
    "    !cd gdrive/My\\ Drive/Level-4-Project/ && pip install --editable .\n",
    "    os.chdir('gdrive/My Drive/Level-4-Project/')\n",
    "    \n",
    "elif os.getcwd() == 'D:\\\\Google Drive\\\\Level-4-Project\\\\notebooks\\\\transferred_DCNN_experiments':\n",
    "    BASE_PATH = \"D:/Google Drive/Level-4-Project/\"\n",
    "    \n",
    "else:\n",
    "    BASE_PATH = \"/export/home/2192793m/Level-4-Project/\"\n",
    "    \n",
    "DATA_PATH = BASE_PATH + 'data/processed/'\n",
    "DATA_SETS = [\"dataset_1/\", \"dataset_2/\", \"dataset_3/\", \"dataset_4/\", \"dataset_5/\", \"dataset_6/\"]\n",
    "MODEL_PATH = BASE_PATH + 'models/transferred_DCNN/'\n",
    "RESULTS_PATH = BASE_PATH + 'results/transferred_DCNN/leave_one_user_out/'\n",
    "FIGURE_PATH = BASE_PATH + 'reports/transferred_DCNN/figures/'\n",
    "REPORT_PATH = BASE_PATH + 'reports/transferred_DCNN/'\n",
    "    \n",
    "from src.models.transferred_DCNN import vgg_16\n",
    "from src.data import load_data\n",
    "from src.visualization import visualize, multiple_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgYwaq1eZb5u"
   },
   "source": [
    "Import remaining packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8rzmlEhpe_R"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from six.moves import cPickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import sys\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import csv\n",
    "from keras.models import load_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PsHOJ9lEpe_V"
   },
   "outputs": [],
   "source": [
    "# Needed as originally code was for theano backend but now using tensor flow\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oqq9LWY5ZiIB"
   },
   "source": [
    "## Experiment Setup and Parameter Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iErZqcpRli6G"
   },
   "source": [
    "### Parameter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5r9302zCpe_j"
   },
   "outputs": [],
   "source": [
    "target_names = ['ArmFasterTowards', 'ArmSlowerTowards', 'CirclingArm', 'Clapping', 'PickingUp', 'Sitting', 'Walking']\n",
    "nb_classes = len(target_names)\n",
    "batch_size = 100\n",
    "nb_epoch = 20\n",
    "nb_epoch = 3\n",
    "\n",
    "# input image dimensions (images are spectrograms)\n",
    "img_rows, img_cols = 75, 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_datasets takes in the window size (1, 1.5, 2 or 3) as a string combines with an array datasets of the form [\"dataset_1/\", \"dataset_2/\",...].\n",
    "\n",
    "Returned is a dictionary indexed by dataset name which contains the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(window_size, datasets):\n",
    "    datasets = {}\n",
    "    # Loop through each dataset 1,2,3,4,5,6\n",
    "    for dataset in DATA_SETS:\n",
    "        # load the training and testing sets\n",
    "        loaded_data = load_data.load_dataset(DATA_PATH + window_size + \"/\" + dataset)\n",
    "        # convert class vectors to binary class matrices\n",
    "        y_train = np_utils.to_categorical(loaded_data[\"train_labels\"], nb_classes)\n",
    "        y_test = np_utils.to_categorical(loaded_data[\"test_labels\"], nb_classes)\n",
    "        x_train = loaded_data[\"train_data\"].astype('float32')\n",
    "        x_test = loaded_data[\"test_data\"].astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255 \n",
    "        # Stack three times to fit VGG16 (RGB) treated as grayscale\n",
    "        x_train = np.hstack((x_train, x_train, x_train))\n",
    "        x_test = np.hstack((x_test, x_test, x_test))\n",
    "        \n",
    "        # [:-1] removes backslash from string\n",
    "        datasets[dataset[:-1]] = {\n",
    "            \"train_labels\": y_train,\n",
    "            \"test_labels\": y_test,\n",
    "            \"train_data\": x_train,\n",
    "            \"test_data\": x_test\n",
    "        }\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OhWJVLK3q0D"
   },
   "outputs": [],
   "source": [
    "def make_model(img_rows, img_cols, nb_classes):\n",
    "    model = vgg_16.make_model(img_rows, img_cols, nb_classes)\n",
    "    sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = sgd, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mjJ4B23bZz47"
   },
   "source": [
    "## Training and Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, train_labels, test_data, test_labels):\n",
    "    model = make_model(img_rows, img_cols, nb_classes)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        train_labels,\n",
    "        batch_size=batch_size,\n",
    "        epochs=nb_epoch,\n",
    "        validation_data=(test_data, test_labels),\n",
    "        shuffle=True, \n",
    "        verbose=1)\n",
    "    y_pred = model.predict_classes(test_data)\n",
    "    report = classification_report(np.argmax(data[\"test_labels\"],axis=1), y_pred,target_names=target_names, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(np.argmax(data[\"test_labels\"],axis=1), y_pred)\n",
    "    evaluation = model.evaluate(test_data, test_labels, batch_size=batch_size, verbose=0)\n",
    "    value[\"loss\"] = evaluation[0]\n",
    "    value[\"accuracy\"] = evaluation[1]\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"history\": history,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": confusion_matrix,\n",
    "        \"evaluation\": evaluation\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, window_length):\n",
    "    for dataset_name, result in results.items():\n",
    "        model = result.pop[\"model\"]\n",
    "        model.save(MODELS_PATH + window_length + \"/\" + datset_name + '.h5')\n",
    "    pickle.dump(results, open(RESULTS_PATH + window_length + \"_results.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(window_length):\n",
    "    results = pickle.load(open(RESULTS_PATH + window_length + \"_results.pkl\", \"rb\"))\n",
    "    for dataset_name, result in results.items():\n",
    "        result[\"model\"] = load_model(MODELS_PATH + window_length + \"/\" + datset_name + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 second window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_seconds = {}\n",
    "if TRAIN_MODEL_3s:\n",
    "    datasets = load_datasets(\"3\", DATA_SETS)\n",
    "    results_3_seconds = {}\n",
    "    for dataset_name, data in datasets.items():\n",
    "        result = train_model(data[\"train_data\"], data[\"train_labels\"], data[\"test_data\"], data[\"test_labels\"])\n",
    "        results_3_seconds[dataset_name] = result\n",
    "    save_results(results_3_seconds, \"3\")\n",
    "    \n",
    "else:\n",
    "    try:\n",
    "        results_3_seconds = load_results(\"3\")\n",
    "    except:\n",
    "        print(\"No saved file exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 second window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_seconds = {}\n",
    "if TRAIN_MODEL_2s:\n",
    "    datasets = load_datasets(\"2\", DATA_SETS)\n",
    "    results_2_seconds = {}\n",
    "    for dataset_name, data in datasets.items():\n",
    "        result = train_model(data[\"train_data\"], data[\"train_labels\"], data[\"test_data\"], data[\"test_labels\"])\n",
    "        results_2_seconds[dataset_name] = result\n",
    "    save_results(results_2_seconds, \"2\")\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        results_2_seconds = load_results(\"2\")\n",
    "    except:\n",
    "        print(\"No saved file exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 second window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_5_seconds = {}\n",
    "if TRAIN_MODEL_1_5s:\n",
    "    datasets = load_datasets(\"1_5\", DATA_SETS)\n",
    "    results_1_5_seconds = {}\n",
    "    for dataset_name, data in datasets.items():\n",
    "        result = train_model(data[\"train_data\"], data[\"train_labels\"], data[\"test_data\"], data[\"test_labels\"])\n",
    "        results_1_5_seconds[dataset_name] = result\n",
    "    save_results(results_1_5_seconds, \"1_5\")\n",
    "else:\n",
    "    try:\n",
    "        results_1_5_seconds = load_results(\"1_5\")\n",
    "    except:\n",
    "        print(\"No saved file exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 second window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_seconds = {}\n",
    "if TRAIN_MODEL_1s:\n",
    "    datasets = load_datasets(\"1\", DATA_SETS)\n",
    "    results_1_seconds = {}\n",
    "    for dataset_name, data in datasets.items():\n",
    "        result = train_model(data[\"train_data\"], data[\"train_labels\"], data[\"test_data\"], data[\"test_labels\"])\n",
    "        results_1_seconds[dataset_name] = result\n",
    "    save_results(results_1_seconds, \"1\")\n",
    "else:\n",
    "    try:\n",
    "        results_1_seconds = load_results(\"1\")\n",
    "    except:\n",
    "        print(\"No saved file exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uU-i7-ijaNu-"
   },
   "source": [
    "## Analysis and Saving of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_graphs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_keys_to_description(results):\n",
    "    # Renaming keys to make more meaninful (helps for reports and graphing)\n",
    "    keys = list(results.keys())\n",
    "    for key in keys:\n",
    "        if key == \"dataset_1\":\n",
    "            results[\"Test on A\"] = results.pop(key)\n",
    "        elif key == \"dataset_2\":\n",
    "            results[\"Test on B\"] = results.pop(key)\n",
    "        elif key == \"dataset_3\":\n",
    "            results[\"Test on C\"] = results.pop(key)\n",
    "        elif key == \"dataset_4\":\n",
    "            results[\"Test on D\"] = results.pop(key)\n",
    "        elif key == \"dataset_5\":\n",
    "            results[\"Test on E\"] = results.pop(key)\n",
    "        elif key == \"dataset_6\":\n",
    "            results[\"Test on F\"] = results.pop(key)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_seconds = convert_keys_to_description(results_3_seconds)\n",
    "results_2_seconds = convert_keys_to_description(results_2_seconds)\n",
    "results_1_5_seconds = convert_keys_to_description(results_1_5_seconds)\n",
    "results_1_seconds = convert_keys_to_description(results_1_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7aCG-luMe2_h"
   },
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Seconds, comparison of different datasets for test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_plots.plot_multiple_val_acc(\n",
    "    results_3_seconds,\n",
    "    \"Leave One User Out Comparison, 3 Second Window\",\n",
    "    save=save_graphs,\n",
    "    path=REPORT_PATH + \"leave_one_user_out_comparison_3sec.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Seconds, comparison of different datasets for test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_plots.plot_multiple_val_acc(\n",
    "    results_2_seconds,\n",
    "    \"Leave One User Out Comparison, 2 Second Window\",\n",
    "    save=save_graphs,\n",
    "    path=REPORT_PATH + \"leave_one_user_out_comparison_2sec.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Seconds, comparison of different datasets for test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_plots.plot_multiple_val_acc(\n",
    "    results_1_5_seconds,\n",
    "    \"Leave One User Out Comparison, 1.5 Second Window\",\n",
    "    save=save_graphs,\n",
    "    path=REPORT_PATH + \"leave_one_user_out_comparison_1_5sec.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Seconds, comparison of different datasets for test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_plots.plot_multiple_val_acc(\n",
    "    results_1_seconds,\n",
    "    \"Leave One User Out Comparison, 1 Second Window\",\n",
    "    save=save_graphs,\n",
    "    path=REPORT_PATH + \"leave_one_user_out_comparison_1sec.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of Time Window using Dataset 1, using test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_accuracy(results, dataset):\n",
    "    return results[\"dataset\"][\"evaluation\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Test on A\"\n",
    "window_results = {\n",
    "    \"3\": get_avg_precision(results_3_seconds, dataset),\n",
    "    \"2\": get_avg_precision(results_2_seconds, dataset),\n",
    "    \"1_5\": get_avg_precision(results_1_5_seconds, dataset)\n",
    "    \"1\": get_avg_precision(results_1_seconds, dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_plots.plot_evaluation_bar(\n",
    "    window_results,\n",
    "    [\"3\", \"2\", \"1.5\", \"1\"],\n",
    "    \"Comparison of window size, Trained on B-F, Tested on A\",\n",
    "    \"Window Size (s)\",\n",
    "    \"Accuracy\",\n",
    "    save=save_graphs,\n",
    "    path=REPORT_PATH + \"window_size_comparison.svg\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "478w01d1xuFs"
   },
   "source": [
    "### Classification Report and Confusion Matricies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "80JwFEpNyFGt"
   },
   "outputs": [],
   "source": [
    "# @TODO"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vgg16_all_zero_deg.ipynb",
   "provenance": [
    {
     "file_id": "1ixohIMt5Ugu13JiFmh4rQfM4MVOcdn78",
     "timestamp": 1540411548970
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
